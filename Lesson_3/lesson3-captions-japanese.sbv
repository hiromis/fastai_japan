0:00:00.030,0:00:05.819
ハロー、コーダーのための実践的ディープラーニングのレッスン3へようこそ。

0:00:07.510,0:00:09.510
先週、

0:00:09.880,0:00:11.590
私たちのモデルを本番環境で公開することを

0:00:11.590,0:00:14.609
検討していましたので、

0:00:15.160,0:00:21.059
今日はそれを終わらせてから、ニューラルネットワークを訓練する際に実際に何が行われているのか、

0:00:21.060,0:00:23.060
舞台裏を見ていきましょう。数学で、

0:00:23.740,0:00:25.830
何が起こっているのかを見て

0:00:26.740,0:00:31.859
SGDや他の重要なことを学んでいくことになります。

0:00:33.219,0:00:36.719
順番は本とは少し違います。本の中では

0:00:36.719,0:00:39.509
「今からレッスン4 とレッスン3 のどちらかに行って、

0:00:40.300,0:00:46.469
その後にもう一方のレッスンに戻ってもいいですよ」というようなことが書かれています。なので、私たちはレッスン４をやって、それからレッスン３、

0:00:47.320,0:00:49.320
第4章と第3章、と言うべきでしょうか。

0:00:49.960,0:00:51.370
どちらでも

0:00:51.370,0:00:53.370
好きな方を選んでください。

0:00:53.590,0:01:01.229
第4章はディープラーニングが実際にどのように機能するかの基礎についてのより技術的な章です。

0:01:01.629,0:01:03.160
一方、第3章は倫理に関するもので、

0:01:03.160,0:01:06.330
来週のレッスンではそれを学びます。

0:01:08.760,0:01:10.819
さて、私たちは

0:01:11.790,0:01:14.119
02プロダクションのノートを見ていますが、

0:01:15.150,0:01:19.039
Fastbook版を見ていきます。

0:01:19.040,0:01:22.009
（実際、今日見ているものはすべてFastbook版です）。

0:01:23.670,0:01:25.670
先週はクマを見て、

0:01:26.490,0:01:31.549
データブロックAPIを使って

0:01:32.220,0:01:34.220
データローダオブジェクトを作りました。

0:01:34.610,0:01:41.780
今週はみなさんが実験する機会があったといいです。もしまだやってない人は今がチャンスです。

0:01:43.650,0:01:45.889
このitm_tfmsの一行を少し飛ばしました。

0:01:47.590,0:01:51.880
アイテム変換です。ここでリサイズは何をしているかというと、

0:01:53.359,0:01:57.969
インターネットからダウンロードした画像は、様々なサイズやアスペクト比があります。

0:01:58.039,0:02:01.959
高さのあるものもあれば、幅のあるものもあります。 正方形のものもあれば、大きいものもあり、小さいものもあります。

0:02:02.479,0:02:08.949
アイテム変換のリサイズというと、各アイテム(ここではアイテムは1枚の画像)を縮小したり伸ばしたりして

0:02:10.009,0:02:12.398
128x128にリサイズすることを意味します。

0:02:13.099,0:02:20.319
いくつかの例を見るには show_batch と言えばいつでも見ることができます。

0:02:20.959,0:02:22.959
これがその例です。

0:02:25.379,0:02:31.279
縮めたり伸ばしたりだけがリサイズの方法ではありません。モデルに入力する前に、

0:02:32.280,0:02:35.780
すべてのものを正方形にしなければならないことを覚えておいてください。

0:02:35.780,0:02:40.639
私たちのモデルに到達するまでに、各ミニバッチに含まれるすべてのものは、同じサイズでなければなりません。

0:02:40.639,0:02:44.329
四角にするのが唯一の方法ではありませんが、最も簡単な方法であり、最も一般的な方法です。

0:02:49.740,0:02:52.219
他の方法としては、

0:02:54.210,0:02:56.779
別のデータブロックオブジェクトを作成して

0:02:57.990,0:03:02.029
既存のデータブロックオブジェクトの同一のコピーであるデータブロックオブジェクトを作成して、

0:03:02.030,0:03:07.970
いくつかの部分だけを変更することができます。

0:03:08.310,0:03:13.880
これは便利な "new "メソッドを呼び出すことで実現できます。 では、別のデータブロックオブジェクトを作成してみましょう。

0:03:14.970,0:03:19.130
そして今回の　item_tfms では、"Squish" メソッドを使用して

0:03:19.800,0:03:21.800
サイズを変更してみましょう。

0:03:22.260,0:03:29.839
質問があります。正方形の画像を使用する利点は、長方形の画像と比べて何ですか？

0:03:32.739,0:03:35.529
いい質問ですね。

0:03:38.840,0:03:40.780
シンプル性です。

0:03:40.780,0:03:42.580
すべての画像が

0:03:42.580,0:03:47.619
特定のアスペクト比の長方形であることがわかっているならば、そのままにしておいたほうがいいでしょう。

0:03:47.620,0:03:51.850
でも、背の高いものや幅の広いものがあるなら、

0:03:53.480,0:03:55.570
全部を正方形にするのが一番簡単なんです。

0:03:56.120,0:04:02.110
そうでなければ、背の高いものはすべてこのミニバッチに、

0:04:02.110,0:04:03.580
幅の広いものはあのミニバッチに、といったように整理しなければなりませんし、

0:04:03.580,0:04:05.889
それぞれのミニバッチに最適なアスペクト比を把握しなければなりません。

0:04:06.290,0:04:13.150
実際には、fastai2でそれを行う研究がありますが、

0:04:14.150,0:04:16.150
それはまだ少し不便です。

0:04:17.540,0:04:22.749
私は嘘をついていました。実際デフォルトは、縮小や伸張ではありません。

0:04:22.750,0:04:27.519
失礼しました。リサイズと言ったときのデフォルトは、

0:04:28.190,0:04:30.190
実際には

0:04:31.190,0:04:32.660
中央をつかむだけです。

0:04:32.660,0:04:34.809
つまり、実際にやっていることは、それぞれの画像の中心をつかむことなのです。

0:04:34.850,0:04:36.580
そのため、スクイッシュやストレッチをしたい場合は、

0:04:36.580,0:04:44.229
ResizeMethod.Squish引数をResizeに追加すると、この黒クマがかなり細くなって

0:04:44.720,0:04:49.059
でも、例えば両側にある葉っぱのようなものがあります。

0:04:51.740,0:04:59.049
質問があります。dls.newメソッドを使ったときに、何が変更できて、何が変更できないのですか？
0:04:59.270,0:05:04.719
トランスフォームですか？dls.newではなくて、bears.newですよね？つまり、新しいデータローダオブジェクトを作っているのではなく、

0:05:04.719,0:05:08.949
新しいデータブロックオブジェクトを作っているのです。覚えていないので

0:05:08.949,0:05:13.179
ドキュメントを確認してください。それか誰かがフォーラムに答えを

0:05:14.449,0:05:16.449
提示してくれると思います。

0:05:17.440,0:05:18.580
さて、

0:05:18.580,0:05:22.020
ドットスクイッシュを使ってみると、このグリズリーベアが

0:05:22.810,0:05:24.280
何となく

0:05:24.280,0:05:31.109
幅が広くて変な感じになっていて、この黒クマのクマは細くて変な感じになっているのがわかります。ResizeMethod.padを使うと

0:05:31.110,0:05:32.680
何が起こっているのかが一番わかりやすいです。

0:05:32.680,0:05:37.199
そして、ドットパッドが何をするかというと、各辺の周りに

0:05:37.449,0:05:41.279
黒い縁を追加するだけです。つまり、グリズリーベアは背が高かったので、

0:05:41.650,0:05:45.720
引き延ばしてみると（縮めることと引き延ばすことは逆の関係にあります）

0:05:45.720,0:05:49.589
引き延ばすと幅が広くなり、黒クマは

0:05:50.889,0:05:54.239
元々幅の広い長方形だったので、結果的には細くなりました。

0:05:58.090,0:06:02.590
ゼロを使う必要はありません。ゼロは黒で埋めることを意味します。また、リフレクトを使用すると

0:06:04.530,0:06:07.260
ピクセルが少し良く見えるようになります。

0:06:08.890,0:06:11.489
これらの異なる方法にはそれぞれ問題があります。

0:06:11.650,0:06:18.239
パッド法が最もクリーンで、正しいサイズになり、すべてのピクセルが得られますが、

0:06:18.520,0:06:22.859
無駄なピクセルが発生するため、無駄な計算が発生します。

0:06:23.800,0:06:28.380
スクイッシュ法が最も効率的なのは、知っているすべての情報を得ることができ、

0:06:30.610,0:06:37.860
何も無駄にしないからですが、その反面、神経網は何かがスクイッシュされたり

0:06:38.230,0:06:42.450
引き伸ばされたりしていることを認識することを学ばなければなりません。

0:06:42.760,0:06:44.250
認識しようとしている物体が2つあって、

0:06:44.250,0:06:48.390
1つは薄い傾向があり、もう1つは厚い傾向があり、

0:06:48.390,0:06:51.509
それ以外は全て同じだったら、認識するのは不可能かもしれません。

0:06:52.720,0:06:55.260
そして、デフォルトのクロップアプローチでは、

0:06:56.020,0:07:01.020
実際にいくつかの情報を削除します。

0:07:01.930,0:07:04.890
このグリズリーベアの場合は

0:07:05.440,0:07:10.440
足の多くを失っているので、足を見ないと何のクマかわからないとしたら、

0:07:11.500,0:07:14.070
もう足は見えません。

0:07:14.950,0:07:16.950
全ての方法に欠点があります。

0:07:20.170,0:07:25.319
そこで、他にもできることがあります。違う方法です。リサイズの代わりに、

0:07:25.660,0:07:31.140
RandomResizedCropというのです。実際にはこれが最も一般的な方法です。

0:07:32.770,0:07:34.919
ランダムリサイズクロップが何をするかというと、

0:07:35.980,0:07:40.980
毎回画像の別の部分を取得して拡大します。

0:07:41.530,0:07:45.059
つまり、これらはすべて同じ画像で、4つの異なるバージョンの画像を

0:07:45.910,0:07:48.930
バッチで取得しています。

0:07:49.930,0:07:56.219
いくつかの画像はそれぞれ異なる方法で縮小されています。そして異なるサブセットなどを選択しています。

0:07:56.950,0:08:02.909
情報が失われているので、これは以前のどのアプローチよりも悪いように思えます。

0:08:02.910,0:08:07.020
例えばこれは、実際には背中の部分がかなり失われています。

0:08:08.440,0:08:12.630
しかしこれの良いところは、オーバーフィットを避けたいということを覚えていますか？

0:08:14.230,0:08:17.640
毎回違う部分を見るとしたら

0:08:18.520,0:08:22.829
オーバーフィットする可能性は低くなります。なぜなら各エポックごとに

0:08:23.650,0:08:26.759
同じ画像を見ているわけではないからです。わかりますか？

0:08:28.870,0:08:35.280
ですから、このランダムリサイズクロップという手法は非常に人気があります。

0:08:35.800,0:08:37.750
min_scale 0.3というのは、

0:08:37.750,0:08:41.309
毎回元のサイズの少なくとも30%のピクセルを選択することを意味します。

0:08:42.010,0:08:45.239
そして、その正方形にズームインするということです。

0:08:50.740,0:08:52.300
このように、

0:08:52.300,0:08:59.490
モデルが画像を見るたびに、前回とは少し違って見えるように何かをすることを、

0:08:59.529,0:09:04.259
データ拡張呼びます。これはデータ拡張の1つのタイプです。

0:09:04.990,0:09:06.990
これが最も一般的な方法ですが、

0:09:07.390,0:09:09.220
他にもあります。

0:09:09.220,0:09:10.959
そして

0:09:10.959,0:09:14.009
データ拡張を行う最良の方法は、

0:09:15.100,0:09:16.600
この

0:09:16.600,0:09:24.279
aug_transforms関数を使うことです。aug_transformsが何をするかというと、

0:09:24.279,0:09:27.029
さまざまな拡張子のリストを返してくれます。

0:09:27.760,0:09:30.599
コントラストを変更したり、明るさを変更したり、

0:09:31.209,0:09:34.139
遠近法を歪めたりする拡張があります。このように

0:09:34.140,0:09:38.909
この部分はあなたの近くにあるように見えて この部分はあなたから遠くにあるように見えます。なぜなら遠近法で歪んでいるからです。

0:09:38.910,0:09:43.860
それから回転させたりします。（実際に回転させているのを見てください）、これは本当に暗くされていますよね？

0:09:45.220,0:09:50.760
これらはバッチ変換であり、アイテム変換ではありません。違いは、アイテム変換は一度に1つのイメージで行われます。

0:09:50.760,0:09:55.709
なので、すべてのイメージを同じサイズにリサイズするのはアイテム変換でなければなりません。

0:09:56.529,0:09:57.899
これをすべてミニバッチにして、

0:09:57.899,0:10:03.539
GPU上に置くと、バッチ変換がミニバッチ全体に一度に行われます。

0:10:03.880,0:10:09.570
そして、これらをバッチ変換にすることで、GPU上で実行されるため、増強が超高速に実行されます。

0:10:09.940,0:10:11.940
このようにして

0:10:12.190,0:10:19.799
GPU上で実行する独自のGPUアクセラレーション変換を書けるライブラリが他にあるかどうかは知りません。

0:10:21.250,0:10:25.409
これはFirstAI2の非常に便利なところです。

0:10:29.059,0:10:32.048
aug変換のドキュメントをチェックすると、

0:10:33.169,0:10:39.759
基本的にラップされているすべての基礎となるトランスフォームのドキュメントが見つかります。

0:10:41.179,0:10:43.358
タブ・シフトを押すと、

0:10:43.359,0:10:49.149
私は前にこのトリックを紹介したか覚えてないのですが、関数の括弧の中に入ってシフトタブを数回押すと、

0:10:49.579,0:10:55.598
すべての引数のリストがポップアップで表示されます。見ての通り、

0:10:57.079,0:11:03.339
基本的には、右に左に反転させることもあれば、下に上に反転させることもあり、回転、ズーム、

0:11:04.039,0:11:05.959
照明の変更、

0:11:05.959,0:11:07.959
遠近法のワープなどができる最大量はどれくらいなのか、

0:11:08.179,0:11:10.179
といったことが設定できるのがわかります。

0:11:10.639,0:11:14.829
訓練セットと検証セットに異なる拡張機能を追加するにはどうすればいいのでしょうか？

0:11:16.970,0:11:18.970
これは素晴らしいことで、

0:11:21.499,0:11:28.209
自動的にfastaiが検証セットでデータの拡張を行わないようにしてくれます。

0:11:28.939,0:11:32.469
つまり、これらすべてのオーグ変換は

0:11:33.319,0:11:37.699
トレーニングセットにのみ適用されます。

0:11:37.699,0:11:43.149
RandomResizedCropを除いて。RandomResizedCropにはそれぞれのセットで異なる動作があります。

0:11:43.699,0:11:51.049
トレーニングセットの動作は先ほど見たように、ランダムで違う部分を選択してそれにズームインします。

0:11:51.049,0:11:56.769
検証セットの動作は可能な限り最大の、中心の正方形を掴みます。

0:12:00.500,0:12:02.450
あなたは自分で変換を書くことができます。

0:12:02.450,0:12:06.160
それらはPythonであり、Pytorchの標準的なコードであるだけです。

0:12:06.830,0:12:10.629
デフォルトでは訓練セットにのみ適用されます。

0:12:10.700,0:12:12.939
もし、RandomResizedCropのように、

0:12:12.940,0:12:15.999
それぞれに異なるものを適用するような凝ったことをしたいのであれば、

0:12:16.460,0:12:22.540
次のコースに戻ってきて、その方法を見つけるか、ドキュメントを読むべきです。ロケットサイエンスではありませんが、

0:12:23.870,0:12:25.870
ほとんどの人には必要ないことです。

0:12:27.900,0:12:29.900
さて、

0:12:31.750,0:12:33.750
前回は

0:12:33.910,0:12:39.149
bears.newにRandomResizedCrop、平均スケール0.5、変換を追加して

0:12:40.240,0:12:43.889
トレーニングしました。実際に先週からこのノートブックを再実行してみましたが、

0:12:43.890,0:12:47.759
別のコンピュータ上にありますし、異なる画像を使っていますので、すべてが完全に同じというわけではありませんが、

0:12:48.460,0:12:52.860
それでも良い混乱のマトリックスが得られました。

0:12:55.470,0:12:58.850
黒クマのうち、正しく分類されたのは37頭で、2頭はグリズリー、1頭はテディでした。

0:13:00.810,0:13:02.810
さて、

0:13:03.220,0:13:06.790
トップの損失をプロットしてみると、このケースでは

0:13:07.399,0:13:10.958
明らかに奇妙なことが起こっていることがわかります。これは全くクマではありません。

0:13:11.540,0:13:15.610
これは熊の絵のように見えます。

0:13:17.120,0:13:23.079
テディと予想されていますが、黒クマの絵を描いたものです。確かに混乱するのはわかります。

0:13:23.629,0:13:25.040
見ての通り、

0:13:25.040,0:13:29.199
いくつかの部分が切り取られているのがわかりますが、その対処法については後で話します。

0:13:29.720,0:13:33.819
興味深いことに、このモデルを構築する前には、

0:13:34.910,0:13:37.990
データのクリーニングはほとんど行っていませんでした。

0:13:37.990,0:13:44.379
私たちが行った唯一のデータクリーニングは、各画像を開くことができるかどうかを検証することだけでした。それはverify_imagesの呼び出しでした。

0:13:44.899,0:13:52.208
その理由は、モデルを作成した後にデータをクリーンアップする方が、通常ははるかに簡単だからです。説明します。

0:13:52.759,0:13:56.350
これは画像分類器クリーナーと呼ばれるもので、

0:13:56.810,0:14:00.339
カテゴリを選択し、

0:14:01.160,0:14:04.360
トレーニングセットまたは検証セットを選択すると、

0:14:05.910,0:14:09.059
そのセットに含まれるすべての画像を

0:14:09.490,0:14:14.339
リストアップして、

0:14:14.890,0:14:22.019
最も自信がないもの、最も間違っている可能性が高いもの、

0:14:23.290,0:14:27.149
より正確には、損失が最も大きいものを選択します。

0:14:27.880,0:14:29.880
これは

0:14:30.130,0:14:32.130
あなたのデータに目を通し、

0:14:32.590,0:14:37.199
問題を見つけるための素晴らしい方法です。この場合、

0:14:37.990,0:14:41.789
最初に出てきたのはテディでもヒグマでも黒クマでもなく、子犬ですね。

0:14:42.280,0:14:47.610
これは素晴らしいクリーナーです。ここで削除をクリックすることができるからです。

0:14:47.950,0:14:53.160
これはテディというよりは、イウォークのように見えます。よくわからないけど、レイチェル、どう思いますか？イウォークかな？

0:14:53.160,0:14:54.940
イウォークと呼ぶことにします。

0:14:54.940,0:14:56.940
そしてこうして見ていって、

0:14:58.240,0:15:05.399
これは絶対にテディではありません。そして「それは間違いなくグリズリーベアだ」とするか

0:15:05.400,0:15:10.019
「ブラックベアだ」とか「削除すべきだ」とか、デフォルトでは「そのままにしておく」ということができます。

0:15:10.020,0:15:12.569
こうしてほとんどが問題ないように見えるまで続けます。

0:15:15.040,0:15:17.040
うーん、多分これは違う。

0:15:18.780,0:15:21.749
一旦全てが問題ないと思われるところまで来たら、

0:15:22.690,0:15:28.200
おそらく残りの部分も問題ないと言えるでしょう。なぜならすべて損失がこれらよりも低くテディのモードに合うからです。

0:15:28.750,0:15:31.440
そしてこのコードを実行して、

0:15:32.820,0:15:40.549
cleaner.delete で削除を選択したものを全てリンクを解除することができるようになります。

0:15:42.090,0:15:46.280
「リンクを解除」というのはすなわちファイルを削除すること。Pythonの別の呼び方です。

0:15:46.800,0:15:52.130
そして、変更すると言ったものをすべて調べて、実際に正しいディレクトリに

0:15:52.680,0:15:54.680
移動させることができます。

0:15:54.900,0:16:00.259
これを見たことがない人は、Jupiterノートブックの中に自分たちの小さなGUIを作ったことに

0:16:02.850,0:16:04.850
驚くかもしれません。

0:16:05.310,0:16:11.239
そう、これができるんですよ。そして私たちは1画面以下のコードでこれを構築しました。

0:16:11.940,0:16:16.369
fast.aiノートブックのソースコードでそれをチェックすることができます。

0:16:20.089,0:16:24.740
これは、fast.aiがノートブックで構築されていることを思い出す絶好の機会だと思います。

0:16:24.740,0:16:31.959
fast.ai repoに行って、クローンしてからNBSに行けば、

0:16:33.350,0:16:36.380
fast.aiのコードがすべてノートブックとして書かれているのがわかります。

0:16:38.010,0:16:43.400
そしてそこには散文や例、テストなどがたくさんあります。

0:16:43.680,0:16:49.519
ですから、どのように実装されているのかを学ぶには、

0:16:50.040,0:16:52.040
モジュールのコードを見るよりも、

0:16:52.890,0:16:54.890
ノートブックを見るのが一番です。

0:16:56.310,0:16:58.290
さて

0:16:58.290,0:17:02.600
ところで、時々このような奇妙なコメントを見ることがあるでしょう。

0:17:03.090,0:17:06.769
これらの奇妙なコメントは Jupiter notebook の開発環境の一部で

0:17:06.770,0:17:09.440
私たちが構築した nbdev と呼ばれるものです。

0:17:09.870,0:17:14.839
Sylvainと私は、Jupyterノートブックで本やウェブサイトやライブラリを簡単に作成できるようにするために、

0:17:15.390,0:17:24.270
これを作りました。この「hide」というのは、

0:17:24.270,0:17:29.030
これが本になったりドキュメントになったりするときに、このセルを表示しないということです。

0:17:29.310,0:17:32.869
なぜかというと、テキストの中ではこのセルと同じ情報が表示されていますが、

0:17:32.870,0:17:38.780
ノートブックを実行しているときには、直接実行できるフォーマットの方がいいと思ったからです。

0:17:38.780,0:17:44.030
だから、ノートには表示されていますが、本の中では違った方法で表示されています。

0:17:47.790,0:17:51.180
また、S: そして引用文のようなものも見られます。

0:17:51.370,0:17:56.130
本の中では「シルヴァんからのコメント」そして彼の言ったことが記載されます。

0:17:56.410,0:17:58.619
だからノートの中には、ちょっと変わった形のものが入っていますが、

0:17:58.620,0:18:04.620
それは何かを作るためにデザインされているからです。

0:18:06.660,0:18:13.849
先週はモデルからの情報をすべて含むpickleファイルにエクスポートして、

0:18:14.370,0:18:18.589
実際に推論を行うサーバー上で保存ファイルをロードして、

0:18:18.590,0:18:25.100
predictを呼び出すことができるLearnerを取得する方法を見ました。

0:18:30.790,0:18:34.200
predictの最も興味深い部分は返ってきた3つ目のテンソルで、

0:18:35.630,0:18:38.599
この場合３つの数字が含まれています。

0:18:39.420,0:18:47.420
テディベア、グリズリーベア、ブラックベアの3つのクラスがあるので、数字は3つあります。

0:18:48.360,0:18:55.160
これはデータローダの中のクラスの順番がわからないと

0:18:55.710,0:18:57.710
意味がありません。

0:18:57.710,0:19:02.240
そして、データローダにそのボキャブを聞くことで、その順番が何なのかがわかります。

0:19:02.250,0:19:06.650
fast.aiのボキャブは本当に一般的な概念で、

0:19:06.650,0:19:12.109
基本的には数字から文字列へのマッピングや数字から離散的なレベルへのマッピングがある場合、

0:19:13.170,0:19:19.579
常にボキャブに保存されています。

0:19:22.200,0:19:24.200
ここでは、

0:19:26.580,0:19:28.580
ブラックベアの活性化は1e-6で、

0:19:29.799,0:19:37.388
グリズリーの活性化は1で、テディの活性化は1e-6です。

0:19:40.450,0:19:48.150
これがグリズリーだと言うことに非常に自信を持っています。驚くことではありませんが、これはgrizzly.jpegと呼ばれるものでした。

0:19:50.650,0:19:52.650
えー、

0:19:53.670,0:19:55.000
正しい表示をするためには

0:19:55.000,0:19:57.420
このマッピングを知っておく必要がありますが

0:19:57.420,0:20:03.330
もちろんデータローダーオブジェクトはすでにそのマッピング（ボキャブ）を知っていて、ローダーと共に保存されています。

0:20:03.880,0:20:06.660
だから自動的にグリズリーと言うことを知っているのです。

0:20:06.660,0:20:10.350
最初に表示するのに最適な人間が読める文字列が手に入ります。

0:20:11.110,0:20:18.420
FastAI２では、このオブジェクトを保存すると、推論に必要なものがすべて入っています。

0:20:18.420,0:20:20.850
これには、正規化や変換ステップ、

0:20:22.420,0:20:28.739
ボキャブなどの情報がすべて含まれているので、すべてを正しく表示することができます。

0:20:30.040,0:20:33.359
そうですね。では、

0:20:34.930,0:20:37.049
これをアプリとしてデプロイしてみましょう。

0:20:38.290,0:20:43.590
ウェブプログラミングをしたことがある人は、知っておく必要があるのは

0:20:44.020,0:20:46.530
このコードとこのコードだけです。

0:20:46.630,0:20:51.359
これはアプリケーションを起動した時に一度だけ呼び出すコードで、

0:20:51.580,0:20:53.580
これは推論を行う時には毎回呼び出すコードです。

0:20:53.710,0:20:57.419
また、バッチ版もありますので、

0:20:57.420,0:21:00.359
興味があれば調べてみてください。これは一度に一つずつです。

0:21:03.520,0:21:04.880
ですから、すでにWebプログラマーであったり、

0:21:04.880,0:21:08.680
Webプログラマーにアクセスできる人であれば、特別なことは何もありません。

0:21:08.930,0:21:13.570
これらはあなたが知っている... この2行のコードをどこかに貼り付けるだけで、3つのものが返ってきます。

0:21:14.270,0:21:17.290
人間が読める文字列ともし分類をしているならば、

0:21:18.110,0:21:23.469
そのインデックス、この場合１はグリズリー、そして各クラスの確率です。

0:21:24.920,0:21:30.729
このコースで本当にやりたかったことの一つは、誰もがウェブ開発者であることを前提としないことです。

0:21:31.880,0:21:38.080
ほとんどのデータサイエンティストはそうではありません。でも、もしすべてのデータサイエンティストが、

0:21:38.210,0:21:40.510
少なくともアプリケーションのプロトタイプを作成して、自分の研究していることをアピールすることができれば、素晴らしいことだと思います。

0:21:41.930,0:21:43.930
それで我々は...

0:21:43.980,0:21:48.719
私たちがキュレートしようとしたのは（作ったものはどれもありません）、

0:21:49.690,0:21:56.400
JupyterノートブックでGUIを作成して完全なアプリケーションを作成する方法です。

0:21:57.160,0:21:59.160
このために

0:21:59.470,0:22:00.490
私たちが

0:22:00.490,0:22:07.559
使用している技術のキーとなる部分は、ipythonウィジェット（通称ipywidget）とVoilàです。

0:22:08.169,0:22:14.939
iPywidgetsはデフォルトではウィジェットとしてインポートされ、彼ら自身のドキュメントでもそうです。

0:22:15.970,0:22:19.199
これはGUIウィジェットとして使用されています。例えば、ファイルアップロードボタンです。

0:22:20.290,0:22:21.820
このファイルアップロードボタンを

0:22:21.820,0:22:25.350
作成して表示すると、

0:22:25.900,0:22:30.540
前回のレッスンでも見たように、実際にクリックできるボタンが表示されます。

0:22:32.020,0:22:37.650
これをクリックすると、

0:22:37.720,0:22:43.689
「OK、あなたは1つのものを選択しました」と表示されます。

0:22:48.470,0:22:55.089
これはどうやって使うのでしょうか? それは... これらのウィジェットには、あらゆる種類のメソッドとプロパティがあります。

0:22:55.940,0:22:59.559
アップロードボタンにはデータプロパティがあり、アップロードした全ての画像を含む配列です。

0:23:00.470,0:23:07.270
これをPILイメージドットクリエイトに渡すことができます。ドットクリエイトは、

0:23:10.000,0:23:13.800
FastAIがアイテムを作成するために使用する標準的なファクトリーメソッドのようなもので、

0:23:14.710,0:23:19.229
PILイメージのドットクリエイトは、様々な種類のものからアイテムを作成することができます。

0:23:19.330,0:23:24.569
それを作成することができるものの一つはバイナリブロブで、これはファイルのアップロードに含まれているものです。

0:23:25.950,0:23:27.950
それを表示することができ、

0:23:28.330,0:23:30.120
これがテディです。でしょう？

0:23:30.120,0:23:37.739
Jupyterノートブックのセルは、他のセルの

0:23:38.200,0:23:41.310
GUIで作成されたデータなどを参照することができます。

0:23:42.530,0:23:44.930
そのテディは少しの間隠しておいて、

0:23:46.110,0:23:52.160
次に知っておくべきことは、出力と呼ばれるウィジェットがあります。

0:23:53.760,0:23:55.760
基本的には後から入力するものです。

0:23:56.580,0:24:01.099
この部分を削除すると、

0:24:02.040,0:24:07.520
出力ウィジェットができました。

0:24:07.930,0:24:09.930
このようにしてみましょう。

0:24:12.509,0:24:13.359
そして、

0:24:13.359,0:24:17.968
出力ウィジェットを表示してくださいと言っても何も出力されていないので表示されません。

0:24:17.969,0:24:23.409
次のセルでは、出力プレースホルダを使って

0:24:23.409,0:24:28.799
画像のサムネイルを表示すると、ここに表示されないことがわかります。

0:24:30.050,0:24:35.389
ここには表示されます。そうですよね？というのは... プレースホルダがあった場所です。

0:24:36.840,0:24:40.280
ということで、もう一度実行して、プレースホルダを消去してみましょう。

0:24:41.940,0:24:46.759
そこで、別の種類のプレースホルダを作成することができます。

0:24:47.490,0:24:56.850
ラベルは、テキストを入れることができるものです。ラベルに、「画像を選択してください」というような値を与えることができます。

0:24:56.850,0:24:59.959
これで「画像を選択してください」というラベルができました。

0:25:00.630,0:25:03.140
別のボタンを作って分類ができるようにしましょう。

0:25:04.870,0:25:09.069
これはファイルアップロードボタンではありません。一般的なボタンです。今のところこのボタンは何もしません。

0:25:10.430,0:25:12.759
イベントハンドラを接続するまでは何もしません。

0:25:13.310,0:25:20.440
イベントハンドラとはコールバックのことで、このコースではコールバックについて学びます。

0:25:21.770,0:25:27.400
GUIプログラミングやWebプログラミングをしたことがある人なら分かると思いますが、

0:25:27.800,0:25:35.139
ボタンがクリックされたときに呼び出される関数を書いて、これがオンクリックイベントであることを

0:25:35.960,0:25:37.960
フレームワークに伝えます。

0:25:38.150,0:25:40.719
これが私のボタン実行(btn_run)です。

0:25:41.240,0:25:45.160
ボタン実行のクリックイベントは、

0:25:45.230,0:25:51.610
このコードを呼び出すことです。このコードが先ほど見たようなことをすべて実行します。

0:25:52.220,0:25:54.970
アップロードされた画像を作成し、出力をクリアして画像を表示し、

0:25:55.850,0:25:58.390
predictを呼び出し、

0:25:59.060,0:26:01.060
ラベルを予測値に置き換えます。

0:26:02.750,0:26:07.330
これですべて完了です。まだ何もしていませんが、分類ボタンに戻ると、

0:26:07.330,0:26:09.819
これにはイベントハンドラが接続されています。見てください。

0:26:10.550,0:26:12.530
クリックして、

0:26:12.530,0:26:14.629
ジャーン、予測が表示され、

0:26:16.010,0:26:22.999
画像も現れました。万が一見逃してしまった人のためにもう一度。すべてをクリアしておきましょう。全部消えました。

0:26:27.330,0:26:30.769
これは「画像を選択してください」とあり、ここには何もありません。分類をクリックして、

0:26:32.340,0:26:33.780
パッ

0:26:33.780,0:26:38.090
パッ、パッ。 このように、

0:26:39.030,0:26:41.540
ノートブックが突然、

0:26:42.210,0:26:47.239
アプリケーションを作るインタラクティブなプロトタイピングの遊び場になってしまったのは驚きです。これがうまくいけば、

0:26:48.300,0:26:51.019
一か所に集めるだけです。

0:26:54.510,0:26:57.439
それをするのに一番簡単な方法は、Vボックスを作ることです。

0:26:57.440,0:26:59.130
Vボックスとは縦長のボックスのことで、

0:26:59.130,0:27:01.849
ウィジェットを入れるものです。

0:27:01.850,0:27:02.870
この場合、

0:27:02.870,0:27:06.409
以下のウィジェットを配置します。「select your bear」と書かれたラベル、

0:27:06.570,0:27:10.789
アップロードボタン、実行ボタン、出力用プレースホルダ、

0:27:11.340,0:27:13.140
予測用ラベルです。

0:27:13.140,0:27:15.679
しかし、これらをもう一度実行して、

0:27:16.590,0:27:18.590
不正をしないようにすっきりさせてから、

0:27:20.060,0:27:26.210
Vボックスを作成しましょう。見ての通り、

0:27:27.789,0:27:31.950
これですべてのパーツが揃いました。

0:27:33.800,0:27:35.800
これは・・・

0:27:37.660,0:27:40.899
あっ、クマを表示するものを誤って実行してしまったので、処分しておきましょう。

0:27:45.600,0:27:52.060
できました。これでアップロードをクリックして、クマを選択して、

0:27:54.880,0:27:56.880
分類をクリックして、

0:27:57.730,0:28:02.459
これは正確には、この・・・これは、このボタンと同じボタンで、

0:28:03.340,0:28:10.169
2つの場所で同じボタンを表示しているようなもので、ちょっとワイルドなアイデアです。分類をクリックすると、

0:28:10.780,0:28:12.780
このラベルとこのラベルが変更され、

0:28:14.350,0:28:17.880
実際には両方とも同じラベルを参照しているからです。

0:28:20.280,0:28:22.080
この通りです。

0:28:22.080,0:28:23.700
さて

0:28:23.700,0:28:28.640
これが私たちのアプリです。これは実際に私がイメージクリーナーGUIを

0:28:29.340,0:28:31.610
構築した方法です。

0:28:32.519,0:28:37.759
これらのものを実際に使用して、このようにノートブックの中で

0:28:38.669,0:28:44.028
セルごとにイメージクリーナーGUIを構築しました。このようなGUIを構築するための

0:28:44.610,0:28:46.200
インタラクティブな実験的なフレームワークを

0:28:46.200,0:28:47.309
得ることができます。

0:28:47.309,0:28:54.018
もしあなたがGUIのものを前にやったことがないデータサイエンティストなら、これは始めるのに最適な時です。なぜなら、

0:28:54.210,0:28:57.419
実際のプログラムを作ることができるようになったからです。

0:28:57.419,0:28:59.419
now, of course an actual program

0:28:59.760,0:29:07.609
もちろん実際のプログラムをノートブックの中で実行するのもクールですが、私たちが本当に必要としているのは、このプログラムを誰でも実行できる場所で実行すること、

0:29:08.850,0:29:10.850
ここがVoilaの出番です。

0:29:11.100,0:29:19.460
Voilaをインストールするには以下の行を実行する必要があります。

0:29:21.330,0:29:23.330
これは散文にも載っています。

0:29:23.340,0:29:28.429
Voilaが何をするのかというと、ノートブックの

0:29:29.610,0:29:32.479
マークダウンとipythonウィジェットと

0:29:33.750,0:29:37.489
出力以外は何も表示しません。

0:29:38.280,0:29:44.509
そのため、すべてのコードセルが消えてしまい、そのページを見ている人は自分のコードを実行することができず、

0:29:44.510,0:29:48.320
ウィジェットとのやりとりしかできません。

0:29:48.600,0:29:50.600
ここで私がしたのは、

0:29:50.970,0:29:57.470
ノートブックのコードを、別のノートにコピーして貼り付けたのですが、

0:29:59.690,0:30:02.419
そのノートにはこれらの行のコードしかありません。

0:30:07.049,0:30:09.409
これは前に見たのと同じコードの行になります。

0:30:12.650,0:30:15.050
これはノートブックです。ただ普通のノートブックです。

0:30:17.400,0:30:21.469
Voilaをインストールしました。

0:30:22.440,0:30:25.999
そうすると、このノートブックを開いて、

0:30:30.430,0:30:34.319
「ノートブック」を 「Voila」に置き換えると、

0:30:35.970,0:30:38.459
実際にはノートブックではなく、

0:30:40.320,0:30:45.500
さっき説明したようにマークダウンとウィジェットだけが表示されます。

0:30:47.250,0:30:51.689
ここにクマの分類器があり、アップロードをクリックして、今回はグリズリーのクマをやってみましょう。

0:30:56.460,0:31:00.199
これは少し違ったバージョンで、分類ボタンがなく、

0:31:00.200,0:31:02.179
アップロードをクリックしたときに

0:31:02.179,0:31:05.839
すべてが実行されるようにするためにもう少し便利にしてみました。

0:31:06.420,0:31:08.420
見ての通り全てうまくいっています。

0:31:09.540,0:31:11.540
これは世界で

0:31:11.730,0:31:13.170
最もシンプルな

0:31:13.170,0:31:16.549
プロトタイプですが、これは概念実証であり、

0:31:17.250,0:31:24.799
ドロップダウンやスライダー、チャートなどのAngularアプリやReactアプリなどで使えるものは全て、

0:31:25.049,0:31:30.289
ウィジェットとして追加することができます。 実際には、

0:31:31.260,0:31:36.770
例えばVue.jsなど、フレームワークを全て使うことができます。Vue.jsフレームワークは非常に人気のあるJavaScriptフレームワークで、

0:31:37.799,0:31:41.059
Vue JSフレームワーク全てを

0:31:42.299,0:31:44.299
ウィジェットとViolaで使用することができます。

0:31:45.000,0:31:47.000
さて、このアプリを

0:31:47.910,0:31:49.530
世界中の誰かに

0:31:49.530,0:31:51.330
実行してもらえるように

0:31:51.330,0:31:53.220
したいと思います。

0:31:53.220,0:31:58.010
Voilaのドキュメントにはいくつかの方法が紹介されていますが、最も簡単なのは

0:31:58.530,0:32:01.669
Binderと呼ばれるシステムを使うことです。

0:32:04.500,0:32:07.050
Binderはmybinder.orgにあり、

0:32:08.290,0:32:13.389
githubのリポジトリ名をここに貼り付けてください。本にも書いてありますが、

0:32:15.510,0:32:21.739
githubのリポジトリ名をここに貼り付けて、

0:32:23.190,0:32:25.460
ファイルをURLに変更、

0:32:28.060,0:32:33.509
ここに今さっきまで使っていたパスを入れて、

0:32:37.860,0:32:43.229
起動と言うと、URLが表示されます。

0:32:44.740,0:32:46.580
このURLを

0:32:46.580,0:32:50.240
人々に渡すことができます。

0:32:50.240,0:32:52.240
これは実際に

0:32:53.000,0:32:57.729
インタラクティブな実行中のアプリケーションです。Binderは無料で、

0:32:57.730,0:33:06.429
誰でもこれを使ってVoilaアプリを公開してウェブアプリケーションにすることができます。

0:33:06.830,0:33:14.030
試してみてください。最初にBinderを使うときは、サイトの構築に5分ほどかかります。

0:33:14.030,0:33:20.469
Dockerと呼ばれるものを使ってFastAIフレームワークやPythonなどをデプロイするからです。

0:33:21.350,0:33:23.350
でもそれを一度やると、

0:33:23.450,0:33:27.790
仮想マシンは人々が利用している限り、しばらくの間稼働します。

0:33:32.150,0:33:37.940
人々が利用している限り、その仮想マシンはしばらくの間稼働し続けます。

0:33:38.580,0:33:40.500
十分速いです。

0:33:40.500,0:33:42.500
ここで注意すべきいくつかのことは、

0:33:43.050,0:33:48.169
無料サービスなので驚かないと思いますが、GPUを使わず、CPUを使っています。

0:33:49.140,0:33:51.770
意外かもしれませんが、

0:33:52.530,0:33:55.519
CPU上で動作するものにデプロイしています。

0:33:59.830,0:34:05.699
しかし、考えてみると、GPUよりもCPUにデプロイする方がはるかに理にかなっています。

0:34:10.220,0:34:12.220
ちょっと失礼します。

0:34:13.800,0:34:16.979
ここで何が起きているかというと、

0:34:17.950,0:34:23.909
アプリに戻りましょう。私のアプリでは、一度に1つの画像を渡しているので、

0:34:25.000,0:34:27.120
その1つの画像を渡すときに、

0:34:27.120,0:34:30.659
GPUが行うべき膨大な量の並列処理を行う必要がありません。

0:34:30.850,0:34:34.649
これは実際にはCPUがより効率的に行うことになるので、

0:34:36.130,0:34:39.899
このコースを受講している人の大半が

0:34:41.020,0:34:44.159
GPUではなくCPUに推論を

0:34:45.100,0:34:49.019
デプロイしたいと考えていることがわかりました。なぜなら、

0:34:49.840,0:34:51.840
通常は一度に一つのアイテムを処理しているからです。

0:34:52.240,0:34:55.800
CPUにデプロイする方がはるかに安くて簡単で、

0:34:56.560,0:34:59.610
その理由は、あなたが好きなホスティングサービスを使用することができるからです。

0:34:59.980,0:35:06.300
この時点ではただのプログラムであることを覚えておいてください。

0:35:07.870,0:35:14.189
あなたはすべての通常の水平方向のスケーリング、垂直方向のスケーリングを使用することができます。Herokuを使用することができるし、AWSを使用することもできます。

0:35:14.890,0:35:17.189
超安価なインスタンスを使用することができます。

0:35:19.060,0:35:21.060
とても安くて超簡単です。

0:35:21.700,0:35:25.230
でもあえてGPUにデプロイする必要がある場合もあるかもしれません。

0:35:26.590,0:35:33.840
例えば動画を処理している場合、1つの動画をCPUで処理するのに

0:35:33.840,0:35:35.840
1日かかるかもしれません。

0:35:36.040,0:35:37.750
または、

0:35:37.750,0:35:42.149
1秒間に1000回のリクエストがあるほど大成功しているかもしれません。

0:35:42.610,0:35:46.320
そのような場合には、一度に128回のリクエストを受けて、

0:35:46.320,0:35:50.789
それらをまとめてバッチ処理して、バッチ全体をGPU上に置いて、結果を得て、それらを元に戻します。

0:35:52.260,0:35:54.260
これには注意が必要です。

0:35:55.490,0:36:02.719
なぜなら、あなたのリクエストが十分に速く来ない場合、ユーザーはバッチ処理の準備が整うまで待たなければならなくなるからです。

0:36:04.410,0:36:10.399
しかし、コンセプト的には、あなたのサイトが十分に人気がある限り、それができる可能性があります。

0:36:12.950,0:36:16.839
もう一つは、携帯電話にデプロイしたいと思うかもしれません。

0:36:19.460,0:36:21.380
携帯電話へのデプロイは、

0:36:21.380,0:36:23.380
可能な限りサーバーにデプロイして、

0:36:23.810,0:36:30.579
携帯電話がネットワークを介してサーバーと通信することです。

0:36:30.770,0:36:32.750
そうすれば、

0:36:32.750,0:36:39.579
通常のサーバ上で通常のPytorchプログラムを使用し、通常のネットワーク通話を行うことができるため、それは人生を楽にします。

0:36:40.790,0:36:44.229
スマホでPytorchアプリを実行しようとすると、

0:36:44.780,0:36:49.780
Pytorchがネイティブに動作する環境ではないので、

0:36:49.780,0:36:54.550
プログラムを他の形式に変換しなければなしません。

0:36:55.069,0:36:56.599
他の形式がないわけではありません。

0:36:56.599,0:37:02.169
変換する主な形式はONNXと呼ばれるもので、超高速で高性能な

0:37:03.530,0:37:08.769
アプローチのために特別に設計されていて、

0:37:10.339,0:37:15.999
サーバ上でも携帯電話上でも実行できるようになっています。

0:37:17.030,0:37:19.329
PythonとPytorchのランタイムを

0:37:20.119,0:37:22.119
配置する必要はありませんが、

0:37:22.550,0:37:25.899
使わないよりはずっと複雑です。

0:37:27.020,0:37:33.159
デバッグや設定、メンテナンスも大変です。

0:37:33.980,0:37:37.149
可能であれば、物事はシンプルにしておいて

0:37:37.819,0:37:43.509
運良く成功してGPUなどにスケールアップする必要が出てきたら

0:37:44.270,0:37:51.759
その時点でONNXのエキスパートやサービングエキスパートなどにお金をかけることを正当化できるだけの

0:37:52.310,0:37:55.629
経済的余裕があることを願っています。

0:37:56.450,0:37:58.040
ONNXランタイムやAWS

0:37:58.040,0:38:02.649
Sagemakerなど、様々なシステムがあり、

0:38:02.650,0:38:09.609
「ここに私のONNXバンドルがあります」と言えば、それを提供してくれます。Pytorchにもモバイルフレームワークがありますが、

0:38:10.010,0:38:12.010
これも同じ考えです。

0:38:13.660,0:38:14.980
さてここで・・・

0:38:14.980,0:38:20.850
面白いことに、ここでは２種類の違ったデプロイメントの話をしています。

0:38:21.550,0:38:28.019
1つは趣味のアプリケーションのようなデプロイで、プロトタイプを作成して友人に見せたり、同僚に何かがどのように動くかを説明したり、

0:38:28.210,0:38:34.199
ちょっとしたインタラクティブな分析をしたりしています。

0:38:35.020,0:38:37.020
その一方で、実際の製品や

0:38:37.270,0:38:40.229
会社の業務の一部にしたいと思っているものを

0:38:41.110,0:38:42.370
プロトタイプにしているかもしれません。

0:38:42.370,0:38:44.370
実際に何かをデプロイするときには、

0:38:45.520,0:38:50.280
注意しなければならないことがたくさんあります。

0:38:53.319,0:38:56.768
注意しなければならないことの一例として、今やったことを正確にやったとします。

0:38:57.319,0:39:01.149
これは宿題ですが、自分のアプリケーションを作ることです。

0:39:01.789,0:39:06.278
自分の画像検索アプリケーションを作って欲しいのですが、

0:39:06.859,0:39:11.078
私のウィジェットのセットを使ってもいいですが、

0:39:11.209,0:39:15.999
ipywidgetsのウェブサイトに行って、他のウィジェットを見て、何かクールなものを考えてみてください。

0:39:17.569,0:39:24.399
できる限りのことをしてみて、フォーラムで私たちを見せてください。

0:39:25.039,0:39:27.019
さて、

0:39:27.019,0:39:29.049
あなたがアプリのユーザーが

0:39:29.509,0:39:34.419
健康的な肌か不健康な肌かを判断するのに役立つアプリを作りたいと決めたとしましょう。

0:39:34.459,0:39:41.019
今やったように、グリズリーベアやテディベアなどをBingで検索するのではなく、

0:39:41.599,0:39:46.659
健康的な肌と不健康な肌を検索してみましょう。するとこのようなことが起こるのです。

0:39:46.969,0:39:49.629
私たちのバージョンでは、

0:39:49.630,0:39:55.599
BingAPI、つまり画像検索APIを使っていましたが、

0:39:55.599,0:40:01.869
それは裏ではウェブサイトを使っています。健康的な肌と入力して検索すると、

0:40:03.530,0:40:06.949
健康的な肌の定義は、

0:40:08.700,0:40:10.700
若い白人女性が

0:40:11.640,0:40:13.070
愛情を持って顔を触っていることだということがわかります。

0:40:13.070,0:40:19.820
健康的な肌の分類器はこれを検出することを学習します。

0:40:20.580,0:40:22.580
そして

0:40:23.070,0:40:28.879
これはDeb Rajiの素晴らしい例です。彼女の論文「Actionable Auditing」をチェックしてみてください。

0:40:30.300,0:40:35.449
モデルのバイアスについての洞察が多く紹介されています。

0:40:36.540,0:40:38.749
つまり、これは、

0:40:39.390,0:40:41.390
データを注意深く見ていなければ、

0:40:41.820,0:40:43.820
結果的に

0:40:43.830,0:40:47.809
解決したい問題を実際には解決しないものになってしまうという例です。

0:40:53.100,0:40:55.100
これは厄介でしょう？

0:40:56.330,0:41:03.019
アルゴリズムを訓練するデータは、もし以前には存在しなかった新製品のようなものを構築しているなら

0:41:03.020,0:41:07.939
定義上、実生活で使用されるデータの例がありません。

0:41:07.940,0:41:14.780
そうですよね？だから、どこかで見つけようとしますが、Googleで検索しても、

0:41:15.450,0:41:17.540
実際の生活で見られるようなミックスを

0:41:18.300,0:41:22.160
反映したデータは出てこないでしょう。

0:41:25.599,0:41:27.599
だから、

0:41:29.450,0:41:33.919
ここで重要なのは、注意が必要だと言う事です。そして、特にテストセットについては、

0:41:33.920,0:41:35.990
最終的にチェックするセットは、

0:41:36.839,0:41:39.289
現実の世界を反映したデータを収集するように

0:41:39.810,0:41:45.019
努力してください。例えば、健康的な肌の例では、

0:41:45.150,0:41:51.500
皮膚科医に相談して、健康的な肌と不健康な肌の例を10個くらい探してみてください。

0:41:52.410,0:41:54.920
それがゴールドスタンダードのテストになるでしょう。

0:41:56.420,0:41:58.420
うーん。

0:41:58.790,0:42:03.849
デプロイメントには考えなければならない問題は山ほどあります。そのすべてを説明することはできませんが、

0:42:04.099,0:42:10.119
オライリーの「Building Machine Learning Powered Applications」

0:42:10.820,0:42:13.570
という本は素晴らしいリソースです。

0:42:14.599,0:42:18.219
これは、A/Bテストやいつデータを更新すべきか、

0:42:19.609,0:42:23.889
どのようにモニタリングするかなどについて

0:42:24.320,0:42:28.539
このコース詳しく説明していない理由の一つで、その本はすでに書かれているので、

0:42:29.180,0:42:31.180
書き直したくないのです。

0:42:33.550,0:42:37.989
私が気になっている特定の分野について触れておきたいと思います。

0:42:40.140,0:42:42.060
それは

0:42:42.060,0:42:43.860
例を挙げてみましょう。

0:42:43.860,0:42:49.370
例えばこのクマ検知システムを展開するとして、キャンプ場周辺のビデオカメラに取り付けます。

0:42:49.680,0:42:57.200
キャンプをしてる人に熊の侵入を警告します。先ほどのデータを使って 訓練されたモデルを使ってみると

0:42:58.140,0:43:00.140
これは全て

0:43:00.330,0:43:04.580
綺麗に撮られた完璧な熊の写真ですね。

0:43:05.940,0:43:07.470
実際にキャンプ場のクマ探知機で

0:43:07.470,0:43:11.240
対処しなけれはいけないような写真とは全く違うものです。

0:43:11.820,0:43:18.499
それは画像ではなくビデオがあるだろうし、

0:43:19.110,0:43:21.110
夜間だろうし、低解像度の防犯カメラがあるでしょう。

0:43:21.420,0:43:27.409
熊に殺される前に警告できるよう、システムの性能が十分に速いことを確認する必要があります。

0:43:29.010,0:43:34.249
藪に隠れていたり、影に隠れていたりする熊もいるでしょう。

0:43:34.380,0:43:38.059
どれもインターネットの写真では見られないようなものです。

0:43:39.420,0:43:45.620
そこで私たちはこれを「ドメイン外データ」と呼んでいます。ドメイン外データ」とは、

0:43:46.140,0:43:50.840
推論を行おうとしているデータが、学習したデータとは

0:43:51.330,0:43:54.709
異なる種類のデータである場合を指します。

0:43:56.549,0:44:02.758
これは実際には... この質問に完璧に答える方法はありません。倫理を説明するときに、

0:44:05.140,0:44:07.559
このような状況を

0:44:08.650,0:44:14.879
最小限に抑えるための本当に役立つ方法をいくつかお話しします。例えば、多様なチームを持つことは、

0:44:15.910,0:44:20.759
人々が最終的に出してくるデータの種類に驚かないようにするための素晴らしい方法であることがわかりました。

0:44:22.359,0:44:26.338
しかし、本当にそれはあなたがあなたが超熟考しなければならないことなのです。

0:44:28.690,0:44:30.810
これと非常によく似たものに

0:44:31.030,0:44:38.249
「ドメインシフト」と呼ばれるものがあります ドメインシフトとは、最初は全てのデータがドメインデータに入っていても、

0:44:38.770,0:44:40.770
時間の経過とともに

0:44:41.290,0:44:43.739
データの種類が変化するというものです。

0:44:44.680,0:44:48.000
そのうちにアライグマがキャンプ場に侵入してくるようになるかもしれませんが

0:44:48.610,0:44:51.569
これはクマ探知機で、アライグマの訓練はされていません。

0:44:51.570,0:44:57.149
これは「ドメインシフト」と呼ばれるもので、これも非常に気をつけなければならないことの一つです。レイチェル 質問がありますか？

0:44:57.970,0:45:00.300
いいえ、私が言いたかったのは、

0:45:01.000,0:45:06.570
すべてのデータは偏っているということで、バイアスのないデータや

0:45:07.600,0:45:12.059
すべてのケースで完全に代表的なデータのようなものは存在しません。これに対処するための多くの提案は、

0:45:12.250,0:45:17.790
この考えに収束してきました。Timnit Gebruの「Datasheets for Datasets」にも見られるように

0:45:18.220,0:45:22.800
データセットの詳細、どのように収集されたか、

0:45:23.710,0:45:30.000
どのような状況で使用するのが適切か、どのように維持されているかなど、データセットに関する多くの情報を書き留めておくのです。

0:45:30.000,0:45:34.500
それは、バイアスを完全に排除したということではなくて、

0:45:34.500,0:45:40.050
データセットの属性を非常に意識しているだけで、後になってそれらの影響を受けないようにしているということです。

0:45:40.450,0:45:47.790
データがどのように収集されたのか、その限界は何なのかを理解するという考え方の中で、

0:45:48.850,0:45:51.959
いくつかの提案がされていますが、私はとても気に入っています

0:45:53.920,0:45:55.920
ありがとう、レイチェル。

0:45:56.320,0:46:03.719
ここでの重要な問題は、ニューラルネットワークの動作全体を知ることができないということです。

0:46:05.290,0:46:10.439
通常のプログラミングでは、if文やループなどを入力して、

0:46:10.440,0:46:12.510
理論的にはそれが何をするかが明らかです。

0:46:12.580,0:46:17.429
それでも時々驚くことがあけれど。この場合、あなたは何も教えずに、

0:46:18.010,0:46:21.600
ただ学習するための例を与え、何か有用なことを学んでくれることを願いました。

0:46:21.760,0:46:25.979
これらのニューラルネットワークには何億ものパラメータがあるので、

0:46:25.980,0:46:31.320
それらがどのように組み合わせて複雑な動作を作り出すのかを理解することはできません。

0:46:31.630,0:46:35.820
だから本当に、ここでは自然な妥協点があります。それは、私たちが

0:46:38.099,0:46:41.479
写真を認識するような洗練された行動を

0:46:42.450,0:46:43.799
得ようとしているということです。

0:46:43.799,0:46:45.799
私たちが説明しきれないほど洗練された行動なので、

0:46:46.440,0:46:52.879
当然のことながら、それを行うために使用されているプロセスが記述可能であることを期待できないというのが自然な欠点です。

0:46:53.280,0:46:55.280
あなたがそれを理解することができるように。

0:46:56.549,0:47:00.799
そこで、これらの問題に対処するために私たちが推奨するのは、

0:47:01.650,0:47:05.839
非常に慎重な展開戦略で、この小さなグラフにまとめました。

0:47:07.200,0:47:08.880
このアイディアは

0:47:08.880,0:47:10.319
まず最初に、

0:47:10.319,0:47:16.609
モデルを何に使おうとしているにせよ、まず手動で行うことから始めてください。例えば、

0:47:17.339,0:47:19.339
パークレンジャーに熊を監視してもらいます。

0:47:19.740,0:47:24.349
その横でモデルを走らせて、パークレンジャーが熊を見るたびに、

0:47:24.480,0:47:29.839
モデルをチェックして、熊を探知したかどうかを確認します。モデルは何もしていません。

0:47:30.210,0:47:35.089
モデルを実行している人がいて、それが賢明な選択をしたかどうかを見ています。

0:47:36.240,0:47:40.879
一旦、限りなく現実に近い状況で

0:47:41.460,0:47:45.649
それが理にかなっていると確信したら、

0:47:47.599,0:47:52.159
次に時間と地理的に制限された方法で展開します。

0:47:52.160,0:47:57.379
カリフォルニア全体ではなく、一つのキャンプ場を選んで

0:47:57.900,0:48:00.019
それを一日だけやって、

0:48:00.720,0:48:08.299
誰かがそれを注意深く監視します。今回は基本的な熊の探知は熊探知機で行われていますが

0:48:08.299,0:48:13.399
まだ誰かが近くで注意深く監視しています。１つのキャンプ場で１日だけ。

0:48:13.400,0:48:15.440
そして

0:48:16.410,0:48:18.410
「よし、まだ会社を潰していない」

0:48:18.720,0:48:20.720
と言えるようなら

0:48:20.980,0:48:25.590
「2つのキャンプ場を1週間やってみましょう」、それから「マリン全体を1ヶ月間やってみましょう 」など。

0:48:26.200,0:48:29.189
これは、私が以前、

0:48:29.770,0:48:31.300
オプティマル・ディシジョンズという会社にいた時に

0:48:31.300,0:48:33.359
やっていたことです。

0:48:34.480,0:48:38.310
オプティマル・ディシジョンズという会社は私が保険の価格設定をするために 設立した会社です。

0:48:38.619,0:48:46.409
もしあなたが保険の価格を１～２％でも間違った方向に変えてしまうと

0:48:47.140,0:48:53.340
基本的には会社全体が潰れてしまいます。これは何度も起きています。

0:48:53.980,0:48:57.810
保険会社は価格を設定する会社です。それは、基本的には彼らが提供する商品です。

0:48:58.359,0:49:04.979
ですから、私たちがオプティマル・ディシジョンズで新しい価格を設定するときには、いつもこうしています。

0:49:04.980,0:49:08.070
5分間だけやってみたり、

0:49:08.590,0:49:12.779
名前がDで終わる人だけを対象にしたりと言った感じです。だから私たちは、うまくいけば、

0:49:13.900,0:49:17.010
かなり異なっていて、そしてあまり数の多くはないグループを

0:49:17.349,0:49:18.520
見つけようとします。

0:49:18.520,0:49:23.550
徐々に規模を拡大していきます。そして、このようなことをする際には、

0:49:23.550,0:49:25.550
本当に優れた

0:49:25.670,0:49:28.749
報告システムをたくさん導入して、

0:49:29.930,0:49:33.909
顧客が怒鳴っていないか、コンピュータが燃え尽きていないか、

0:49:35.210,0:49:37.210
コンピュータが燃え尽きていないか、

0:49:38.900,0:49:46.119
コストが暴騰していないか、などを認識できるようにしておく必要があります。

0:49:47.030,0:49:49.030
だからこそ、

0:49:49.130,0:49:51.130
優れた報告システムが必要なのです。

0:49:52.130,0:50:00.130
FastAIには、インクリメンタル・ラーニング（増分学習）すなわち、毎回1つのデータポイントを使って時間をかけてゆっくりとモデルを改善する方法が組み込まれているのでしょうか？

0:50:01.520,0:50:03.520
ええ、それは素晴らしい質問ですね。

0:50:04.190,0:50:07.029
これは、それとは少し違います。これは、

0:50:08.000,0:50:14.890
推論を行う際にモデルを訓練し続けることで、「ドメインシフト」や同様の問題に対処することについてで、

0:50:15.740,0:50:17.800
特別なものは必要ありません。

0:50:18.770,0:50:21.729
これは基本的には単なる伝達学習の問題です。

0:50:22.310,0:50:27.279
このように、さまざまな方法でこれを行うことができます。一番簡単なのはこう言うことです。毎晩...

0:50:28.640,0:50:32.019
おそらく一番簡単なのは、こう言うことです。

0:50:33.110,0:50:34.670
「いいですか、毎晩、

0:50:34.670,0:50:36.130
真夜中にタスクを開始します。

0:50:36.130,0:50:43.029
前日のすべての取引をミニバッチとして取り込み、もう一つエポックを訓練します。

0:50:43.970,0:50:45.530
それは、

0:50:45.530,0:50:50.290
実際にうまく機能します。基本的には、これを微調整のアプローチと

0:50:51.140,0:50:58.119
考えることができます 事前に訓練されたモデルが昨日のモデルで、微調整データが今日のデータです。

0:50:59.840,0:51:03.159
モデルを展開する際に、

0:51:04.580,0:51:11.409
非常に慎重に考えなければならないことの1つは、モデルの一部であるシステムの動作を影響する可能性があるということです。

0:51:11.930,0:51:18.130
これは「フィードバック・ループ」と呼ばれるものを生み出す可能性があります。「フィードバック・ループ」は、

0:51:19.430,0:51:22.840
実世界でのモデル展開、特に機械学習モデルにとって最も困難なことの1つです。

0:51:24.290,0:51:26.090
なぜなら

0:51:26.090,0:51:28.090
些細なことでも

0:51:28.460,0:51:30.460
大きな問題に

0:51:31.130,0:51:32.630
発展させてしまうからです。

0:51:32.630,0:51:35.140
例えば、

0:51:36.050,0:51:38.050
予測的な取り締まりアルゴリズムを考えてみましょう。

0:51:38.480,0:51:41.140
基本的にこのアルゴリズムは

0:51:43.400,0:51:48.010
どこで人が逮捕されているかというデータに基づいて訓練されたものです。

0:51:48.860,0:51:54.249
逮捕者が出た場所に基づいてアルゴリズムを訓練していくと、

0:51:55.940,0:52:02.890
モデルが犯罪の可能性が高いと判断した場所に

0:52:03.200,0:52:09.520
警察官を送るシステムを導入したことになります。この場合、逮捕が多い場所。

0:52:10.800,0:52:12.800
より多くの警察官がその場所に行くにつれ、

0:52:13.960,0:52:19.260
より多くの犯罪を見つけます。逮捕者が増えて、その結果、

0:52:20.020,0:52:23.880
今話したような段階的な学習をすれば、

0:52:23.880,0:52:28.589
「ここにはもっと犯罪があるんだ」ということになります。明日にはさらに多くの警察官が送られてくる。

0:52:29.410,0:52:36.149
その状況では、予測取り締まりアルゴリズムは、

0:52:36.730,0:52:38.560
ある通りのブロックに全ての警察官を送ることになります。

0:52:38.560,0:52:44.640
なぜならその時点ですべての逮捕はそこで起きているから。それは警察官がいるのはそこだけだから。

0:52:46.030,0:52:48.209
この問題についての「To predict and serve」という

0:52:49.300,0:52:57.029
論文があります。「To predict and serve」では、著者はこの素晴らしい言葉を書いています。

0:52:57.430,0:53:02.880
「Predictive policing というのは適切な名前で、それは犯罪を予測するのではなく

0:53:03.490,0:53:05.490
警察を予測することです。」

0:53:05.770,0:53:07.770
最初のモデルが完璧だったとして

0:53:08.910,0:53:13.969
(それが一体何を意味するかは知らないが)、実際に犯罪が起こる確率に基づいて

0:53:14.729,0:53:20.989
それがどうにかして犯罪を見つけるのに最適な場所に警察を送ったとします。

0:53:23.150,0:53:25.150
問題はないように思えますよね？

0:53:26.670,0:53:29.059
しかし、いくらかの偏りがあるとすぐに・・・

0:53:29.760,0:53:32.719
例えばアメリカでは、

0:53:33.690,0:53:35.690
黒人と白人が同じ程度で起こす犯罪でも、

0:53:36.870,0:53:43.880
白人よりも黒人の方が逮捕者数が多いんです。

0:53:45.100,0:53:47.100
このような偏見があると、

0:53:47.270,0:53:49.270
いえ、どんな偏見でも

0:53:49.880,0:53:57.190
時間の経過とともにその偏見を莫大させるドミノ連鎖の

0:53:57.830,0:54:01.750
フィードバックループを起こすのです。

0:54:02.360,0:54:03.590
ですから、

0:54:03.590,0:54:08.350
私が好きなことの一つは、「もしこのモデルが本当に、

0:54:09.410,0:54:12.729
本当に良いものだったらどうなるだろうか」ということを考えることです。

0:54:13.920,0:54:15.920
誰が影響を受けるか？

0:54:16.020,0:54:23.430
この極端な結果はどうなるのか？実際に何が起きているのかをどうやって知るんだ？

0:54:24.010,0:54:30.119
この信じられないほどの予測アルゴリズムが、あなたの警察官の行動を変えるようなものだったら、それはどのように見えるだろうか？実際に何が起こるのか？

0:54:32.230,0:54:36.000
そして、「何が問題になるのだろう」

0:54:36.000,0:54:40.289
「どのようなロールアウト計画があるのか？」、「どのような監視システムがあるのか？」

0:54:41.050,0:54:48.840
「どのような監視者が遮断器を提供できるのか？」と言ったことを考えます。それが本当に必要なものだからです。完璧なものは何もありません。
0:54:49.600,0:54:51.690
「フィードバックループ」がないことを確信することはできません。

0:54:52.330,0:54:59.010
あなたができることは、あなたのシステムがあなたが望まない方法で動作しているときに、

0:54:59.560,0:55:01.560
すぐに気づくことができるようにすることです。

0:55:01.750,0:55:03.809
レイチェル、何か付け加えることはありましたか？

0:55:06.010,0:55:10.229
私が付け加えたいのは、モデルが次のラウンドのデータがどのように変わるかを制御しているときはいつでも、

0:55:10.600,0:55:17.279
潜在的に「フィードバックループ」が発生する危険性があるということです。

0:55:17.410,0:55:19.410
これは、ほとんどすべての製品に当てはまることだと思います。

0:55:20.200,0:55:23.399
科学的なバックグラウンドを持っている人は、

0:55:23.470,0:55:28.139
データは「ある種の実験を観察した結果だ」と考えているかもしれません。

0:55:28.480,0:55:30.480
一方で現実世界と

0:55:30.480,0:55:32.480
相互作用するものを構築しているときはいつでも、

0:55:32.590,0:55:38.279
現在のデータに対するアルゴリズムの動作に基づいて、

0:55:38.410,0:55:40.410
将来のデータがどのようになるかを制御しています。

0:55:41.380,0:55:43.380
だから、

0:55:43.720,0:55:45.670
あなたはおそらく

0:55:45.670,0:55:47.819
「フィードバックループ」を避けることはできないでしょうが、

0:55:48.850,0:55:52.589
あなたが本当に投資する必要があるのは、

0:55:53.110,0:55:56.700
ループの中の人間です。多くの人が自動化に注目していますが、

0:55:57.340,0:56:03.329
私は不思議に思います。人間の関与を90％程度減らすことができれば、

0:56:03.760,0:56:09.299
完全に自動化した場合の経済的なメリットをほぼすべて得ることができ、そして人間ブレーカーを設置する余地はまだあります。

0:56:09.460,0:56:12.389
不服申し立てのプロセス

0:56:12.400,0:56:19.440
監視、人間が関与して「おい、それは変だ。

0:56:19.440,0:56:21.440
私たちが望んでいることではないと思う。」と言うのが必要です。

0:56:22.000,0:56:23.630
さて

0:56:23.630,0:56:30.040
はい、レイチェル。それについてもう一つ付け加えておきたいことがあります。これらの人間は、

0:56:30.680,0:56:36.909
製品部やエンジニアリング部とうまく統合する必要があります。多くの企業では、信頼・安全部門が

0:56:37.430,0:56:42.520
多くの種類の問題や、プラットフォームが悪用されたりするような問題に

0:56:42.650,0:56:45.010
対処、また処理していると思います。

0:56:45.380,0:56:49.210
しかし、多くの場合、信頼と安全の部門は、

0:56:49.400,0:56:55.240
実際に大きな影響のある決定権を持っている製品チームやエンジニアリングチームからかなり隔離されています。

0:56:55.240,0:56:56.900
エンジニアはたぶん、

0:56:56.900,0:57:02.170
彼らをかなり迷惑な存在だと思っていると思います。ソフトウェアのリリースの

0:57:02.170,0:57:07.300
邪魔になる存在だとか。そうですね、でも、その間の統合ができれば、

0:57:07.300,0:57:10.840
製品を作っている人たちが、実際に何がうまくいっていないのか、何がうまくいかないかもしれないのかを

0:57:11.060,0:57:15.219
見ることは役に立つと思います。そうですね。エンジニアが実際にその場にいて、

0:57:15.220,0:57:20.470
実際にこれらのことが起こっているのを見ていれば、それはもう抽象的な問題ではありません。

0:57:21.750,0:57:24.629
この時点で、第2章の最後まで来ているので、

0:57:26.560,0:57:31.169
他の人よりも多くのことを知っていると思います。

0:57:32.020,0:57:39.749
深層学習、そして一般的に機械学習の重要な基礎についても、そしてデータ製品についても。

0:57:40.570,0:57:42.570
ですから、今は文章を書いてみる

0:57:43.000,0:57:45.000
絶好の機会です。

0:57:45.640,0:57:47.640
ということで、

0:57:48.540,0:57:50.460
時々、

0:57:50.460,0:57:56.869
Jupyterノートブックの中でフォーマットされていない文章が出てくることがあります。本の中でしか正しくフォーマットされません。

0:57:56.869,0:58:00.108
このようなフォーマット済みのテキストを見ると、それが理由です。

0:58:03.450,0:58:05.450
だから...

0:58:05.760,0:58:08.399
ここでの考え方は、先に進みすぎる前に、

0:58:10.090,0:58:16.619
この時点で、書き始めることを考えるということです。レイチェル

0:58:18.460,0:58:20.970
質問があります。では質問を聞きましょう。

0:58:21.910,0:58:28.800
質問は「私は、毎晩更新された転送学習の設定を行う、fastAIならではの方法があると仮定します。

0:58:29.080,0:58:35.340
前の人が質問したように、毎晩の転送学習の訓練の例を持っている、FastAIのバージョン4のノートが公開される可能性がありますか？

0:58:36.400,0:58:41.369
私は、FastAIで最も効果的にそれを行う方法を知ることに興味がります。」

0:58:42.100,0:58:46.739
私の考えでは、FastAIには特別なことは何もありません。

0:58:47.290,0:58:53.159
だから、実際にはエマニュエルの本を読んで アイデアを理解することをお勧めします。

0:58:54.130,0:58:58.500
もし興味がある人がいたら、これについての学術的な研究を紹介しましょう。

0:58:58.500,0:59:00.869
それほど多くはありませんが、

0:59:01.450,0:59:03.750
いくつかはこの分野で良い研究があります。

0:59:06.640,0:59:08.640
では、

0:59:09.280,0:59:13.620
今の段階で文章を書くことに言及したのは、

0:59:15.569,0:59:20.159
物事はここからますます重くなり、どんどん複雑になっていくからです。

0:59:20.619,0:59:25.439
あなたがちゃんと理解しているか確認するための本当に良い方法は、あなたが学んだことを書き留めてみることです。

0:59:28.640,0:59:34.819
で、すみません、さっきは正しい画面を共有していなかったのですが、これが先ほど言っていたフォーマットされていないテキストです。

0:59:42.780,0:59:48.470
レイチェルはこの素晴らしい記事を書いていて、是非チェックしてください。「なぜブログを書くべきなのか」

0:59:49.170,0:59:54.140
彼女の代わりに私が言います。なぜなら私の目の前にあって、彼女には見えないからです。

0:59:54.840,0:59:56.960
妙な話ですが。レイチェルはこう言っています。

0:59:58.080,1:00:02.120
「若い自分に与えるであろうトップアドバイスは、早くブログを始めた方がいいということです。」

1:00:02.370,1:00:07.549
レイチェルは数学の博士号を持っていて、ブログを書くというアイデアは、

1:00:07.550,1:00:10.850
あまり多く博士課程で見られなかったと思います。

1:00:11.790,1:00:15.170
でも実際には、それは、仕事を見つけるための

1:00:16.320,1:00:22.400
本当に素晴らしい方法です。実際、最高の仕事を得た私の学生のほとんどは、

1:00:23.280,1:00:25.280
良いブログ記事を持っています。

1:00:25.530,1:00:27.590
私が本当に好きなことは、学ぶの手助けになるということです。

1:00:28.230,1:00:31.879
書き留めることによって、自分の考えをまとめることができます。

1:00:32.820,1:00:34.820
そして

1:00:36.030,1:00:39.620
ブログにはたくさんの理由があります。

1:00:40.680,1:00:43.279
本当にクールで見せたいものがあります。

1:00:44.250,1:00:49.220
続編の記事「より良いブログ記事を書くためのアドバイス」というのがあるんですが、

1:00:49.530,1:00:53.600
これはもう少し高度なもので、このリンクを貼っておきます。

1:00:53.970,1:00:54.840
これは、

1:00:54.840,1:00:56.280
私が多くのブログ記事で見てきた

1:00:56.280,1:01:02.150
共通の落とし穴について話しているもので、それをうまくやるために時間をかけることの重要性と、

1:01:02.250,1:01:05.960
考えるべきことが書かれています。だから、私もその記事も共有します。ありがとうレイチェル。

1:01:06.210,1:01:12.889
ブログを書かない人が時々いる理由の1つは、ブログの書き方を学ぶのが面倒だからです。

1:01:14.250,1:01:17.300
特に、多くの人がブログを書きたいと思うのは、

1:01:18.180,1:01:20.569
Jupyterノートブックで制作しているクールなもののことだと思います。

1:01:21.690,1:01:29.690
そこで、実際にHamel Husainという人とGitHubとチームを組んで、

1:01:30.330,1:01:32.070
この無料の製品を作りました。

1:01:32.070,1:01:38.749
いつものFastAIのように、広告も何もなく、「fastpages」と呼ばれるもので、

1:01:39.420,1:01:41.420
Jupyterノートブックを使って実際にブログを書くことができます。

1:01:43.270,1:01:46.199
自分で「fastpages」に行って、その方法を見てもらえば分かると思いますが、

1:01:46.200,1:01:50.639
基本的なアイディアは、文字通り1つのボタンをクリックすると、

1:01:52.500,1:01:55.649
ブログがセットアップされ、

1:01:56.590,1:01:57.790
ノートブックを

1:01:57.790,1:02:02.310
アンダースコアノートブックというフォルダに入れると、

1:02:03.160,1:02:09.240
ブログの記事に変換されます。それは... 基本的には魔法のようなもので、Hamelはこの素晴らしい仕事をしてくれました。

1:02:11.260,1:02:14.100
これはあなたがチャートや表、

1:02:14.680,1:02:21.840
画像、実際のJupyterノートブックの出力、

1:02:22.390,1:02:24.390
マークダウンでフォーマットされたテキストや見出しなど、

1:02:24.970,1:02:27.720
ハイパーリンクやすべてのものを持っているブログ記事を作成することができることを意味しています。

1:02:28.330,1:02:36.029
これは、ここで学んだことを書き始めるのに最適な方法です。

1:02:38.410,1:02:44.129
ブログをする事に対して、レイチェルと私の両方が強く感じるのはこれです。

1:02:47.150,1:02:54.319
あなたが知っている絶対的な最先端のことを考えて、ジェフ・ヒントンを感動させるようなブログ記事を

1:02:54.990,1:02:56.370
書こうとしないでください。でしょう?

1:02:56.370,1:02:58.789
ほとんどの人はジェフ・ヒントンではありません。

1:02:58.980,1:03:02.959
おそらく、(a) あなたよりも多くの専門知識を持っている人のためにブログを書こうとしているのだから、

1:03:02.959,1:03:07.290
いい仕事はできないでしょう。

1:03:07.290,1:03:08.670
そして (b)

1:03:08.670,1:03:11.270
この場合、読者が少ない。でしょう？

1:03:11.300,1:03:17.810
実際には、ディープラーニングに精通している人よりも、そうでない人の方がはるかに多いのです。だから、考えてみてください。

1:03:17.810,1:03:19.810
あなたは6ヶ月前のあなたを本当に理解しています。

1:03:20.340,1:03:24.559
なぜならあなたは実際6ヶ月前にそれを経験したからです。

1:03:24.560,1:03:30.350
６ヶ月前のあなたがとても面白いと思うような、

1:03:30.660,1:03:35.809
たくさんの小さな豆知識や、半年前のバージョンのあなたを喜ばせるような

1:03:36.630,1:03:39.289
物を書いてみてください。

1:03:40.680,1:03:48.349
もう一度言いますが、アンケートをするまでは先に進まないでください。あなたが理解する必要があると思われる重要なことを

1:03:50.100,1:03:53.660
理解していることを確認するためです。

1:03:54.300,1:04:01.519
そして、更なる研究課題についても考えてみてください。課題とより密接に関わることができるようになるかもしれないからです。

1:04:02.460,1:04:05.000
では、休憩を取りましょう。

1:04:05.910,1:04:07.910
5分後にまた開始します。

1:04:10.530,1:04:12.530
では、再開しましょう。

1:04:13.589,1:04:15.589
ここからが、

1:04:16.240,1:04:19.990
このコースの中で面白いパートです。というのも、

1:04:20.840,1:04:25.989
今まではずっと

1:04:27.329,1:04:32.879
私たちが機械学習でやろうとしていること、

1:04:32.890,1:04:35.699
機械学習を機能させる上で必要なピースや知識

1:04:37.260,1:04:44.790
について、ほぼ数学は使わずごくわずかのコードで説明してきました。

1:04:47.130,1:04:50.849
初めにこういった説明を行なったのは、

1:04:51.790,1:04:56.009
機械学習やそれに関する問題を理解したい人たちもターゲットにしているからです。

1:04:57.460,1:04:59.460
中には機械学習にでてくる

1:05:00.010,1:05:06.060
数式やコードに深入りすることなく理解したい人もいるでしょう。

1:05:07.330,1:05:09.330
もし今から話すことに

1:05:09.610,1:05:11.520
興味がなければ

1:05:11.520,1:05:18.270
倫理について話す次回のレッスンに進んだ方が良いかもしれません。次回は

1:05:19.570,1:05:22.080
あまり技術的ではないものになります。

1:05:25.460,1:05:27.880
今から見ていくのは

1:05:29.500,1:05:31.500
非常に単純な問題ですが

1:05:34.060,1:05:37.289
ほんの数年前までは困難と思われていたものです。

1:05:38.050,1:05:41.039
それは手書き数字認識です。

1:05:42.400,1:05:44.400
そして、私たちはこれから

1:05:44.510,1:05:46.039
スクラッチで解いていきます。

1:05:46.039,1:05:48.879
そのために色々な解法を見ていきます。

1:05:50.059,1:05:52.749
では、今からデータセットを見ます。

1:05:53.510,1:06:00.789
MNISTというデータセットですが、機械学習に触れたことがあれば使ったことがあるでしょう。

1:06:01.520,1:06:05.859
これは手書き数字の機械学習データセットでYann Lecunとその同僚が

1:06:06.589,1:06:10.899
作成し、彼らの提案手法を検証するのに使いました。

1:06:10.900,1:06:14.349
その方法はおそらく最初の非常に実用的で有用な計算機システムで、

1:06:14.779,1:06:20.679
さらにスケールするものであり、LeNetと呼ばれました。そして実際に

1:06:21.380,1:06:25.809
アメリカ合衆国で使われる小切手の1割を処理するのに使われました。

1:06:29.900,1:06:36.279
さて、新しいモデルを作るときに大事なのは非常に単純なものから始め、

1:06:36.559,1:06:38.559
徐々に複雑にしていくことです。

1:06:39.589,1:06:45.038
MNIST sampleというMNISTより簡単なものを用意してあります。3と7のみが含まれるデータセットです。

1:06:45.739,1:06:50.139
今回はこのMNIST sampleから始めましょう。

1:06:50.319,1:06:53.409
3と7は見た目がかなり違うので単純な問題です。

1:06:53.569,1:06:57.399
もしこの問題ができなければ手書き数字認識はできないと思います。

1:06:59.859,1:07:01.630
さて、

1:07:01.630,1:07:06.039
第一ステップはuntar_dataです。untar_dataはfastaiの

1:07:07.819,1:07:09.819
関数でURLを引数にとり、

1:07:11.480,1:07:17.379
ダウンロード済みか確認し、そうでなければダウンロード、その次に解凍済みか確認し、

1:07:17.380,1:07:22.089
もしまだなら解凍し、データセットのパスを返します。

1:07:22.609,1:07:24.609
ここに

1:07:27.200,1:07:34.210
URLs.MNIST_SAMPLEとありますね、tabを押すと自動補完がききます。

1:07:37.140,1:07:42.930
これは場所を表していて、どこにあるかはさほど重要ではありません。そして

1:07:45.460,1:07:51.580
私はすでにダウンロード・解凍済みなので非常にスムーズです。

1:07:52.190,1:07:54.280
そしてこのpathは

1:07:55.520,1:08:03.280
データがどこにあるかを示していて、今は”.”ですがこれはPath.BASE_PATHを

1:08:03.530,1:08:04.910
pathに設定することで

1:08:04.910,1:08:06.910
私が作業するパスの

1:08:07.790,1:08:11.169
開始地点を変えているからです。そして、

1:08:11.170,1:08:16.299
path.lsはそのパスにあるファイルを列挙します。そして、

1:08:17.180,1:08:22.209
列挙されたパスは解凍した場所からの相対パスなので非常に便利です。

1:08:30.759,1:08:34.589
さて、pathは、、、

1:08:35.979,1:08:41.639
pathの型はなんでしょう。実はPathlibのPathオブジェクトです。

1:08:44.229,1:08:50.819
Pathlibは標準ライブラリで大変素晴らしいのですが、lsは実装されていません。

1:08:52.059,1:08:56.458
非常に便利ですが、本当に使いたいものがなかったので、

1:08:56.459,1:08:59.429
実際にlsメソッドを追加しました。

1:09:05.639,1:09:08.059
もし、実装が気になったら、

1:09:08.759,1:09:11.209
すでに伝えてありますが、いくつか確認する方法があります。

1:09:11.210,1:09:15.290
?を付け加えれば、どこで実装されているかわかります。

1:09:15.290,1:09:22.849
fast coreにありますね。fast coreはfastaiの基本的なものが実装されていますが、

1:09:23.819,1:09:25.650
とくにPyTorchや

1:09:25.650,1:09:28.009
pandasなどの大規模なライブラリに依存していないものが含まれます。

1:09:29.940,1:09:34.549
実際に何をしているか知りたければ

1:09:34.549,1:09:36.549
?をもう1つ加えると

1:09:39.000,1:09:45.990
ソースコードが確認できますし、忘れないで欲しいのは、

1:09:47.720,1:09:49.720
doc関数です。

1:09:51.179,1:09:57.929
doc関数は実際のドキュメントへのリンクを表示し、そこにジャンプすれば

1:09:59.199,1:10:03.029
例やチュートリアルなども確認できます。

1:10:07.980,1:10:14.180
新しいデータセットを使う時はls関数で何が入っているか確認することをお勧めします。

1:10:14.990,1:10:20.240
そして、trainとvalidフォルダーがあります。非常に一般的なつくりです。

1:10:20.580,1:10:24.799
trainフォルダーをを見てみましょう。

1:10:25.320,1:10:28.700
7と3という名前のフォルダがありますね。

1:10:29.040,1:10:33.560
この構成は熊のデータセットとそっくりですね。

1:10:33.560,1:10:38.629
画像をそのラベルに対応するフォルダにダウンロードしています。

1:10:39.450,1:10:41.450
また、このラベルによる分類の前に

1:10:42.060,1:10:48.410
まず学習データかバリデーションかという分類が行われています。

1:10:49.170,1:10:53.960
画像のデータセットではこのフォルダ構成が一般的です。

1:10:57.290,1:10:59.290
ではどんな画像があるか見るために

1:10:59.700,1:11:03.859
threesというリストを用意して

1:11:04.410,1:11:09.349
3の学習データファイルを列挙し、並び替えます。

1:11:09.960,1:11:13.730
7についても同じことをし、3のデータを見てみましょう。

1:11:14.340,1:11:19.130
さて、threesから1つ選び、

1:11:20.790,1:11:28.009
ファイルを開いて描画してみましょう。3の画像ですね、実際にはなんでしょう？

1:11:31.000,1:11:34.089
im3の型は

1:11:35.570,1:11:42.399
PILで、これはPythonの画像ライブラリで、最も一般的なものです。

1:11:43.550,1:11:45.579
そしてPNGですね。

1:11:46.490,1:11:48.490
一般的ですね。

1:11:49.190,1:11:51.790
Jupyter Notebookは

1:11:53.780,1:11:55.340
様々なものを

1:11:55.340,1:11:59.980
描画する方法を知っていて、自分で型を作った場合にはPILにその描画方法を教えられます。

1:12:00.010,1:12:04.959
PILは一般的な型の描画方法を知っているので、このような画像を出力します。

1:12:05.990,1:12:11.019
しかし、今はこの画像が数字でどう表されるかを見ます。

1:12:11.660,1:12:16.599
画像を数字で扱う簡単な方法は、arrayに変換することです。

1:12:16.880,1:12:20.950
The array is part of numpy which is the most popular
arrayはnumpyの要素で、numpyは広く使われている

1:12:21.470,1:12:22.580
配列

1:12:22.580,1:12:24.350
プログラミングライブラリです。

1:12:24.350,1:12:27.100
もし、

1:12:28.670,1:12:29.750
PILの

1:12:29.750,1:12:31.750
image object to array
画像オブジェクトをarrayに渡すと

1:12:32.000,1:12:35.589
画像が多数の数値に変換されます。

1:12:35.590,1:12:40.810
実は画像もともと数字なのです。ディスクに保存された大量の数値です。

1:12:41.000,1:12:48.129
マジックのようなものがあり、Jupyterが描画できるだけなのですが、

1:12:48.770,1:12:50.720
arrayがPILオブジェクトをnumpy.arrayに変えていると表現しました。

1:12:50.720,1:12:56.050
numpy.arrayに変えると先ほどのように描画されなくなります。

1:12:56.240,1:12:59.530
so once I do this we can then index into that array and
一度numpy.arrayにすれば、要素へのアクセスが可能になり、

1:13:00.050,1:13:02.949
4から9行目の全要素を取得したり、

1:13:03.080,1:13:10.390
また、4から9列目の全要素を取得することもできます。ここにいくつかの数値がありますが、

1:13:11.000,1:13:12.890
これらは

1:13:12.890,1:13:14.090
8ビットの整数値で、

1:13:14.090,1:13:21.970
0から255を取り得るものです。計算機上の全ての画像は大量の数字であり、

1:13:22.520,1:13:24.350
だからこそ、それを使って

1:13:24.350,1:13:26.350
計算することができるのです。

1:13:26.880,1:13:31.909
要素のアクセス等は、arrayではなくtensorでもできます。tensorは

1:13:32.699,1:13:37.158
numpy.arrayのPyTorch版と言えるものです。

1:13:37.889,1:13:41.479
ですから、コードは上とほぼ同じ見た目をしています。

1:13:41.699,1:13:47.959
arrayをtensorに書き換えただけで全く同じことをしています。

1:13:47.960,1:13:53.899
PyTorchのtensorとnumpyのarrayがほぼ同じように動作することが

1:13:54.900,1:13:56.900
わかりますね。

1:13:57.210,1:14:02.330
一部例外はありますが、大事なことはPyTorchのtensorは

1:14:03.449,1:14:05.569
GPU上でも動くことです。

1:14:07.320,1:14:12.049
この講義と本では、

1:14:12.449,1:14:17.299
numpy.arrayではなく、PyTorchのtensorを使うようにしています。

1:14:17.520,1:14:23.209
というのも、numpy.arrayとGPU計算のメリットを使うことができる上に、

1:14:23.639,1:14:26.539
numpyにはない機能も多く取り揃えているからです。

1:14:27.990,1:14:29.990
Pythonを書いた経験がある

1:14:31.690,1:14:33.690
多くの人は常に

1:14:33.850,1:14:39.870
みなさんがPyTorchのTensorを使いたいと思うようにNumPyに飛びつきますが、

1:14:40.570,1:14:46.860
それはtensorやarrayを使うようにすることで多くのことが

1:14:46.860,1:14:48.860
簡単に、そして高速に行えるからです。

1:14:50.280,1:14:52.280
さて

1:14:52.449,1:14:58.379
先ほどの3の画像をtensorにしましょう。

1:14:58.380,1:15:02.699
im3_tがim3のtensorです。im3_tの一部を取り出し

1:15:03.280,1:15:09.210
pandas.DataFrameにしましょう。理由は

1:15:09.210,1:15:15.779
background gradientが非常に便利だからです。

1:15:16.000,1:15:21.329
3の画像の上の方が描画されていて、0が白、

1:15:22.000,1:15:27.779
255に近い数字が黒、中間の値が灰色です。

1:15:28.630,1:15:32.909
この描画で、

1:15:34.119,1:15:38.939
画像、数値の集合がスクリーンでどう描画されるかわかりますね。

1:15:40.679,1:15:48.538
実際の画像のごく一部を見せていますが、MNISTの画像は28x28、つまり768ピクセルです。

1:15:50.559,1:15:57.479
非常に小さいですね。例えば私の携帯電話が何メガピクセルか知りませんが何百万ピクセルです。

1:15:57.480,1:15:59.909
シンプルで小さいものから始めるのは大事です。

1:16:02.650,1:16:10.529
モデルを作るのが目標ですが、モデルはデータから学習した何かしらの計算プログラムで、

1:16:11.889,1:16:16.589
3と7を認識できるものです。3検知器と捉えても良いでしょう、なぜなら

1:16:16.590,1:16:18.809
3じゃなければ7と言えるのです。

1:16:20.110,1:16:24.089
ではここでビデオを一時停止して、

1:16:25.179,1:16:26.440
あなたならどうするかを考えてみてください。

1:16:26.440,1:16:30.089
How would you like you don't need to know anything about neural networks, or?
ニューラルネットワークについて知る必要なくするにはどうするでしょうか？

1:16:30.519,1:16:34.679
あるいは常識を使って3検出器を作るには

1:16:35.289,1:16:37.059
どうしますか？

1:16:37.059,1:16:40.919
必要であれば紙とペンを用意してください。

1:16:41.710,1:16:45.539
私の1つ目のアイデアは

1:16:47.079,1:16:49.079
データセットの3の画像

1:16:49.389,1:16:51.389
を全て取り出し、

1:16:51.880,1:16:53.880
各ピクセルの

1:16:54.039,1:16:56.248
平均値を求める

1:16:57.800,1:17:02.120
というものです。

1:17:02.120,1:17:04.189
つまり28x28の

1:17:05.970,1:17:07.170
画像で

1:17:07.170,1:17:11.510
各ピクセルは全部の3画像の平均ですから、理想的な

1:17:11.790,1:17:14.839
3になっています。7についても同じことを行い、

1:17:15.450,1:17:20.569
バリデーションセットに含まれる画像に対して、

1:17:21.270,1:17:27.979
この画像は理想的な3と7のどちらに似ているかに基づいて分類するのです。

1:17:28.980,1:17:33.140
ここではピクセル類似度法とでも呼びましょう。

1:17:33.600,1:17:39.109
これがベースラインです。ベースラインは非常に簡潔なモデルで

1:17:39.110,1:17:43.100
プログラムも簡単に書けるものであるべきです。

1:17:43.100,1:17:46.729
この方法は平均算出を行うだけですから簡単ですし、

1:17:47.790,1:17:52.490
ランダムよりは良くなるでしょう。

1:17:53.280,1:17:55.370
経験豊富な人でもし得る

1:17:55.950,1:18:03.859
大きな誤りの1つはベースラインを作らないというものです。

1:18:04.620,1:18:06.620
彼らは

1:18:09.239,1:18:12.539
ベイズ予測器やニューラルネットワークを作り

1:18:12.540,1:18:18.180
「Jeremy、素晴らしいモデルができました。」と言うのですが、私が「どうして素晴らしいと
わかるのですか？」と問うと、

1:18:18.180,1:18:21.389
「正確度が80%です」と言いますが、私は

1:18:21.700,1:18:25.529
「常に平均を予測に用いるモデルでどうなるか確認しましょう。おや、

1:18:26.110,1:18:28.110
85%ですね」と言えば、

1:18:29.170,1:18:30.340
当然、

1:18:30.340,1:18:34.860
彼らは大変落ち込むのです。なので、必ず、まともなベースラインから始め、

1:18:35.380,1:18:37.830
徐々に大きいものを作るようにしましょう。

1:18:39.040,1:18:41.040
私たちは、

1:18:41.050,1:18:43.050
ピクセルの平均値を計算する必要があります。

1:18:45.100,1:18:48.359
そのためにPythonのトリックをいくつか紹介します。

1:18:49.150,1:18:52.140
まず必要なのは3と7の画像の

1:18:52.750,1:18:56.430
リストです。

1:18:56.950,1:18:58.950
すでにsevensはありますが

1:19:00.650,1:19:03.230
要素はファイル名でした。

1:19:05.040,1:19:07.729
それぞれに対して、

1:19:07.800,1:19:15.020
Image.openでPILオブジェクトを取得し、tensorに変換しています。

1:19:15.270,1:19:18.199
これはリスト内包と呼ばれるものです。

1:19:18.360,1:19:23.179
これはPythonの中で最も強力かつ便利なものです。

1:19:23.640,1:19:29.299
C#のlinkの下位互換とも言えますし、

1:19:30.659,1:19:35.929
JavaScriptにおける関数型プログラミングのアイデアに似たものでもあります。

1:19:36.270,1:19:39.890
基本的には、この集合の各要素、

1:19:40.409,1:19:44.989
ここではoと呼ばれますが、それがこの関数に渡されます。

1:19:45.480,1:19:50.480
この関数は画像を開いてtensorに変換します。各要素に対応する関数の返り値がリストに格納されます。

1:19:50.480,1:19:52.480
ですから、このリストには

1:19:53.040,1:19:54.540
tensorとしての7の全画像が含まれます。

1:19:58.630,1:20:02.889
Silvyanと私はリストと辞書の内包を毎日使っています。

1:20:03.409,1:20:07.299
もしまだ慣れていなければ、少し時間をかけて使えるようにすべきです。

1:20:08.690,1:20:16.419
3をあらわすtensorのリストがあるので1つ取り出して

1:20:17.960,1:20:19.960
表示してみましょう。

1:20:20.040,1:20:23.779
tensorであって、PIL Imageオブジェクトではないので

1:20:24.719,1:20:26.719
Jupyterは描画できません。

1:20:28.230,1:20:30.230
ですからここでは

1:20:30.330,1:20:37.640
show_imageコマンドを使います。これはfastaiが提供するtensor描画コマンドです。

1:20:39.770,1:20:44.299
3の平均画像を求める必要があります。

1:20:45.060,1:20:47.060
平均を計算するためにまず、

1:20:47.130,1:20:51.230
tensorのリストをtensorにします。これはリストではなく、

1:20:52.110,1:20:54.140
tensorです。

1:20:55.080,1:20:56.880
今、

1:20:56.880,1:20:59.120
three_tensors[1]

1:21:02.830,1:21:04.490
の形（shape）は

1:21:05.630,1:21:13.600
(28, 28)です。行の数と列の数です。しかし、three_tensors自体は

1:21:17.609,1:21:19.079
リストです。

1:21:19.079,1:21:22.819
このままだと平均の計算は簡単ではありません。

1:21:22.919,1:21:28.819
そこで、私たちができることと言うと、28x28の画像を積み重ねて

1:21:29.820,1:21:35.149
画像からなる3次元の立方体にすることで、これもtensorです。

1:21:35.149,1:21:41.809
tensorは軸もしくは次元をいくらでも持てます。

1:21:42.570,1:21:45.649
torch.stackはtensorのリストを

1:21:46.379,1:21:48.559
tensorにし、今ここにあるように

1:21:49.109,1:21:51.169
stacked_threesのshapeは

1:21:51.719,1:21:54.378
(6131, 28, 28)です。

1:21:54.959,1:21:58.398
So it's kind of like a cube of height 6 1 31
これは直方体のようなもので、高さが6131、

1:22:00.840,1:22:02.840
底面が28x28になっています。

1:22:06.510,1:22:09.590
もう1つやりたいことは、平均を計算するために

1:22:10.170,1:22:12.120
このtensorを

1:22:12.120,1:22:13.739
浮動小数点に変換することです。

1:22:13.739,1:22:17.119
なぜなら、整数の丸め込みを避けたいからです。

1:22:18.000,1:22:22.100
もう1つ知っておくべき標準的なことは、

1:22:22.920,1:22:29.239
コンピュータビジョンで浮動小数点を扱う時は値が0から1であるということです。

1:22:29.699,1:22:34.039
なので、ピクセルの最大値である255で割っています。

1:22:34.560,1:22:37.759
ここまでが多くの画像をPyTorchで

1:22:38.610,1:22:41.960
表現するときの非常に標準的な作法です。

1:22:44.849,1:22:51.779
この3つはaxes（軸）と呼ばれ、左から第1軸、第2軸、第3軸です。

1:22:53.380,1:23:00.119
また、軸が3つあるのでランクが3のtensorとも言います。

1:23:01.150,1:23:04.230
これはランク2のtensorだったのです。

1:23:04.869,1:23:06.869
軸が2つなので。

1:23:08.090,1:23:15.279
tensorのランクはshapeの長さでわかります。

1:23:18.940,1:23:20.940
また、

1:23:21.180,1:23:24.300
私は軸（axes）と表現していますが、

1:23:25.090,1:23:27.150
次元と言うこともできます。

1:23:27.930,1:23:34.499
NumPyはaxes、PyTorchはdimを使っていると思います。ランクはまた、

1:23:36.169,1:23:38.169
次元の数でもあるので、ndimで取得できます。

1:23:40.140,1:23:47.209
ランクはtensorの軸あるいは次元の数であることと、

1:23:47.520,1:23:51.080
shapeはtensorの各軸のサイズであることを

1:23:52.820,1:23:54.820
しっかり覚えてください。

1:23:57.380,1:24:04.210
もう、stack_threes.mean()が使えます。stack_threes.mean()は

1:24:08.270,1:24:14.739
全てのピクセルの平均値を返しますが、

1:24:15.110,1:24:17.110
mean(0)とすれば

1:24:17.420,1:24:25.390
この軸に関する平均を計算します。つまり画像の平均です。

1:24:28.880,1:24:32.040
これは28x28です。なぜなら

1:24:32.890,1:24:36.390
6131の軸に関してreductionを行ったからです。

1:24:36.910,1:24:44.459
この軸に関してとった平均は描画することができるので、これが理想的な3、

1:24:46.600,1:24:48.959
こちらが同様にして得られた理想的な7です。

1:24:49.630,1:24:52.170
では、3の画像を1枚持ってきましょう。

1:24:52.780,1:24:56.759
1度描画したものと同じ画像です。

1:24:57.370,1:25:01.109
今から、この画像が理想的に3に近いのか、

1:25:01.360,1:25:07.860
もしくは7に近いのかを計算し、より似ている方をこの画像のラベルと予測します。

1:25:10.900,1:25:15.299
各ピクセルに関して

1:25:16.420,1:25:19.020
画像と理想的なものの差を

1:25:19.020,1:25:23.999
例えば、0、0、1、1、と言ったように、計算して平均をとることはできません。

1:25:24.070,1:25:29.100
その理由は、正の値も負の値もあるのでキャンセルされ、

1:25:29.950,1:25:34.049
0になり得るからです。各ピクセルの差は正の必要があります。

1:25:35.170,1:25:40.649
2つの方法があります。絶対値をとる、つまり

1:25:41.380,1:25:43.380
負の符号を無視し、

1:25:43.750,1:25:46.620
平均を計算する方法です。

1:25:47.440,1:25:51.660
平均絶対誤差やL1ノルムと呼ばれる方法です。

1:25:52.719,1:25:58.169
もう1つは二乗した誤差の

1:25:58.989,1:26:04.979
平均を求め、二乗根を計算する方法で

1:26:05.410,1:26:08.819
二乗平均平方根誤差やL2ノルムと呼ばれます。

1:26:10.930,1:26:14.610
So, let's have a look let's take a three
さて、3の画像を1つとり、

1:26:16.309,1:26:21.799
3の平均を引き、絶対値をとってから平均を計算したものを

1:26:22.800,1:26:24.659
dist_3_absとし、

1:26:24.659,1:26:28.009
すると、

1:26:28.739,1:26:34.788
その値は0.1です。これが平均絶対誤差、L1ノルムです。

1:26:35.369,1:26:39.918
もしL1を知らなければ、不思議なものに感じるかもしれませんが

1:26:40.649,1:26:44.088
必要な数学の用語や式というのはここにあるように

1:26:45.589,1:26:47.589
ごくわずかのコードで表せます。

1:26:48.770,1:26:51.560
ほら、数学的な要素に

1:26:52.080,1:26:54.890
うろたえているよりもコードを

1:26:54.890,1:27:00.079
見る方がどんなことをしているかわかりやすく、これを見て勉強したり

1:27:00.870,1:27:02.870
どう検索するか学べば良いのです。

1:27:03.060,1:27:09.289
こっちは二乗平均平方根誤差です。二乗してから平均をとり、平方根を計算しています。

1:27:11.100,1:27:16.160
これと同じことを理想的な7に対しても行います。

1:27:16.710,1:27:23.029
a3からmean3までの距離は絶対値だと0.1で

1:27:24.030,1:27:28.580
mean7までの距離は0.15です。

1:27:29.670,1:27:33.770
よって、a3はmean3の方が近いので

1:27:33.770,1:27:36.020
私たちはこのa3は

1:27:36.720,1:27:40.549
平均絶対誤差に基づいて3と推測するのです。

1:27:41.310,1:27:45.260
平均二乗誤差についても同様です。つまり、この値とこの値を比較して、

1:27:46.560,1:27:53.089
mean7との誤差が大きいので、3と推測します。

1:27:53.490,1:27:55.490
これは

1:27:56.350,1:28:02.169
機械学習あるいはデータドリブンなモデルのようなもので、3と7を認識しようとしています。

1:28:02.810,1:28:04.810
良いベースラインです。

1:28:05.510,1:28:09.099
妥当なベースラインです。ランダムより良いでしょう。

1:28:10.400,1:28:15.040
実は平均絶対誤差をこうして書き出す必要はありません。

1:28:16.310,1:28:21.550
l1_lossを使えば良いのです。l1_lossは全く同じことをします。

1:28:23.780,1:28:25.989
また、平均二乗誤差も書き出す必要はありません。

1:28:26.630,1:28:31.690
単にmse_lossを使えば良いのですが、デフォルトでは平方根を求めないので、追加しないといけません。

1:28:31.760,1:28:33.760
そして、このように

1:28:34.490,1:28:36.490
同じ数字です。

1:28:39.520,1:28:44.729
あまり先に進む前に、arrayやtensorの操作に慣れておくのは

1:28:45.460,1:28:49.469
非常に重要です。tensorとarrayはよく似ています。

1:28:50.020,1:28:55.080
リストのリストから始めましょう。行列のようなものです。

1:28:56.640,1:28:58.640
arrayにも

1:28:59.300,1:29:01.300
tensorにも変換できます。

1:29:02.300,1:29:04.300
表示もできます。

1:29:04.870,1:29:06.870
ほとんど同じですね。

1:29:07.090,1:29:09.090
1行だけアクセスしたり、

1:29:10.710,1:29:16.649
1列だけアクセスもできます。コロン（:）は

1:29:18.820,1:29:24.239
全ての行を意味します。なぜなら始めに書いたからです。もし2番目がコロンなら

1:29:24.910,1:29:27.569
全ての列を意味します。

1:29:30.430,1:29:34.530
この場合は取り除いても同じです。

1:29:36.970,1:29:38.970
最後のコロンは取り除くことが

1:29:39.380,1:29:43.210
できます。というのもそれが示唆されていますから。

1:29:43.210,1:29:49.509
こうする必要はありませんが、私自身はあえて書くこともあります。そうした方が、

1:29:50.030,1:29:52.030
どう対応していて

1:29:52.130,1:29:54.130
どうずれているかわかりやすいからです。

1:29:55.300,1:30:02.500
組み合わせることもできます。1行目の1列目から3列目までと行った感じで使えます。

1:30:07.200,1:30:15.200
足し算や型の確認もできます。この型はPythonの型とは異なります。

1:30:16.470,1:30:18.740
Right. So type is a function
Pythonのtypeは関数で

1:30:20.570,1:30:26.179
この場合の型はtensorですが、もしtensorの型が知りたい時はメソッドで、これはlongです。

1:30:28.650,1:30:31.969
floatを掛け合わせれば、float型になります。

1:30:31.980,1:30:35.750
もしこれまでにNumPyやPyTorchを使ったことがあまりなければ、

1:30:36.930,1:30:40.730
今が良い機会です。

1:30:42.079,1:30:48.139
いろんなことを試し、動かないと思うものも試してエラーメッセージをよく読んでください。

1:30:52.550,1:30:54.550
さて、今度はどれぐらい

1:30:55.460,1:30:57.730
このモデルが機能するかチェックしましょう。

1:30:58.400,1:31:02.619
私たちのモデルは受け取った画像を平均と

1:31:03.350,1:31:05.350
比べるものです。

1:31:12.230,1:31:17.080
すでに議論しましたが、学習データでだけでなく、

1:31:17.080,1:31:20.859
バリデーションセットでの性能を見るべきです。

1:31:21.409,1:31:27.039
validディレクトリにデータが入っています。さて、先に進む前に

1:31:27.040,1:31:29.709
バリデーションデータを用意しましょう。

1:31:30.590,1:31:31.969
3lsで取得できる

1:31:31.969,1:31:37.149
ファイルを開いて、tensorにして、stackして、浮動小数点にして、

1:31:37.790,1:31:39.770
255で割ります。

1:31:39.770,1:31:41.750
Okay

1:31:41.750,1:31:47.739
7についても同じです。必要な手順を数行にまとめました。

1:31:49.219,1:31:49.920
私は

1:31:49.920,1:31:53.119
ほぼいつもshapeをプリントするようにしています。

1:31:54.059,1:31:58.489
というのももしshapeが期待されたものでなければ変なことが起きているとわかるからです。

1:32:01.110,1:32:07.400
アイデアはis_threeという画像が3だと思ったらTrueを返す関数を定義することです。

1:32:09.239,1:32:12.558
実装するためには、

1:32:13.860,1:32:21.589
今見ている数字が理想的な3と7のどちらに近いかテストすることです。まずは

1:32:27.000,1:32:31.410
2つの画像の差の絶対値の平均を返すものを定義しましょう。

1:32:33.689,1:32:36.989
この関数はmnist_distanceとし、

1:32:37.659,1:32:40.558
2つの画像の差を計算し、

1:32:41.769,1:32:46.259
その絶対値をとり、平均を計算します。そしてこの関数にはすでに計算した平均画像をわたします。

1:32:46.260,1:32:50.010
今回は、平均を

1:32:54.960,1:33:02.279
後ろから2番目と3番目の軸で計算します。

1:33:03.850,1:33:10.799
つまり、x軸とy軸に関しての平均です。そして、これは、

1:33:11.290,1:33:16.979
a3とmean3の距離を返します。

1:33:17.380,1:33:19.589
そしてこの値は先ほど計算した値と

1:33:20.320,1:33:22.320
同じ0.114です。

1:33:24.500,1:33:30.580
さて、この計算をバリデーションセットの全画像に対して行います。メトリクスを計算するためです。

1:33:30.590,1:33:34.329
メトリクスとは、私たちのモデルがどれぐらい良いあるいは

1:33:35.420,1:33:39.309
ズレているかの指標です。mnist_distanceを

1:33:40.130,1:33:45.159
a3だけでなく、バリデーションセットの全データと

1:33:47.200,1:33:49.200
mean3に対して適用します。

1:33:49.910,1:33:55.910
これはすごいですね。普通のプログラミングで

1:33:56.670,1:34:03.710
行列あるいはランク3のtensorが入力でどちらでも動くものはありません。

1:34:04.890,1:34:09.079
ここでは1つの数字を返すのではなく、何が起きているのでしょう？

1:34:13.620,1:34:15.620
返り値は1010個の数字ですね。

1:34:15.660,1:34:17.970
これはブロードキャスティングのおかげです。

1:34:19.030,1:34:20.680
ブロードキャスティングは

1:34:20.680,1:34:25.680
とても特別な魔法のようなトリックで、

1:34:26.290,1:34:31.919
Pythonをとてもとても高速な言語にするものです。もしブロードキャスティングを

1:34:33.520,1:34:40.590
GPUのtensorに行うと、Pythonで書かれているのにGPUを使って計算されます。

1:34:42.490,1:34:44.490
このa - bを見てください。

1:34:45.850,1:34:47.850
- bを

1:34:48.050,1:34:53.949
valid_3_tensに行います。valid_3_tensは

1:34:56.220,1:35:01.229
約1000枚の画像で、mean3は

1:35:04.200,1:35:08.099
1枚の理想的な画像です。

1:35:10.180,1:35:12.180
このshapeのtensor -

1:35:13.000,1:35:14.680
このshapeのtensorは

1:35:15.760,1:35:20.130
ブロードキャスティングはこのshapeとこのshapeが一致しない時に

1:35:20.440,1:35:26.609
一致しているかのように対応する要素から引き算を行います。しかし、実際にshapeが

1:35:27.160,1:35:31.800
一致しているわけではないのに1010個のmean3があるかのように

1:35:32.410,1:35:34.410
振舞います。

1:35:34.420,1:35:40.409
つまり、各画像データからmean3を引きます。

1:35:42.970,1:35:45.659
ブロードキャスティングの例を見ていきましょう。

1:35:47.230,1:35:50.489
理解するには要素毎の演算を知る必要が

1:35:51.010,1:35:52.420
あります。

1:35:52.420,1:35:58.049
要素毎の演算とは、このようなものです。ここにランク1で要素数3のtensorが

1:35:58.480,1:36:03.029
2つあります。shapeが全く同じです。

1:36:03.840,1:36:10.679
1, 2, 3と2, 1, 1の要素和は2, 3, 4となります。単純に

1:36:11.140,1:36:15.810
対応する要素を足し合わせるだけです。

1:36:19.110,1:36:20.940
では

1:36:20.940,1:36:23.060
shapeが異なる

1:36:25.440,1:36:27.440
場合はというと、

1:36:28.890,1:36:31.970
基本的にこの数字を

1:36:32.700,1:36:38.329
1010書いコピーし、valid_3_tensから1010個のmean3のコピーの

1:36:38.700,1:36:42.649
引き算を行います。

1:36:47.100,1:36:51.209
実際にはmean3を1010回もコピーすることなく、

1:36:51.210,1:36:52.300
そのように振舞うだけです。

1:36:52.300,1:36:57.749
実際には何回も何回もループしているかのように振舞い、

1:36:57.750,1:37:01.050
こういった演算はCやCUDAで実装されます。

1:37:03.610,1:37:07.989
さて、少し戻って絶対値を見ましょう。

1:37:09.950,1:37:14.950
さて、absolute valueの関数をshapeが(1010, 28, 28)のtensorに適用すると

1:37:17.219,1:37:19.219
何が起きるのでしょうか？

1:37:21.260,1:37:26.110
各要素にabsが適用されますね。

1:37:28.040,1:37:32.019
最後にmean呼びますが、

1:37:33.140,1:37:37.479
-1は最後の軸、-2は最後から2番目の軸に対して作用します。

1:37:37.690,1:37:41.289
ですのでmean((-1, -2))は最後の2つの軸の平均をとります。

1:37:41.290,1:37:47.560
ですので最初の軸に関して返します。なので最終結果は1010個は

1:37:48.410,1:37:50.650
1010個の画像と理想画像の

1:37:51.380,1:37:53.230
差を表していて、今欲しいものです。

1:38:03.820,1:38:09.690
さて、この関数を使えばis_three関数も作れます。まず、

1:38:10.510,1:38:14.400
問題の数字画像を受け取り、それと理想的な3画像との距離を求め、

1:38:14.830,1:38:19.350
理想的な7の画像との距離より小さければ、

1:38:20.050,1:38:26.759
3、yesと予測するのです。

1:38:27.699,1:38:32.339
そして、それをfloatに変換、つまりyesなら1を返します。

1:38:35.230,1:38:37.699
これをバリデーションセット全体に行います。

1:38:39.179,1:38:42.469
Set right. So this is so cool. We basically get rid of loops
イケてますね。私たちは基本的にloopなしで、

1:38:43.260,1:38:49.670
In in in in this kind of programming you should have very few very very few. Loops. Loops make things
プログラムしました。loopはプログラムの

1:38:50.580,1:38:52.469
much harder to read
可読性を損ねますし、

1:38:52.469,1:38:53.940
さらに

1:38:53.940,1:38:58.580
GPUの有効活用を妨げプログラムを何十万倍も遅くします。

1:38:59.969,1:39:02.389
is_threeをvalid_three_tensに

1:39:03.390,1:39:07.129
適用し、floatに変換し、平均を取れば、

1:39:07.320,1:39:14.179
3の正確度になりますし、7の正確度は1 - 3の正確度です。

1:39:15.000,1:39:18.589
そして3の正確度は91%強で、

1:39:18.690,1:39:24.679
7に関しては98%、それらの平均は95%です。

1:39:25.230,1:39:27.350
ここで私たちは

1:39:28.140,1:39:32.449
95%の精度を誇る3と7を認識するモデルを作りました。

1:39:33.510,1:39:35.510
このように

1:39:36.090,1:39:38.239
簡単な計算だけでこのモデルができるというのは

1:39:39.570,1:39:44.659
驚きでしょうが、これが良いベースラインというものです。

1:39:47.440,1:39:49.440
さて、問題は

1:39:51.150,1:39:57.889
これを改善する方法が自明ではないことです。問題はこの方法がアーサー・サミュエルの言う

1:39:59.130,1:40:01.190
機械学習とは

1:40:01.860,1:40:07.130
Machine learning. This is not something where there's a function which has some parameters
異なることです。彼の表現ではパラメータを受け取る関数があり、

1:40:07.950,1:40:09.870
私たちが、

1:40:09.870,1:40:14.750
適合性の指標に基づいて評価し、その値に基づき繰り返しパラメータを改善するのです。

1:40:15.000,1:40:17.029
ですが、今作った方法は1ステップで、

1:40:18.030,1:40:20.030
十分でした。

1:40:21.360,1:40:27.380
今から取り組む方法では、重みの割り当てを評価する方法を用意し、

1:40:27.510,1:40:33.500
私はパラメータの割り当てと言いますが、

1:40:33.690,1:40:36.199
パフォーマンスを最大化するような重み割り当てを自動で行います。

1:40:36.870,1:40:42.140
この方法に取り組みたいのですが、何せ、第一章、初回レッスンからこの方法を知っているのですから、

1:40:42.170,1:40:45.049
しかし、そうするには、

1:40:45.930,1:40:47.640
マジックボックスのようなもの、

1:40:47.640,1:40:53.690
機械学習があり、ニューラルネットを使います。

1:40:54.510,1:40:56.510
理論的にはニューラルネットは

1:40:57.630,1:40:59.940
良い重みの組み合わせが見つかればどんな問題も解けます。

1:41:00.940,1:41:04.830
そして、重みを改善する方法が必要です。

1:41:08.110,1:41:10.110
では、

1:41:11.250,1:41:13.250
パラメータをとる関数を考えましょう。

1:41:13.840,1:41:21.090
理想的な画像を見つけたりある画像がその理想的なものからどれぐら離れているかを見たり、

1:41:26.920,1:41:33.839
ある画像が理想的なものとどれくらい違うかを計算する代わりに

1:41:34.210,1:41:36.210
できることは、各ピクセルに

1:41:36.910,1:41:38.080
対応する重みを用意し、

1:41:38.080,1:41:41.760
3の画像のピクセルが値を持つような

1:41:42.100,1:41:47.850
場所により重みを割り当てると言ったものです。

1:41:47.860,1:41:52.650
そうすれば、もしそのようなピクセルに値があったときに

1:41:53.170,1:41:57.390
よりスコアを与えることができ、それ以外の場所には

1:41:57.880,1:42:05.069
低いスコアを与えることで、最終的に何らかの確率が計算できる関数になりますね。

1:42:05.920,1:42:07.920
ここでは画像が8ピクセルとして、

1:42:07.990,1:42:12.359
そのピクセルと

1:42:13.330,1:42:19.919
何かしらの重みと掛けてから足し合わせますを計算します。

1:42:22.750,1:42:24.750
今見ている画像の

1:42:26.540,1:42:28.540
大きい重みが多ければ多いほど

1:42:29.130,1:42:35.960
確率は高くなります。今予測したい画像をXとします。

1:42:36.900,1:42:39.770
Xをベクトルで表します。

1:42:39.770,1:42:44.450
ただ全ての行をつなぎ合わせ、1つの長い行にするだけです。

1:42:46.830,1:42:52.910
今から取り組む方法では重みWから始めます。Wはベクトルで

1:42:52.910,1:42:59.329
ランク1のtensorです。ベクトルWの初期値は、

1:43:00.420,1:43:01.770
乱数に

1:43:01.770,1:43:08.629
すると良いでしょう。

1:43:11.670,1:43:15.830
そして、数字が3に見えるか7に見えるかを

1:43:16.890,1:43:18.720
この簡単な

1:43:18.720,1:43:20.100
関数で

1:43:20.100,1:43:21.570
予測します。

1:43:21.570,1:43:26.060
それから、このモデルがどれくらい正確かを

1:43:26.670,1:43:30.260
どの程度正しく予測できているかという感じで計算します。

1:43:31.350,1:43:33.350
これが損失です。

1:43:34.559,1:43:37.829
そして大事なステップは、勾配の計算です。

1:43:37.829,1:43:42.478
勾配は各重みをほんの少し動かした時に

1:43:43.449,1:43:49.438
損失が大きくなるか小さくなるかを尺測るもので、

1:43:49.439,1:43:51.479
全ての重みに対して計算します。

1:43:51.669,1:43:56.309
そうすると、全ての重みに対して、それを大きくするか小さくするかを決められます。

1:43:57.800,1:44:05.270
これを勾配と言います。勾配が得られたら、stepです。これは全ての重みを

1:44:05.790,1:44:07.790
更新することで、

1:44:09.070,1:44:11.349
勾配に基づいて小さくしたり大きくしたりします。

1:44:17.750,1:44:22.239
更新されるとほんの少し改善されて、ステップ2に戻ります。

1:44:23.119,1:44:25.869
再び式に基づいて予測を計算し、

1:44:27.770,1:44:29.550
勾配を計算し

1:44:29.550,1:44:31.230
重みを更新します。

1:44:31.230,1:44:32.060
この繰り返しです。

1:44:32.060,1:44:37.700
これが基本的なフローチャートで、待ちくたびれるか、損失が十分改善されたら

1:44:37.860,1:44:39.860
訓練を止めます。

1:44:40.800,1:44:48.260
So these seven steps 1 2 3 4 5 6 7
7つのステップですね。

1:44:51.899,1:44:56.239
この7つのステップ、深層学習モデルの訓練の鍵となるのは確率的勾配降下法です。

1:44:56.689,1:45:00.499
いまのは、勾配降下法で、確率的勾配降下法はあとで見ます。

1:45:01.829,1:45:03.749
これらの7つのステップはそれぞれ

1:45:03.749,1:45:08.749
どう実行するかの選択肢が多々ありますね？

1:45:08.749,1:45:11.179
これらのうち、多くのものはここでは置いておきます。

1:45:11.550,1:45:17.209
例えばランダム初期化や実際に勾配を計算する方法や勾配に基づいてどう更新するか、そして

1:45:17.209,1:45:19.459
どうやって訓練を止めるかを決める方法などです。

1:45:20.129,1:45:24.889
このコースではこれらのステップについて勉強しますが、

1:45:25.679,1:45:28.038
これあはパート1みたいなもので、

1:45:29.550,1:45:35.449
もう1つの大きなパートはニューラルネットワークがどういった関数であるかというものです。

1:45:35.449,1:45:37.998
どうやって訓練して、訓練しているものは何かといった感じです。

1:45:39.179,1:45:41.929
さて、パラメータを乱数で初期化し

1:45:42.419,1:45:45.259
損失関数となる関数が必要です。

1:45:45.539,1:45:50.088
損失関数はモデルが良ければ小さい値を返します。

1:45:51.719,1:45:56.058
何らかの方法で重みを増やすか減らすか決めます。

1:45:58.780,1:46:03.309
そして、いつ訓練を止めるか、つまり、いつ十分なエポック数学習したと言うかを決める必要があります。

1:46:06.780,1:46:08.550
So, let's like
さて、

1:46:08.550,1:46:14.179
もっとシンプルに行きましょう。MNISTも使いません。まずはxの二乗を計算する関数で始めます。

1:46:14.730,1:46:20.839
fastaiはplot_functionという関数があり、これは与えられた関数

1:46:25.610,1:46:27.610
fを描画します。

1:46:27.809,1:46:34.619
この図が損失関数ですが、今から

1:46:35.139,1:46:36.489
この底を見つけようとします。

1:46:36.489,1:46:37.139
さて、

1:46:37.139,1:46:41.279
今からするのは損失関数を最小にするxの値を見つけることで、

1:46:41.469,1:46:46.259
7つのステップは初期化するところから始まりますので、

1:46:47.859,1:46:49.719
1つ値を決める必要があります。

1:46:49.719,1:46:55.469
ここでは-1.5から始めます。

1:46:56.769,1:47:04.349
次に調べるべきはxを少し大きくしたら、損失関数の値は

1:47:04.349,1:47:07.049
良くなる、つまり小さくなるか、悪くなるかです。

1:47:09.270,1:47:15.450
これは非常に簡単でxを少しずらしてどうなるか確認すれば十分です。

1:47:15.450,1:47:19.109
そして、この情報はその地点における傾きがわかれば

1:47:19.960,1:47:23.760
得られます。

1:47:30.489,1:47:38.158
傾きの方向に重みを変更すれば損失は良くなります。

1:47:38.650,1:47:43.739
これがこの地点における傾きでこれが新しいxの値です。

1:47:44.349,1:47:46.949
これを何度も繰り返せば

1:47:47.860,1:47:49.860
この曲線の底にたどり着きます。

1:47:52.989,1:48:00.718
これはニュートンが考えたものでニュートン法といいます。

1:48:02.560,1:48:04.709
ですので私たちが行う必要があるのは

1:48:06.100,1:48:08.100
傾きの計算です。

1:48:09.250,1:48:12.959
微積分が必要という悪い知らせですが、

1:48:14.320,1:48:19.230
というのも私は微積分が嫌いですから。

1:48:20.170,1:48:22.170
良い知らせは

1:48:23.380,1:48:27.060
すでに導関数の求め方の勉強に時間を費やしているかもしれませんが、

1:48:27.940,1:48:34.859
計算機が高速で計算してくれるということです。

1:48:35.710,1:48:39.149
計算機はあなたが勉強した方法とそれ以外にも賢いトリックを

1:48:39.550,1:48:43.170
使って勾配計算を高速化しています。

1:48:43.750,1:48:51.299
高校数学を覚えているか知りませんが、x二乗の導関数は2xです。

1:48:53.320,1:48:57.000
これは先ほど言及したトリックの1つで

1:48:58.150,1:49:01.109
PyTorchは

1:49:01.900,1:49:06.509
導関数から勾配を計算するエンジンを積んでいます。

1:49:07.360,1:49:09.360
さて、これを使うために

1:49:10.050,1:49:12.050
tensorを使います。

1:49:14.440,1:49:17.489
そして、今回はこのtensorを更新するために

1:49:18.520,1:49:25.469
requires_grad_メソッドを呼びます。このメソッドはPyTorchに、tensor xtを使って

1:49:25.780,1:49:27.610
計算するときは

1:49:27.610,1:49:31.889
どんな計算をしたか覚えておき、あとで導関数を使えるようにしろと伝えます。

1:49:33.740,1:49:35.740
You see the underscore at the end and
末尾のアンダースコア（_）は

1:49:36.890,1:49:43.539
PyTorchではin-placeであることを示します。

1:49:44.180,1:49:47.200
このrequires_grad_は

1:49:47.870,1:49:52.870
私たちがxtの勾配を必要としていることをPyTorchに伝えます。

1:49:52.940,1:49:56.800
それはつまり、xtに対して行う計算全ての履歴を保存することになります。

1:49:57.050,1:49:59.169
こうすると導関数をあとで計算できます。

1:50:02.969,1:50:06.198
さて、要素が3のtensorを作りました。

1:50:07.230,1:50:13.459
関数fを適用します。fはただ二乗するもので、3の二乗は9ですね。

1:50:14.429,1:50:16.040
しかし結果はただの9ではなく

1:50:16.040,1:50:22.759
9と勾配を計算する関数で、二乗が適用されたことを示します。

1:50:23.280,1:50:25.400
ここまでくると

1:50:26.849,1:50:28.730
backwardを呼べて、

1:50:28.730,1:50:30.730
backwardは

1:50:32.150,1:50:36.109
あとで勉強しますが基本的には導関数と

1:50:37.350,1:50:42.870
requires_grad_を呼んだ、xtの値に基づいて

1:50:43.510,1:50:45.510
その勾配を求めます。

1:50:46.240,1:50:48.840
xの二乗の導関数は2xですね、

1:50:50.719,1:50:52.719
今回xは3だったので、

1:50:53.540,1:50:55.110
勾配は6ですね。

1:50:57.420,1:51:04.940
導関数を求める必要はありません。ただbackwardと.gradを呼べば勾配が得られます。

1:51:05.670,1:51:10.129
PyTorchで微分するのはこんなに簡単なのです。

1:51:11.910,1:51:17.030
ですから微積分について知っておくべきはどのように導関数を求めるかではなく

1:51:17.670,1:51:20.960
何を意味するかで、それは

1:51:21.720,1:51:23.670
ある点における

1:51:23.670,1:51:25.670
傾きです。

1:51:27.479,1:51:29.249
少し面白いことをしてみましょう。

1:51:29.249,1:51:32.699
3だけではなく、ランク1のtensor、

1:51:33.460,1:51:35.410
ベクトルを用意し

1:51:35.410,1:51:37.410
(3, 4, 10)で初期化し

1:51:37.780,1:51:39.760
sum()を

1:51:39.760,1:51:42.959
関数fに加えましょう。

1:51:43.630,1:51:46.200
そして、f(xt)を計算すると

1:51:48.199,1:51:50.598
125になります。

1:51:51.860,1:51:59.150
backward()を呼ぶと、勾配は(2x, 2x, 2x)です。

1:52:00.500,1:52:02.500
つまり私たちは

1:52:03.660,1:52:08.569
ベクトル微積分ができるのです。私たちはここで

1:52:09.390,1:52:10.920
ベクトルの

1:52:10.920,1:52:15.649
各要素の勾配を全く同じコードで求めました。

1:52:18.750,1:52:23.279
これが微積分について知っておくべき全てです。

1:52:24.940,1:52:29.279
もしこの傾きという考えに馴染みがなければ、

1:52:29.800,1:52:32.190
Khan Academyをお勧めします。

1:52:32.230,1:52:37.919
入門的なコースがありますし、あなたたちは実際に微分を手で求める部分は

1:52:38.770,1:52:40.770
飛ばして良いのです。

1:52:41.830,1:52:48.220
さて、もう勾配、つまり関数の傾きが計算できる、つまり、関数への入力を

1:52:48.800,1:52:50.800
少し変えたら

1:52:51.350,1:52:53.350
その関数の出力がどう変わるかわかります。

1:52:53.870,1:52:55.990
Correspondingly, that's what a slope is
これが傾きの意味です。

1:52:56.510,1:53:04.389
もし勾配が得られたら、そこにある全てのパラメータを

1:53:04.390,1:53:10.839
どう更新したら損失がどれくらい変わるかわかります。よってパラメータをどう変えるべきかわかります。

1:53:12.080,1:53:17.289
私たちがすべきは、重みwの各要素から

1:53:18.140,1:53:21.579
何か小さい係数を掛け合わせた

1:53:22.610,1:53:24.320
勾配を

1:53:24.320,1:53:29.169
引くことです。この小さい係数はだいたい

1:53:29.630,1:53:32.740
0.001から1ぐらいで学習率と呼ばれます。

1:53:33.500,1:53:37.570
そしてこれこそが勾配降下法の

1:53:38.540,1:53:40.540
肝です。

1:53:40.820,1:53:43.719
もし学習率が小さすぎると

1:53:44.269,1:53:47.739
傾きの方向にほんの少しだけ移動し、

1:53:47.899,1:53:52.239
それを繰り返します。この調子だといつまで経っても、ゴール、つまり損失関数の

1:53:52.849,1:53:54.439
底に着きません。

1:53:54.439,1:53:56.439
逆に学習率が大きすぎると、

1:53:57.409,1:53:59.409
遠くに行きすぎるので

1:54:00.289,1:54:02.889
それを繰り返してたとしても、先ほど同様に終わらないでしょうし、

1:54:05.429,1:54:11.129
この場合では、ここから始まるので、むしろ悪化します。

1:54:13.780,1:54:16.659
また、ここからこれぐらいの学習率で始めると

1:54:17.300,1:54:20.920
毎回悪化します。ただ長い時間をかけて行ったり来たりします。

1:54:21.739,1:54:23.690
ですから、

1:54:23.690,1:54:30.250
妥当な学習率を選択するというのは問題を解く上でも、現実的な時間で問題を解く

1:54:30.590,1:54:33.279
上でも非常に重要です。

1:54:33.469,1:54:37.808
ですからこのコースで学習率の選び方も教えます。

1:54:41.780,1:54:43.070
では

1:54:43.070,1:54:47.139
この方法を試しましょう。勾配降下法も試しましょう。

1:54:48.010,1:54:53.380
確率的勾配降下法と言いましたが厳密には間違いです。この問題を解くには勾配降下法を使います。

1:54:54.650,1:55:00.039
今から扱う問題のイメージは、こんな感じです。あなたはジェットコースターを見ているとします。

1:55:00.650,1:55:05.949
てっぺんから反対側のてっぺんに向かって進むとき

1:55:06.499,1:55:10.629
始めは徐々にスピードを上げていきますが、

1:55:11.059,1:55:14.859
上りでは徐々にスピードを失っていきます。

1:55:15.260,1:55:17.590
頂上についたらまた下りはじめ、スピードを付けていきます。

1:55:17.599,1:55:22.808
もしスピードメーターやストップウォッチのようなもので

1:55:23.059,1:55:25.599
等間隔で

1:55:26.329,1:55:32.109
測定したらこのようなものが得られますね。

1:55:32.110,1:55:36.099
And so the way I did this was I just grabbed a range just grabs
この関数の作り方は、まずarange関数で

1:55:36.679,1:55:43.748
The numbers from naught up to but not including 20, right? So these are the time periods at which I'm taking my speed measurement and
0から20までの整数を取得し、これが時間ですね、

1:55:44.599,1:55:46.599
Then I've just got some
それから、

1:55:47.479,1:55:52.929
時刻から9.5を引いた後に二乗し0.75倍したものに定数項1と

1:55:52.929,1:55:56.438
乱数の三倍を足しています。

1:56:07.070,1:56:10.449
その結果、少し凸凹の二次関数が得られました。

1:56:10.639,1:56:14.768
でこぼこのおかげで少し現実的になっています。なぜならスピードメータによる

1:56:15.289,1:56:17.469
計測は不完全ですから。

1:56:20.659,1:56:22.659
では、次は

1:56:22.789,1:56:27.728
どんな時間でも何かしら推測する関数を用意します。ジェットコースターの速度はなんでしょう。

1:56:28.519,1:56:30.519
いつも、

1:56:30.769,1:56:33.849
どんな関数が存在するか予測することから始まります。

1:56:33.849,1:56:40.899
We guess that it's a function a times x squared plus B times time plus C
私たちは、その関数はtの二乗＋B t + Cのようなものと考えました。

1:56:40.969,1:56:43.419
You might remember from school is quite a quadratic
これは二次関数の一般的な形ですね。

1:56:44.090,1:56:47.799
So let's create a function, right? And so
では、関数を作りましょう。

1:56:49.010,1:56:54.070
Let's create it using kind of the Alpha Samuels technique the machine learning technique. This function is going to take two things
アーサー・サミュエルの機械学習のテクニックを使って関数を作りましょう。この関数は

1:56:54.409,1:56:56.409
It's going to take an input
入力、ここでは時間

1:56:56.599,1:56:58.599
そして、

1:56:58.760,1:57:00.760
いくつかのパラメータ、

1:57:01.850,1:57:05.149
a, b, cを受け取ります。

1:57:05.670,1:57:12.410
Pythonではリストなどからこのように要素を取り出せます。

1:57:16.100,1:57:18.890
ここでは、どんな関数に対しても、私たちは

1:57:19.920,1:57:22.790
a, b, cを見つけることで二次関数を適合させようとしています。

1:57:23.880,1:57:27.680
アーサー・サミュエルにならえば、

1:57:27.990,1:57:35.030
次にするべきは、関数の予測がどの程度優れているかを測る損失関数を

1:57:36.000,1:57:38.000
決めることです。

1:57:38.460,1:57:41.960
このとき、目標は実際の値で、

1:57:42.750,1:57:44.750
ここでは、

1:57:46.320,1:57:52.939
平均二乗誤差を使います。

1:57:54.530,1:57:57.310
準備ができたので7つのステップを実行します。

1:57:57.679,1:58:03.549
できる限り良いa, b, cのを見つけるたいのですが、

1:58:03.800,1:58:07.509
まずa, b, cを初期化する必要があります。

1:58:07.880,1:58:13.599
これがPyTorchで乱数を取得する方法です。ここからパラメータを調整していきます。

1:58:13.599,1:58:15.969
ですのでPyTorchに勾配を計算するよう伝えなければなりません。

1:58:19.950,1:58:26.490
そして、この初期値をあとで確認するために保存しておきます。そして、関数fを使って予測値を計算します。

1:58:27.370,1:58:29.370
fはこれです。

1:58:31.650,1:58:35.000
それから、その時点での予測値がどの程度かを可視化する

1:58:35.520,1:58:37.760
関数も作ります。

1:58:38.010,1:58:44.539
この関数は予測を赤、正解を青でプロットします。

1:58:44.700,1:58:46.700
ボロボロですね。

1:58:48.520,1:58:50.520
そして損失を

1:58:51.670,1:58:53.670
この関数で求めます。

1:58:54.050,1:59:01.160
パラメータを更新するために、backwardメソッドを呼び、gradを取得する2ステップで勾配を計算します。

1:59:01.710,1:59:03.710
この結果はパラメータが

1:59:04.620,1:59:06.859
負の勾配を持っているということです。

1:59:09.660,1:59:15.829
学習率を10の-5乗とし、この勾配それぞれに学習率をかけて

1:59:19.019,1:59:25.699
重みを更新、つまり、現時点での重み - 学習率 x 勾配

1:59:26.519,1:59:28.519
を実行します。

1:59:28.980,1:59:31.020
ここではdata attributeを使っていますが

1:59:32.020,1:59:36.330
これは、PyTorchにおいて、dataに対する計算は

1:59:38.980,1:59:44.399
勾配を計算しなくなるからです。重み更新に関する勾配は不要です。

1:59:44.860,1:59:51.810
勾配が必要なのは

1:59:52.989,1:59:57.479
関数fだけです。ですから、重みの更新においては、data attributeを

1:59:58.300,2:00:00.300
使います。

2:00:00.610,2:00:02.350
重み更新後は

2:00:02.350,2:00:04.350
使用済みの勾配を削除し、

2:00:04.989,2:00:08.309
損失が良くなったか見てみましょう。最初は

2:00:10.840,2:00:12.760
25800でしたが、

2:00:12.760,2:00:19.679
今は5400です。プロットも-300に向かって加工する曲線から

2:00:22.030,2:00:24.030
だいぶまともになりました。

2:00:25.129,2:00:30.769
このプロセスをもう少し繰り返すので、関連する数行のコードを1つのセルにまとめました。

2:00:31.409,2:00:35.118
予測、損失を計算して、backward、重み更新、勾配削除という感じです。

2:00:35.969,2:00:38.388
そして、毎回損失の値を出力するようにして、

2:00:39.329,2:00:42.889
10回繰り返すと毎回改善されていますね。

2:00:46.030,2:00:50.640
そして、改善の様子が可視化されています。

2:00:52.230,2:00:59.000
イケてますね。アーサー・サミュエルの技術を使って、それは

2:01:00.840,2:01:03.560
良いパラメータを見つけるためのものですが、

2:01:04.170,2:01:10.520
損失関数による結果のフィードバックを使って継続的に改善していくのです。

2:01:11.999,2:01:14.339
非常に重要なステップです。

2:01:15.579,2:01:23.429
これが勾配降下法というもので、みなさんはぜひ、何回も復習して、

2:01:24.070,2:01:28.289
何が起きているかをしっかり理解してください。もし馴染めなくても

2:01:28.289,2:01:32.998
もしこれが初めてなら仕方ありません。

2:01:34.840,2:01:39.779
このnotebookのどのセルからあやふやになってしまったかを洗い出し、

2:01:40.389,2:01:45.748
しっかり考えてみてください。

2:01:45.749,2:01:50.339
1行1行何が起きているか良くみて、何回か実験したり、本を読んで

2:01:51.340,2:01:53.320
あなたが詰まった

2:01:53.320,2:01:56.039
セルを理解してから次に進みましょう。

2:01:58.380,2:02:00.920
So let's now apply this to em mist
ではこれをMNISTに使いましょう。

2:02:06.050,2:02:08.050
MNISTでは

2:02:09.310,2:02:13.620
ほとんど同じで、追加ですべきことはほとんどありません。

2:02:14.590,2:02:16.150
必要なのは

2:02:16.150,2:02:18.150
損失関数と

2:02:21.190,2:02:27.280
メトリクスでこれは誤差率です。

2:02:27.320,2:02:31.689
ここでも、メトリクスが良くなるように取り組むのですが、

2:02:32.780,2:02:35.709
深刻な問題は

2:02:36.470,2:02:39.130
勾配を計算して、

2:02:40.400,2:02:46.239
パラメータをどう更新するかはっきりさせることです。勾配は傾きで

2:02:47.030,2:02:50.169
関数の出力の変化 / 入力の変化で定義されます。つまり、

2:02:51.050,2:02:57.519
(y_new - y_old) / (x_new - x_old)です

2:02:58.490,2:03:06.369
実際に勾配が定義されるのはx_newがx_oldに非常に近いときです。

2:03:07.650,2:03:09.650
では、

2:03:09.940,2:03:17.129
もし、パラメータをごくわずか変化させたとしても、正確度は全く変わらないでしょう。

2:03:17.800,2:03:19.800
というのも

2:03:19.929,2:03:25.439
3と予測されていたものが7に変わったりその逆は起きないからです。

2:03:25.659,2:03:28.049
そもそもパラメータの変化は微小なのですから。

2:03:29.320,2:03:34.949
ですから、実際に多くの場所で勾配は0になり得るのです。

2:03:35.679,2:03:39.149
そして、このことは

2:03:39.790,2:03:46.709
学習率x勾配=0となり、パラメータを全く変化させないことを意味します。

2:03:48.429,2:03:50.429
これが

2:03:51.250,2:03:53.020
損失関数と

2:03:53.020,2:03:57.149
メトリクスが必ずしも一致しない理由です。

2:03:58.150,2:04:00.540
もしメトリクスの勾配が0なら

2:04:01.300,2:04:05.009
損失としては使えません。

2:04:07.680,2:04:09.680
ですからメトリクス以外で、

2:04:10.920,2:04:12.920
とはいっても正確度のようなものが必要で

2:04:14.530,2:04:19.620
それは正確度が良くなればその損失関数も

2:04:20.140,2:04:22.950
改善されると同時に、

2:04:23.770,2:04:25.770
勾配が0にならないようなものです。

2:04:27.670,2:04:29.670
ではこんな関数を考えましょう。

2:04:32.800,2:04:35.610
3枚の画像があるとします。

2:04:37.779,2:04:39.779
えー、

2:04:41.110,2:04:45.060
おそらくこのタイミングで今日のレッスンは止めた方が良さそうです。

2:04:45.060,2:04:49.680
勾配降下法の説明をしました。

2:04:51.780,2:04:55.219
単純な損失関数でどう実行するか学びました。

2:04:55.680,2:04:59.720
ですので、今日はもうMNISTの損失関数について考えたり、

2:05:00.690,2:05:02.400
説明しない方が良さそうです。

2:05:02.400,2:05:06.560
来週までの宿題も沢山あります。

2:05:06.560,2:05:09.410
1つはwebアプリを作成すること、そして

2:05:09.810,2:05:15.080
勾配降下法を復習することです。

2:05:15.660,2:05:17.660
ですから今日のところは

2:05:18.930,2:05:26.510
ここまでとしておきましょう。Rachel、何か質問は出ていますか？

2:05:28.170,2:05:35.390
わかりました。ではみなさん、今日もありがとうございました。最後の数分間についてはごめんなさい。

2:05:36.240,2:05:43.309
webアプリケーション作成を楽しんでください。

2:05:44.250,2:05:48.439
何か素晴らしいものを作ってくれることを期待しています。

2:05:49.350,2:05:53.870
過去には、16人のいとこを見分けるモデルを作った

2:05:54.270,2:05:57.530
生徒もいました。

2:05:57.960,2:06:03.200
婚約者のために作ったそうです。

2:06:04.590,2:06:11.120
どんなものでも作ることができますが、ぜひ誰かに見せて、そして

2:06:12.780,2:06:18.259
ipywidgetのドキュメントを確認したりしながら何か作ってみてください。

2:06:19.200,2:06:21.530
ではさようなら、また来週。
