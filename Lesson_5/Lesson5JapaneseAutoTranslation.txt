レッスン5にようこそ！データサイエンスの倫理についてお話します。私はこのコースの6週間バージョンを教えたばかりですが、現在は8週間バージョンを教えています。詳細を知りたい方は、7月に来てください。レイチェル・トーマスです。サンフランシスコ大学のCenter for Applied Data Ethicsの創設ディレクターであり、ジェレミー・ハワードと一緒にfastaiの共同創設者でもあります。私の経歴としては、数学の博士号を持っていて、データサイエンティストとソフトウェアエンジニアとしてテック業界で働いていた後、USFとfastaiで4年間働いています。倫理的な問題がニュースになっています。これらの記事は全て今年の秋に掲載されたもので、テクノロジーが私たちの世界にどのように影響を与えているかという交差点に登場しています。これらの記事の多くは、本当に懸念を抱かせるものでした。まず、テクノロジーに携わるすべての人が知っていて、気をつけてほしい3つのケースについてお話します。このビデオを5分だけ見たとしても、3つのケースを見てほしいと思います。フィードバックループは、モデルが次のラウンドのデータを制御しているときに発生する可能性があります。そのため、返されたデータはすぐにソフトウェア自体に欠陥があるものになります。そして、これは多くの場所で現れる可能性があります。一つの例としては、レコメンデーションシステムがあります。レコメンデーションシステムとは、基本的にはユーザーが好むコンテンツを予測するものですが、ユーザーがどのようなコンテンツに触れているかを判断し、人気が出る可能性のあるコンテンツを判断するのにも役立ちます。YouTubeは、多くの陰謀論や、非常に有害な陰謀論を推奨していることで注目を集めています。また、彼らは小児性愛の推奨をまとめています。ホームムービーの中にあったものの中から、若い女の子が水着やパジャマを着ているようなものを選んでいます。これは誰かが意図したものではなく、後ほど詳しくお話します。特に科学のバックグラウンドを持つ私たちの多くは、データを観察することに慣れていると思いますが、実際には、現実世界と相互作用する製品を作るときには、データがどのように見えるかをコントロールすることになります。2つ目のケーススタディは、貧しい人々の健康上のメリットを判断するために使用されているソフトウェアから来ています。これは50州の半分以上で使用されています。Vergeはアーカンソー州で展開された時に何が起こったのかを調査しました。バグがあり、ソフトウェアの実装が間違って脳性麻痺や糖尿病の人の保険を これらの人々は本当に医療を必要としていたのですが、このバグのために誤って保険料がカットされてしまいました。そして最終的には、長い裁判を経てすべてが明らかになりました。しかし、それまでの間に多くの苦しみをもたらしました。ですから、間違いを特定して対処する方法を持ったシステムを実装することが本当に重要です。私たちのコードは予期せぬ振る舞いをすることがあるので、それに備える必要があります。この考え方については、2年前の投稿「HBRがアルゴリズムとバイアスについて誤解していること」で詳しく書きました。そして、誰もが知っておくべき3つ目のケーススタディは、ハーバード大学のデータ・プライバシー研究室のディレクターで、コンピュータ・サイエンスの博士号を持つラターニャ・スウィーニーです。彼女は数年前、彼女の名前をグーグルで検索すると 「ラターニャ・スウィーニー 逮捕されましたか？ 」という広告が出てくる事に気付いたのですが、それは彼女に前科がある事を暗示しています ラターニャ・スウィーニーは 逮捕された事がない 身元調査会社に50ドル払って 逮捕された事がない事を確認した 他の名前をググってみて 気付いたんです 例えば クリステン・リンドクィストは 中立的な広告が出てきました クリステン・リンドクィストは ３回逮捕されてるのに コンピュータ科学者であるスウィーニー博士は2000人以上の名前を調べてこのパターンを発見したんだアフリカ系アメリカ人の名前は
伝統的にヨーロッパ系アメリカ人や白人の名前は、より中立的な広告を取得していました。そして、この広告の偏りの問題は、よく表れています。広告は、一種の、主要なハイテクプラットフォームのほとんどのための収益モデルであり、それは一種の影響力の強い方法でポップアップし続けています。ちょうど昨年、広告を配置する人がそうしようとしていない場合でも、Facebookの広告システムがどのように差別するかを示す研究があった。例えば、同じ住宅広告でも、全く同じテキストで、白人の家族と黒人の家族の写真を変更した場合、全く異なる2つのオーディエンスに配信されていたのです。これは、住宅を探しているとき、仕事に応募するときに、人々に影響を与える可能性があります。ここで、一歩下がって、なぜ、なぜ、これが重要なのか、と問いかけてみたいと思います。非常に極端な例ですが、データ収集はホロコーストを含むいくつかの大虐殺において重要な役割を果たしてきました。これはアドルフ・ヒトラーが当時のIBMのCEOと会っている写真です。この写真は1937年に撮影されたものだと思いますが、IBMはナチスとの提携を続けていました。彼らは強制収容所で使用されるコンピュータを製造していましたが、それはユダヤ人かどうか、どのように処刑されたかをコード化するために使用されました。これらの機械は多くのメンテナンスを必要とし、業者との継続的な関係を維持し、修理する必要があります。これはスイスの判事の判決です。IBMの技術支援が、ナチスの人類に対する犯罪の遂行を容易にしたと推論するのは不合理ではない。また、IBMのマシンによる会計と分類を含む行為と強制収容所自体で利用されています。まだ謝ってないとか。（山里）あっ そうなんですか... 忙しかったんだろうな。...ひどいですね これは非常に心が痛むような例ですが 肝に銘じておくことが重要だと思います 非常に、非常に、非常に恐ろしい害をもたらします。これは、私たち全員が取り組まなければならない問題を提起しています 自分が社会を傷つけるシステムの一部であることを知ったら、どう感じるでしょうか？"あなたは、どのように、どのようにして、あなたが構築したものが有害であったかもしれないことを発見することにオープンになりますか？これは、私たち全員が取り組む必要のある問題だと思います。あなたの技術が嫌がらせ者や権威主義政府によって プロパガンダやディスインフォメーションに使われたり 誤用されたりした場合の意図しない結果を 考えることも重要です。そして、より具体的なレベルでは、あなたは刑務所に入ることさえあり得るのです。フォルクスワーゲンのエンジニアが ディーゼル不正行為事件で 懲役刑を受けました 覚えていますか？フォルクスワーゲンが排ガステストで不正をしていた事件で、その一部だったプログラマーの一人がいました。その人は上司の命令に従っただけですが、それは言い訳にはなりません、非倫理的なことをしたからといって。気をつけなければならない事があります 倫理とは、何が良くて何が悪いかを扱う規律です。道徳的な原則のセットです 答えのセットではありませんが、どのような種類の、どのような質問をすればいいのか、どのように判断を下すのかを学ぶことです。このレッスンでは、倫理的な基礎や異なる倫理哲学について、後ほど詳しくお話します。しかし、まず最初に、いくつかの使用例から始めます。倫理は、宗教、法律、社会的規範、感情と同じではありません。倫理はこれらすべてのものと重複していますが 決まったルールではありません。それは正しいことと間違っていることの十分に確立された基準であり、これは明らかに誰もが、すべてのケースでは、倫理的な行動に同意しない何かですが、それは、一種の、何でも行く、またはすべてのアクションが等しく倫理的であると考えられることを意味するものではありません。広く合意されていることはたくさんありますし、これらの決定を下すための、ある種の、哲学的、哲学的な裏付けがあります。倫理学とは、私たちの倫理基準を継続的に研究し、発展させていくことでもあります。倫理的な知恵を実践するための学習の、ある種、終わりのないプロセスです。そして、私はそれを何度か参照します... ここでは、サンタクララ大学の技術倫理のためのマーククラセンターの記事をいくつか紹介します。
特にシャノン・ヴァロー、ブライアン・グリーン、イリーナ・ライクーの研究は素晴らしいもので、彼らは多くのリソースを持っていますが、そのうちのいくつかはこの話の後半に回顧します。 私は人生の何年もかけて倫理学を勉強しました。大学では倫理学を専攻していましたが、倫理とは何かという問いに多くの時間を費やしました。そこから離れると、哲学的な倫理学を勉強することは、倫理学を学ぶ上で特に役に立たなかったということになると思います。そうですね、そして、私はこの種の非常に、非常に、非常に応用的で、非常に実用的なものにしようとしています。 また、非常にテック業界に特化したもので、応用倫理学の観点から何が必要なのでしょうか？ Markoulisは素晴らしいと言っていました。  私が本当に尊敬しているコロラド大学のCasey Fiesler教授は、技術倫理のシラバスをクラウドソース化したスプレッドシートを作成してくれました。 これは2年ほど前のことですが、200以上のシラバスをこのクラウドソースのスプレッドシートに入力して、シラバスのあらゆる側面をメタ分析しました。そしてそれについての論文を発表しました。技術倫理を教えるときには何を教えるのでしょうか？技術倫理を教えるときに何を教えるのか、それについていくつか興味深いことがあります。 それは独立したコースであるべきなのか、それともカリキュラムのすべてのコースに組み込まれるべきなのか。 誰が教えるべきなのか - コンピュータ科学者、哲学者、社会学者？ そして、彼女はシラバスのために、コースのホームは何か、講師のホームは何かを分析しました。そして、講師はコンピュータ・サイエンスを含む様々なコースから来ていたことがわかります。  コンピュータサイエンス、情報科学、哲学、科学技術研究、工学、法律、数学、ビジネス。どのようなトピックをカバーするために - 法律や政策のプライバシーと平等な正義と人権の監視、環境への影響、AIやロボット、そして職業倫理、労働の仕事、サイバーセキュリティを含む、カバーすることができるトピックの巨大な範囲。  このように、このリストには、1学期の長さのコースでさえもカバーすることができる以上のことが明らかにありますし、確かに、一種類の単一の講義ではありません。 どのような学習成果があるのでしょうか？ これはもう少し意見が一致している分野で、コースが教えようとしているスキルの第一位は批評であり、それに続いて問題点を発見し、議論をすることです。  その多くは、何が問題なのかを見極め、技術やデザインの提案を批判的に評価し、何がうまくいかないのか、何がリスクになるのかを知ることです。  いいですね。  では、いくつかの異なる中核的なトピックを学びます。 私が提案したように、これはカバーしうるものの極端な部分集合になります。  私は非常に重要で影響力のあるものを 選ぼうとしました  1つは、「責任逃れ」と「説明責任」です。  先ほど、貧しい人々の医療給付を決定していたシステムにバグがあったという例をお話ししました。 このシステムでは、バグが発見されても、誰も責任を取らなかったのです。 アルゴリズムを作った人がインタビューを受けて質問されたのですが、彼らは彼に、なぜ給付金がカットされたのか説明を受けるべきかと尋ねたのですが、彼はとても無愛想な答えをしました、「そうだね、そうすべきだと思うけど、僕はベッドの下で埃を払うべきだね、誰がそんなことをするのかな」というような。  そして、彼は結局、政策立案者がどのようにアルゴリズムを展開したかを非難しました。  政策立案者はそれを実装したソフトウェア・エンジニアを責めることができましただから、ここでは多くの責任転嫁が行われました  ダナ・ボイド氏は、官僚が責任を負うことは常に課題であり、官僚は責任を回避するために使われてきました。 倫理の文化的文脈については、それらのシラバスの一部として言及されていないように見えましたが、他の誰かが、『どうやって対処するのか、これは文化的に依存しているのか？そして、それにどのように対処するのか？ それは文化的に依存しています。 これについては後で簡単に触れますが、西洋から来た3つの異なる倫理哲学をお話しします。  例えば今。
多くの先住民族のデータ主権運動があります。マオリ族のデータ主権運動が特に活発に行われていることは知っていますが、文化の違いによって倫理観が異なりますし、文化的背景は非常に重要だと思います。今晩はこの話はしませんが、アルゴリズム・コロニアリズムという分野も増えてきています。ある特定の国や文化で作られたテクノロジーが、世界の反対側で、全く異なる文化的な文脈で実装されている場合、何が問題になるのかということを研究しています。例えば、世界人権宣言ですが、その名前にもかかわらず、普遍的に受け入れられているわけではありませんが、多くの国が人権の枠組みとして、また、基本的な権利として受け入れています。さて、この話題に戻りますが、説明責任と償還の話です。覚えておいて欲しいのは、データには誤りが含まれているという事です カリフォルニアで使われている 怪しげなデータベースがありました ギャングのメンバーを追跡しているのですが、ある監査員が１歳未満の赤ちゃんが４２人いることを発見しました。このデータベースは基本的に更新されません 人は追加されても削除されません 一旦登録された人はそのままです そのうち28人の赤ちゃんが ギャングのメンバーであることを 認めたとマークされています これは本当に明白なエラーの例ですが、他にもいくつかの完全に間違ったエントリがあることを覚えておいてください。エラーを含むデータのもう一つの例は、米国の3つの信用情報機関です。信用報告書のFTCの大規模調査では 26%が少なくとも1つのミスをしていて 5%は壊滅的なミスをしていました これはある公共ラジオのレポーターが書いた記事の見出しです アパートを取りに行って 大家がその後彼に電話をかけてきて言ったんです あなたの身元調査では あなたに銃器所持の前科があることがわかりました この人には銃器所持の前科はありませんでした ほとんどの場合 大家はおそらく言わないでしょう あなたに伝えて知らせて あなたに知らせてください それがアパートを手に入れられなかった理由なんです それで、この男はそれを調べました。この男は白人だったので、この間違いを発見したのは間違いないと思いますが、彼は何十回も電話をしました。しかし、それは......。一旦誤りをピンポイントで指摘して、彼が以前住んでいた場所の、あの、郡書記官のような人に話を聞く必要があったとしても これは、人々の生活に大きな影響を与える可能性があります。例えば、顔認識は大人向けに開発されていますが、ニューヨーク市警は11歳の子供の写真をデータベースに入れています。誤り率が高いことも知っています これは開発された方法ではありません これは、これは、これは、これは、深刻な、深刻な、深刻な懸念です。多くの誤用があります ジョージタウンのプライバシーと技術のセンターは素晴らしいです、是非、彼らを追いかけるべきです、報告書「Garbage In, Garbage Out [...]」を書きました。 警察が実際に顔認識をどのように使っているかを調べていて、いくつか本当に気になる例を見つけました。例えば、ニューヨーク市警が容疑者の写真を持っていたのですが、一致するものが返ってこなかったので、「この人はウディ・ハレルソンに似ている」と言って、俳優のウディ・ハレルソンをググってみて、顔認識に彼の顔を入れて、それを手がかりにしていました。これは明らかに正しい使い方ではありませんが 使われている方法です ここには説明責任の欠如があります。別の研究では、50州全ての警察官が元交際相手や活動家を探す為に 機密データベースを悪用していました。いいだろう
次のトピックはフィードバックループとメトリクスです。冒頭では、3つの主要なユースケースの1つとしてフィードバック・ループについて少しお話しました。このトピックについては、今年の秋に「メトリクスの問題はAIにとって大きな問題」というブログ記事を書きました。そして、The Data InstituteのディレクターであるDavid Uminskyと一緒に、これを「メトリクスへの依存はAIにとって根本的な課題である」という論文に発展させました。そして、これは「Ethics and Data Science」カンファレンスに採択されました。しかし、メトリクスを強調しすぎると、操作やゲーム性、短期的な量を追跡しやすいために短期的な目標に近視眼的に焦点を当てること、予期せぬ負の結果を招くことなど、多くの問題を引き起こす可能性があります。AIや機械学習の多くは、メトリクスを最適化することに重点を置いています。これは、機械学習の強みであるメトリクスの最適化が非常に得意になってきているという点で、両方を兼ね備えています。しかし、これは本質的に弱点や限界でもあると思います。いくつか例を挙げます。これは機械学習だけでなく、アナログな例でも起こりうることです。これは、イギリスの公衆衛生システムが2000年代初頭に、数字を中心に多くの目標を実施した時の研究からのものです。この研究は「何を測定するかが重要」と呼ばれていました。その結果、目標の一つは、ERの待ち時間を短縮することであることが分かりました。しかし、その結果、ERに余分なスタッフを入れるために、予定されていた業務をキャンセルすることになった。救急車を待っている時間はあなたのERの待ち時間にカウントされないので、救急車の列で待つ患者を必要とする医師を増やすことができるように、彼らはERにあまりにも多くの人々があったように感じた場合、彼らはちょうど操作をキャンセルして開始されます。廊下にストレッチャーを置いてベッドにしたり、病院と患者が報告した数字には大きな食い違いがあります。病院に平均してどれくらい待たされているのかと聞くと、患者にどれくらい待たされたのかと聞くのとは全く違う答えが返ってきます。もう一つの例としては、小論文の採点ソフトがあります。この小論文採点ソフトはアメリカの22の州で使われていると思います。はい、20州ですが、文の長さ、語彙、スペル、主語動詞の一致などの評価基準に重点を置いています。これらは私たちがコンピュータを使って測定する方法や方法を知っているものです。しかし、創造性や新規性のようなものを評価することはできません。しかし、洗練された言葉をたくさん使った失言的なエッセイは良いスコアを出します。洗練された言葉を多用した、陳腐で洗練された作文をコンピュータで作成している例さえあります。そして、そのコンピュータプログラムで採点され、高い評価を得たものがあることをご存じでしょう。これにも偏りがあります。アフリカ系アメリカ人の学生の作文は、専門家である人間の採点者よりもコンピュータの方が低い評価を受けます。また、中国本土の学生の作文は、専門家である人間の採点者よりもコンピュータの方が高い評価を受けました。この研究の著者は、この結果は、あらかじめ暗記したテキストの塊を使っている可能性があることを示唆していると考えています。これは、これらは2つの例に過ぎません。ブログの記事にはもっとたくさんありますし、論文にはさらに多くのメトリクスが強調されているときはいつでも、操作やゲーム性を誘うことができます。これは、多くの人が話している、良いハートの法則のようなものです。これは、メトリクスに頼れば頼るほど、信頼性が低くなるという考え方です。フィードバックループとレコメンデーションシステムの例に戻りますが、ギョーム・シャスロは元グーグル、ユーチューブのエンジニアです。YouTubeはGoogleが所有しており、彼は本当に素晴らしい記事を書いています。彼はこの問題に対する認識を高めるために多くの活動をしており、非営利団体「AlgoTransparency」を設立し、外部からYouTubeのレコメンデーションを監視しようとしています。彼はガーディアンやウォールストリートジャーナルと提携して調査をしています。しかし、彼は初期の頃のレコメンデーションシステムがいかに視聴時間を最大化するように設計されていたかについての記事を書いています。そして、これは、これは、メトリクスでよく行われている他の何かですが、どんなメトリクスでも、あなたが本当に気にしていることの代理に過ぎないということです。ここでは、Googleのチームは、YouTubeをもっと見ている人が多いということは、その人たちが幸せであることを示していると言っていました。
しかし、これは他のメディアが嘘をついていることを伝えるコンテンツを奨励することにもなります。ギヨームはこのような仕組みについて素晴らしい記事を書いてくれました。これはYouTubeだけではなく、どのようなレコメンデーションシステムにも当てはまると思いますが、プラットフォームをまたいだ多くのレコメンデーションシステムの問題点について多くの話題が出ています。
次のトピックはフィードバックループとメトリクスです。冒頭では、3つの主要なユースケースの1つとしてフィードバック・ループについて少しお話しました。このトピックについては、今年の秋に「メトリクスの問題はAIにとって大きな問題」というブログ記事を書きました。そして、The Data InstituteのディレクターであるDavid Uminskyと一緒に、これを「メトリクスへの依存はAIにとって根本的な課題である」という論文に発展させました。そして、これは「Ethics and Data Science」カンファレンスに採択されました。しかし、メトリクスを強調しすぎると、操作やゲーム性、短期的な量を追跡しやすいために短期的な目標に近視眼的に焦点を当てること、予期せぬ負の結果を招くことなど、多くの問題を引き起こす可能性があります。AIや機械学習の多くは、メトリクスを最適化することに重点を置いています。これは、機械学習の強みであるメトリクスの最適化が非常に得意になってきているという点で、両方を兼ね備えています。しかし、これは本質的に弱点や限界でもあると思います。いくつか例を挙げます。これは機械学習だけでなく、アナログな例でも起こりうることです。これは、イギリスの公衆衛生システムが2000年代初頭に、数字を中心に多くの目標を実施した時の研究からのものです。この研究は「何を測定するかが重要」と呼ばれていました。その結果、目標の一つは、ERの待ち時間を短縮することであることが分かりました。しかし、その結果、ERに余分なスタッフを入れるために、予定されていた業務をキャンセルすることになった。救急車を待っている時間はあなたのERの待ち時間にカウントされないので、救急車の列で待つ患者を必要とする医師を増やすことができるように、彼らはERにあまりにも多くの人々があったように感じた場合、彼らはちょうど操作をキャンセルして開始されます。廊下にストレッチャーを置いてベッドにしたり、病院と患者が報告した数字には大きな食い違いがあります。病院に平均してどれくらい待たされているのかと聞くと、患者にどれくらい待たされたのかと聞くのとは全く違う答えが返ってきます。もう一つの例としては、小論文の採点ソフトがあります。この小論文採点ソフトはアメリカの22の州で使われていると思います。はい、20州ですが、文の長さ、語彙、スペル、主語動詞の一致などの評価基準に重点を置いています。これらは私たちがコンピュータを使って測定する方法や方法を知っているものです。しかし、創造性や新規性のようなものを評価することはできません。しかし、洗練された言葉をたくさん使った失言的なエッセイは良いスコアを出します。洗練された言葉を多用した、陳腐で洗練された作文をコンピュータで作成している例さえあります。そして、そのコンピュータプログラムで採点され、高い評価を得たものがあることをご存じでしょう。これにも偏りがあります。アフリカ系アメリカ人の学生の作文は、専門家である人間の採点者よりもコンピュータの方が低い評価を受けます。また、中国本土の学生の作文は、専門家である人間の採点者よりもコンピュータの方が高い評価を受けました。この研究の著者は、この結果は、あらかじめ暗記したテキストの塊を使っている可能性があることを示唆していると考えています。これは、これらは2つの例に過ぎません。ブログの記事にはもっとたくさんありますし、論文にはさらに多くのメトリクスが強調されているときはいつでも、操作やゲーム性を誘うことができます。これは、多くの人が話している、良いハートの法則のようなものです。これは、メトリクスに頼れば頼るほど、信頼性が低くなるという考え方です。フィードバックループとレコメンデーションシステムの例に戻りますが、ギョーム・シャスロは元グーグル、ユーチューブのエンジニアです。YouTubeはGoogleが所有しており、彼は本当に素晴らしい記事を書いています。彼はこの問題に対する認識を高めるために多くの活動をしており、非営利団体「AlgoTransparency」を設立し、外部からYouTubeのレコメンデーションを監視しようとしています。彼はガーディアンやウォールストリートジャーナルと提携して調査をしています。しかし、彼は初期の頃のレコメンデーションシステムがいかに視聴時間を最大化するように設計されていたかについての記事を書いています。そして、これは、これは、メトリクスでよく行われている他の何かですが、どんなメトリクスでも、あなたが本当に気にしていることの代理に過ぎないということです。ここでは、Googleのチームは、YouTubeをより多く見ているならば、それは彼らがより幸せであることを示していると言っています。しかし、これは他のメディアが嘘をついていることを伝えるコンテンツを奨励することにもなります。なぜなら、他の誰もが嘘をついていると信じることで、特定のプラットフォームでより多くの時間を過ごすことを奨励するからです。ギヨームはこのような仕組みについて素晴らしい記事を書いてくれました。これはYouTubeだけではなく、どのようなレコメンデーションシステムにも当てはまると思いますが、プラットフォームをまたいだ多くのレコメンデーションシステムの問題点について多くの話題が出ています。
しかし、これは、気をつけなければならない事であり、これを作った人たちが予想していなかった事です 去年、ギョームはこのデータを集めました X軸はチャンネル数、YouTubeのチャンネル数 動画を推奨しているチャンネル数 Y軸は再生回数の対数です この極端な外れ値を見てみましょう ロシアのトゥデイの記事です ミューラー報告書に対するロシアのトゥデイの記事です ギヨームが観察した結果、ワシントン・ポスト紙に取り上げられました しかし、これは、ロシア・トゥデイがレコメンデーション・アルゴリズムを 使っていることを強く示唆しています これは、驚くべきことではありませんが、多くのコンテンツ制作者が 意識していることだと思います そして、実験をして、何がより強く推奨され、より多くのビューが得られるかを 見ようとしています 私たちのオンライン環境は中毒性があるように設計されていますので、私たちがクリックしたものが、私たちが何を楽しんでいるのか、何が好きなのかの代理として使われることが多いのですが、それは必ずしも私たちの最高の自分や高次の自分のためのものではありません。それは、私たちがクリックしているものです、この、ある種、非常に中毒性の高い環境の中で、私たちの、ある種、低い本能に訴えかけていることが多いのです。Zeynep Tufekciは、カフェテリアの例えを使います。塩辛い、甘い、脂肪分の多い食べ物を顔に押し込んで 私たちのほとんどは原始的な方法でやっていると思いますが、私たちはしばしば、あなたが知っているように、私たちの高次の自己は、「ああ、私はジャンクフードを常に食べているようにしたくない」と、オンラインでは、私たちはしばしば、あなたが知っているように、あなたが知っているように、あなたが言うための素晴らしいメカニズムを持っていない「ああ、私は本当に研究するのに数ヶ月かかって、消化するのに長い時間がかかりそうな長文の記事を読みたい」のように。そうしたいと思っていても オンライン環境は必ずしもそれを助長するものではありません そうなんですか？Sylvainは偽りの安全性の議論についてのコメントをしましたが、これはマスクや物事に非常に関連しています。その偽りの安全性の議論について何か言うことはありませんか? もっと言えますか？今、マスクをしてはいけないという意見がよく出ていますが、それは偽の安心感を持っているかもしれないからです。それは、倫理的な観点から見て、人々にそう言うのは理にかなっていると思いますか？いいえ、それは正論ではないと思います。一般的には、ジェレミーを含む他の人たちも指摘していますが... 私たちの生活をより安全にするために取る行動はたくさんあります シートベルトをしたり 自転車に乗るときにヘルメットをかぶったり 安全なセックスの練習をしたりと 安全性を最大限に高めたいと思うことはたくさんあります 人々が誤った安心感を抱くような影響が絶対にないわけではありませんが、データを収集してしっかりとしたケースを構築し、それが起こると仮定するのではなく、ほとんどの場合、人々が考えることができます。何か付け加えることはありますか？先ほども言いましたが、私たちのインセンティブの多くは短期的な指標に焦点を当てています。長期的なものは測定するのがはるかに難しく、複雑な関係性を伴うことが多いです。そして、ほとんどのテック企業の基本的なビジネスモデルは、人々の行動を操作したり、時間を独占したりすることにあります。広告が本質的に悪いとは思いませんが、彼らは... 私は、それが極端に取られたときに、それが負のものになることができると思います。ジェームズ-グリメルマンによる偉大なエッセイがあります 'プラットフォームはメッセージである'と、彼は指摘しています。"これらのプラットフォームは構造的に自分自身と戦争をしている "と指摘しています。"無礼で攻撃的なコンテンツを容認できないのと同じ特徴が、そもそもそれを流行らせているのだ ここには、ある種の、本当の緊張感があります。この緊張感の中で、コンテンツを本当に不快にしたり、受け入れられないものにしてしまうことが、その人気を高め、多くの場合、促進されているのです。これは興味深いエッセイです。彼は「Tide Pod Challenge」というミームについて深く掘り下げていて、毒のあるTide Podを食べることについてのミームですが、食べてはいけません。これは非常に一般的なミーム文化をよく見ていて、「Tide Pod Challenge」について話している人の例はおそらくないだろうと主張していて、部分的な皮肉ではなく、ミームでは一般的なもので、何を言っているにせよ、皮肉の層があり、異なるグループは異なる解釈をしていて、それを打ち消そうとしても、それを促進している。
タイドポッド・チャレンジで多くの有名人が 「タイドポッドを食べないで」と言っていますが それもまたこのミームの人気を永続させています だから... これは私がお勧めするエッセイで、かなり洞察力に富んでいると思います。それで、これは... 誤報についてはすぐに説明しますが、主要な技術プラットフォームは、しばしば誤報を煽動し、促進します。そして... メトリクスの話題で 私は... 私はただ疑問に思ったのですが、ブリッツスケーリングという考え方があります。前提として、企業が十分に大きく、十分な速度で成長すれば、最終的に利益は後からついてくるというものです。それは効率よりもスピードを優先し、潜在的に悲惨な敗北を招くリスクがあります。ティム・オライリーは昨年、このアプローチの問題点の多くについて、本当に素晴らしい記事を書きました。多くのベンチャーキャピタルの根底にある基本的なモデルのようなものです。そして、その中で、投資家は市場の力とは対照的に、勝者を指名してしまうのです。独占や二重独占を生み出す傾向があります。それは... 創業者には良くありませんし、人々は、自分自身を手薄にしてしまうのです。だから、いくつかの重大な欠点があります。倫理の授業でこれを持ち出す理由は？メトリクスの話をしていた時 ホッケーのスティックの成長には 自動化が必要で メトリクスへの依存が必要だ また、何よりもスピードを優先することは、倫理について考える時間を与えてくれません。これは難しいことだと思いますが、このモデルに従うと、問題が発生したときには、大規模なスケールで問題が発生することが多いのです。だから、私は、これは少なくとも、少なくとも意識しなければならないことだと思います。ある人が尋ねてきました。第一世界の問題のように見えるAIの倫理と、戦争、貧困、環境搾取との間には二分法があるのでしょうか？ここに答えがありますが、他の誰かが、もしかしたらあなたが同意するかどうかコメントできるかもしれませんし、私も何か付け加えることがあるかもしれませんが、「AIの倫理...」と言っています。例えば、アフリカの多くの国では携帯電話の普及率が高く、人々はFacebookやWhatsApp、YouTubeからニュースを得ています。何かコメントはありましたか？そうですね... 最初の質問は... AI倫理についてですが、先ほども述べたように、データ倫理という言葉を使っていますが、これは非常に広範囲で、多くのことを指しています。もし人々が「将来、コンピュータは意識を持つことができるようになるのか、それに関する倫理はどうなのか」という話をしているのであれば、それは私の関心事ではありません。私が非常に重視しているのは、サンフランシスコ大学の応用データ倫理センターの使命です。今、人々はどのような被害を受けているのか？その意味では、データ倫理は第一世界的な、あるいは未来的な問題である必要はないと思います。今起きていることなんですが、その人が言っていたように、いくつか例を挙げてみましたが、後ほどその例を紹介しますが、ミャンマーではイスラム教徒の少数民族、ロヒンギャが大量虐殺を経験しています。国連はFacebookが決定的な役割を果たしたと裁定しました。私が思うに、これはテクノロジーが実害をもたらす例だと思います フェイスブックが所有するWhatsAppも所有しています。誤った情報や噂を広める人々が問題になっています インドではリンチ事件が何度も起きています 人里離れた小さな村では、「誘拐犯が来る」という誤った噂を広めてしまい、訪問者や見知らぬ人が現れて殺されてしまいます。また、WhatsAppはブラジルのボルソナロ氏の選挙でも、フィリピンのドゥテルテ氏の選挙でも、非常に重要な役割を果たしました。テクノロジーは、人々に非常に直接的な影響を与えていると思います。そして、それは... これらは、私が本当に興味を持っている倫理的な質問です 皆さんにも興味を持って頂きたいと思います 他に何か言う事はありますか？私は、誤報について話します 私は、それらが、ある種、ディスインフォメーションに焦点を当てたものだと理解しています、そして、私は最初にバイアスについて話します。私はバイアスだと思います、次に偽情報です そうなの？
質問です うーん。倫理について話すとき、このうちどれくらいが意図的な非倫理的な行動なのでしょうか？私は多くの例を無能な行動や悪いモデリングのように見ています。製品やモデルが十分なテストをせずに急かされたり、バイアスがかかっているように考えられていたりしますが、必ずしも悪意があるわけではありません。ええ、いや、私はそれに同意します。ほとんどは意図的ではないと思います。私が思うには... まあ... いくつかのケースに入ります 私が思うに、多くの場合、利益のインセンティブがずれていると思います。人々が大金を稼いでいる時には、たとえそれが害を防ぎ、倫理観を高めることになるとしても、利益を減らすような行動を考えるのは非常に難しいと思います。だから、ある時点で、人々がどのように被害を受けているかよりも、利益を重視することが、いつになったら、いつになったら、それが意図的なものになるのかは、議論の余地がある問題だと思いますが、私は、「大量虐殺を起こしたい」とか、「権威主義的なリーダーが当選するのを助けたい」とか、そんなことを言い出す人はいないと思っています。ほとんどの人はそうではないと思いますが、時としてそれは不注意であり、軽率だと思いますが、その責任は私たちにあると思います。そうですか、バイアスは... バイアスは、私が思うに、この問題は、おそらく多くの注目を集めていると思いますが、それは素晴らしいことです。昨年、Harini SureshとJohn Guttagによる素晴らしい論文がありましたが、その論文では、さまざまなタイプのバイアスの分類法が示されていて、機械学習のパイプラインの中でどのようにして異なるソースを持っているのかを調べていました。それは本当に役に立ちました。なぜなら、異なるソースには異なる原因があり、それに対処するためには異なる、異なるアプローチが必要だからです。それは... ハリニは論文のブログ記事も書いてくれました。あなたが学術論文を書いているなら、もっと多くの人がブログポスト版も書いてくれることを願っています。このようなタイプのものをいくつか紹介します。皆さんの多くがジョイ・ブオラムウィニの研究を聞いたことがあると思いますが、これは多くの人に知られるようになりました。Gender Shades』の中で、彼女とTimnit GebruはMicrosoft、IBM、Face++の市販のコンピュータビジョン製品を調査し、その後、Joy BuolamwiniとDeb RajiはAmazonやKairos、その他いくつかの企業を調査しました。つまり、肌の色が薄い人よりも、肌の色が濃い人の方が悪いということです。男性よりも女性の方が悪いということと、肌の色が黒い女性の方がエラー率が非常に高いということもありました。一例としてIBMの製品は、肌の薄い男性では99.7%の精度でしたが、肌の黒い女性では65%しか精度がありませんでした。もう一度言いますが、これは市販のコンピュータビジョン製品がリリースされたものです。質問は？TWIML研究会からの質問です。フォルクスワーゲンの例では、多くの場合、非倫理的な行動を引き起こし、報いているのは経営陣です。このような場合、個々のエンジニアに何ができるのでしょうか？特にシリコンバレーのように、人々が頻繁に会社を移動するような場所ではどうすればいいのでしょうか？これは、私ならもっと上位の人たちが刑務所に入っているのを見たかった例です。世界の多くの人がこの選択肢を持っていないのは知っていますが、私たちの多くは、テック業界、特にシリコンバレーで働いていて、多くの選択肢を持っていると思います。いいですか？シリコンバレーでソフトウェアエンジニアをしていて、多くの企業が求人を出しているにもかかわらず、仕事に追われていると感じている人たちとよく話をします。だから、それを利用することが重要だと思います。多くの従業員組織化運動は非常に有望で、それは有用ですが、入社する会社の倫理観を本当に吟味して、もし可能であれば、辞めても構わないという気持ちを持つようにしましょう。それは素晴らしい、素晴らしい質問ですね。これは、この代表的な偏りの例ですが、これに対処するには、より代表的なデータセットを構築することです。人々の写真を使用している場合、人々の同意を心に留めておくことは非常に重要ですが、Joy BuolamwiniとTimnit Gebruはこれを行いました。
しかし、これは... これが1つの会社だけの問題ではなく 基本的にどの会社でも問題になっていたのは この根本的な問題に起因しています 機械学習のベンチでは ベンチマークデータセットが多くの研究に拍車をかけています しかし数年前には 人気のある顔のデータセットは 主に肌の薄い男性のデータセットでした 例えば IJB-A、数年前のある種の人気のある顔のデータセットでは、画像の４％しか肌の黒い女性の画像がなかった。そうなんですか？質問：『COVID-19の接触追跡、プライバシーの位置追跡、民間の監視会社などの侵食を心配しています。COVID後のデジタル権利を守るために何ができるか。私たちは何を期待しているのか、歴史の中でどんな例を見てもいいのでしょうか？それは... それは大きな質問ですね、私もずっと考えていたことです。私は、私はそれについて話すために後でまで延期するつもりです、そして、それは私が教えるコースでは、私はプライバシーと監視に関する全体のユニットを持っている何かです、私は今夜の講義ではありませんが、私はすでに本当に、さらにはちょうど好きですが、私はいくつかの材料を共有することができます。2ヶ月前に初めて教えた時と比べて COVID-19の時代のプライバシーと監視を どう教えるか考え直しました でもそれは私がよく考えることです 時間があれば後で話します あるいはフォーラムでも 素晴らしい質問ですね。とても重要な質問です・・・。話題について 私はまだ調べていませんが、グループがあるのは知っています、トラッキングのためのよりプライバシー保護のアプローチに取り組んでいるグループがあります。そうなんですか？私もそれを見ています これはテクノロジーで解決可能な問題のように思えます。全ての問題が解決できるわけではありませんが、誰かの携帯電話に追跡履歴を保存することができます。そして、いつ感染したかを知ることができ、その時点で位置情報を共有することで感染したことを伝えることができます。何人かの人がそれに取り組もうとしていると思います。実際に技術的に問題があるかどうかはわかりません。プライバシーを守りつつ、最低限のアプリケーションを提供する方法があると思います。そうですね、それに加えて、有効期限を明確にしておくことも非常に重要だと思います。COVID-19のためにやっているだけで、期限があり、期限切れになってしまいますが、この明確な目的のためにやっているのです。先ほど、データに誤りが含まれているという問題がありましたが、これは既に問題になっていますし、他の国では、より監視に重点を置いたアプローチを行っています。この件については、後で詳しく話します 話を... 偏見の話に戻ると... ベンチマークのようなものがあって 広く使われているベンチマークに偏りがある場合、その偏りは大規模で再現されます。ImageNetの画像の3分の2は欧米のものです。この円グラフを見ると、ImageNetの画像の45％が米国、7％が英国、6％がイタリア、3％がカナダ、3％がオーストラリアで、欧米以外の国に行かなくても、このパイの多くをカバーしています。花婿、結婚する男性のカテゴリの1つですが、これには文化的な要素が多く含まれています。今では、データセットの多様化に取り組んでいる人たちがいますが、データセットの規模が大きくなったり、偏りが認識される前から大きくなったりするのは非常に危険です。
もう一つの重要な研究は、COMPAS再犯アルゴリズムです 誰が保釈金を支払わなければならないかを 判断するのに使用されます 米国では、非常に多くの人が刑務所に入っています 彼らは保釈金を支払う余裕がないので 裁判すら受けていないのです プロパブリカは2016年に有名な調査をしましたご存知の方も多いと思いますが、その調査では黒人被告人の偽陽性率が白人被告人の2倍近くも高いことが分かりました ダートマス大学の研究では そのソフトウェアは アマゾンのメカニカル・タークの労働者よりも 正確ではないことがわかりました インターネット上の無作為な人々 また、このソフトウェアは、知っての通り、この独自のブラックボックスで、130以上の入力を使用していますが、3つの変数についての線形分類器よりも正確ではありません。しかし、これはまだ使用されています 多くの州で使用されています ウィスコンシン州では異議を唱えられましたが ウィスコンシン最高裁は使用を支持しました 公平性の定義についての話題に興味があるならば、ここには多くの複雑さがありますが、私は、COMPASのやっていることが正しいと考えている人を誰も知りません。Arvind Narayanan は素晴らしいチュートリアル「...21 の公平性の定義とその政治」を持っていますが、これは私が、私が、非常にお勧めします。これはヒストリカルバイアスの例です。ヒストリカルバイアスは、データ生成プロセスの最初のステップでの基本的な構造的な問題であり、完全なサンプリングと特徴の選択が行われていても存在する可能性があります。ですから、画像分類器では、より代表的な画像を集めれば、その問題に対処することができますが、今回はそうではありません。米国の刑事司法制度に関するより多くの データを収集すると 偏りが出てきます なぜなら、それは本当に、歴史と現在の状態に組み込まれているからです だから、これは良い事だと思います、 認識するのは良い事だと思います これを緩和するためにできることの一つは、少なくとも、この問題を緩和するためには、領域の専門家と話をして、影響を受けた人々と話すことです。逮捕されて保釈金を払えない無実の男、テレンス・ウィルカーソンと、元公選弁護人のエリザベス・ベンダー氏を招いて、 エリザベスとテレンスは、刑事司法制度が実際にどのように 機能するかについて多くの洞察を提供してくれました コンピューター科学者が扱うような きれいで論理的な抽象的なものとは 非常に異なりますが 質問は？"AIの偏見は実生活の偏見から 移されるのではないか？例えば 人々が異なった扱いを受けているのは 日常的な現象ではないのか？その通りです これは多くの場合、そう、実世界のバイアスから来ています、これについては後で説明しますが、アルゴリズム・システムはそのバイアスを増幅させることができます、だからさらに悪化させることができます、しかし、そう、それは多くの場合、既存のデータから学習されます。私がそれを聞いたのは、私が思うに、これは、AIを心配しなくてもいい理由のようなものだと、よく見かけるからです。AIではないんですね。まあ、それについてはすぐに説明します。実際には、2つのスライドで考えてください。だから、その質問を待っていてください。最初に他の種類のバイアスについて話したいと思います。測定バイアスです これはSendhil MullainathanとZiad Obermeyerによる 興味深い論文です 彼らは過去の電子カルテデータを見て 脳卒中の最も予測しやすい要因を 突き止めようとしています 最も予測可能な因子の第一位は脳卒中の既往であり、これは理にかなっている。２番目は心血管疾患、それも合理的だと思います、そして３番目は事故による傷害、それに乳房の良性しこり、大腸内視鏡検査、副鼻腔炎が続きます。私は医者ではありませんが 奇妙なことが起こっていると言えます ３から６までの要因で なぜこれらが脳卒中を 予測するのか？誰か考えてみませんか？
読んでみたい推理は？誰かがそうだな 最初の答えは脳卒中になったら いつでも検査するの？ 確認バイアス？ オーバーフィット？ たまたま入院したから？偏ったデータ？EHRはこれらのイベントを記録する？データは、医学の特定の進歩の前に撮影されたからですか？これらは、これらはすべて良い推測です。私が探していたものではありませんが、良い考えです。 ノーと言うのは素敵な方法ですね 研究者がここで言っていることは、これは彼らの患者についてのもので、彼らは医療を多く利用している人とそうでない人がいて、それを一種の「医療の高効用対低効用」と呼んでいて、これには多くの要因があります。多くの要因があります。基本的に、医療をよく利用している人は、副鼻腔炎になったら医者に行くでしょうし、脳卒中になったら病院に行くでしょう。我々が測定したのは、症状のある人、医者に行って、検査を受けて、脳卒中と診断された人です。これは、脳卒中になった人の妥当な代理のように思われますが、代理は、正確には望んでいたものではありませんし、多くの場合、そのギャップが大きくなります。人は偏っていないのでしょうか？そうですね。はい、そうです。これまで何十、何十、何百もの研究がありましたが、いくつかを引用しますが、その全てがこのニューヨークタイムズの記事にリンクされています。しかし、医師が同じファイルを見せられた時 白人患者に比べて 黒人患者に有用な心臓手術を 勧める可能性は低いのです。中古車の交渉では、黒人は初期価格を７００ドル高く提示され、譲歩は少なかった。アパートの賃貸広告に黒人の名前を使ってCraigslistで回答すると、白人の名前を使って回答するよりも少ない回答が得られた。白人ばかりの陪審員は、白人の陪審員よりも黒人の被告人を有罪にする可能性が16ポイント高かったが、陪審員に黒人が一人だけいた場合は、両方とも同じ割合で有罪になった。医療データ、販売データ、住宅データ、刑事司法データなどどんなデータを見ていてもバイアスがかかっている可能性が高いことを示すために 疑問がある いや、最後の質問が面白いと言おうと思っていたんだが、黒人一人が陪審員になるというのは、ある種のアンカー効果があるような気がするんだが、多様性の話は後ですると思うが、ちょっとした多様性があるだけでも、様々なタイプの人がいて、様々な視点を持っていることを人々に思い出させてくれるんじゃないか？そうですね、それは素晴らしい指摘です。先ほどの質問にもありましたが、なぜアルゴリズムのバイアスが重要なのか？先ほど、人間も本当に偏っているということをお見せしましたが、なぜアルゴリズムのバイアスの話をしているのでしょうか？そして、人々はこの話を持ち出してきました。そこで、私はアルゴリズムのバイアスは非常に重要であり、話す価値があると考えていて、その理由を4つお話しします。1つは、機械学習がバイアスを増幅させる可能性があるということです。
私が好きなのは、CMUのMaria De-Arteagaの研究で、LinkedInから人々の仕事内容を取り出して、不均衡が複合的になっていることがわかったそうです。つまり、このようなアンバランスが悪化しているのです。基本的には、このような非対称性がありました。 アルゴリズムは、女性は外科医を推測しない方が 安全だと学習しています。アルゴリズムのバイアスが懸念されるもう一つの理由は、 アルゴリズムは人間の意思決定者とは非常に異なった使い方をしています。
読んでみたい推理は？誰かがそうだな 最初の答えは脳卒中になったら いつでも検査するの？ 確認バイアス？ オーバーフィット？ たまたま入院したから？偏ったデータ？EHRはこれらのイベントを記録する？データは、医学の特定の進歩の前に撮影されたからですか？これらは、これらはすべて良い推測です。私が探していたものではありませんが、良い考えです。 ノーと言うのは素敵な方法ですね 研究者がここで言っていることは、これは彼らの患者についてのもので、彼らは医療を多く利用している人とそうでない人がいて、それを一種の「医療の高効用対低効用」と呼んでいて、これには多くの要因があります。多くの要因があります。基本的に、医療をよく利用している人は、副鼻腔炎になったら医者に行くでしょうし、脳卒中になったら病院に行くでしょう。我々が測定したのは、症状のある人、医者に行って、検査を受けて、脳卒中と診断された人です。これは、脳卒中になった人の妥当な代理のように思われますが、代理は、正確には望んでいたものではありませんし、多くの場合、そのギャップが大きくなります。人は偏っていないのでしょうか？そうですね。はい、そうです。これまで何十、何十、何百もの研究がありましたが、いくつかを引用しますが、その全てがこのニューヨークタイムズの記事にリンクされています。しかし、医師が同じファイルを見せられた時 白人患者に比べて 黒人患者に有用な心臓手術を 勧める可能性は低いのです。中古車の交渉では、黒人は初期価格を７００ドル高く提示され、譲歩は少なかった。アパートの賃貸広告に黒人の名前を使ってCraigslistで回答すると、白人の名前を使って回答するよりも少ない回答が得られた。白人ばかりの陪審員は、白人の陪審員よりも黒人の被告人を有罪にする可能性が16ポイント高かったが、陪審員に黒人が一人だけいた場合は、両方とも同じ割合で有罪になった。医療データ、販売データ、住宅データ、刑事司法データなどどんなデータを見ていてもバイアスがかかっている可能性が高いことを示すために 疑問がある いや、最後の質問が面白いと言おうと思っていたんだが、黒人一人が陪審員になるというのは、ある種のアンカー効果があるような気がするんだが、多様性の話は後ですると思うが、ちょっとした多様性があるだけでも、様々なタイプの人がいて、様々な視点を持っていることを人々に思い出させてくれるんじゃないか？そうですね、それは素晴らしい指摘です。先ほどの質問にもありましたが、なぜアルゴリズムのバイアスが重要なのか？先ほど、人間も本当に偏っているということをお見せしましたが、なぜアルゴリズムのバイアスの話をしているのでしょうか？そして、人々はこの話を持ち出してきました。そこで、私はアルゴリズムのバイアスは非常に重要であり、話す価値があると考えていて、その理由を4つお話しします。1つ目は、機械学習がバイアスを増幅させる可能性があるということです。私が好きなのはCMUのMaria De-Arteagaの研究ですが、LinkedInから人々の仕事内容を取り出して、不均衡が複合化していることを発見しました。つまり、このようなアンバランスが悪化しているのです。基本的には、このような非対称性がありました。 アルゴリズムは、女性は外科医を推測しない方が 安全だと学習しています。
アルゴリズムのバイアスが懸念されるもう一つの理由は、アルゴリズムが人間の意思決定者とは実際には非常に異なって使用されているからです。
しかし、その周りのシステムは、実際には違うものになっています。一つは... 一つの、ある種の側面として、人々はアルゴリズムが客観的でエラーの無いものだと 考える傾向があります たとえ、人間が上書きするオプションが与えられていたとしてもです 場合によっては、上司からのプレッシャーもあるかもしれませんが、コンピュータの勧告に反対しないようにとのプレッシャーもあるでしょう。アルゴリズムは、不服申し立てのプロセスがない状態で実装される可能性が高いです。アルゴリズムは大規模に使用されることが多いです。アルゴリズムは大規模で同じバイアスを再現することができます。そして、アルゴリズムシステムは安価です。そして、これらはすべて相互に関連していると思います。多くの場合、アルゴリズミックシステムが実装されていると思います。エラーを見逃さないようにするには、よりコストがかかります。キャシー・オニールは著書『大量破壊兵器』の中で、これらのテーマについて多くを語っています。質問があるの？質問が二つ。うーん これは非常に深いテーマのように思えますが、 間違えないようにするためには専門的な専門知識が必要です。もしあなたがML製品を開発しているとしたら、学術機関に相談しますか？データ、製品、開発の三位一体がカルテットになると思いますか？倫理やデータ・プライバシーの専門家を巻き込んで？そうですね。だから、学際的な仕事はとても重要だと思います。私は... 私は間違いなく、あなたの特定のドメインが何であれ、そのドメインの複雑さを理解しているドメインの専門家を見つけようとすることに焦点を当てています。そして、私が思うに、学術的な分野の専門家の場合は、それにもよると思いますが、その分野の専門家を見つけることが重要です。業界でどのように、どのように、どのように、物事が起こっているのかを理解するのに十分な応用力を持っている人を選んだ方がいいと思います。でも、より多くの人を巻き込んで、より多くの分野の人を巻き込むというのは、全体的には良いアプローチだと思います。誰かがより優れたML技術を発明して発表し、次に大学院生がそれを使って顔認識を5%向上させ、小さなスタートアップがより優れた顔認識をするアプリを発表し、政府がそのアプリを使って絶滅危惧種の繁華街の歩行パターンを研究し、これらの成功の後、裁判所命令による監視のために、抑圧的な政府がその方法を使って民族を識別するようになり、大量虐殺が起こるのです。どんな段階を踏んでも大きな倫理的ミスをした人はいないのに、その結果は恐ろしいものです。私は、Amazonが利益を最大化するために、商品ごとに個人的にカスタマイズされた価格をすぐに提供することに疑いの余地はありません。多くの小さな原因のために効果が遠隔地にあるこのような倫理的なクリープに、どのように対処することができますか？これは、全部... ええ、これは、これは、これは、素晴らしい要約です、ええ、これらのことは少しずつ起こる可能性があります。このレッスンの最後に、実装するためのツールについてお話しします。これまで以上に、もう少し先のことを考えることが必要だと思います。特に、この研究では、群衆の中の抗議者をどうやって見分ければいいのかという例を見てきました スカーフやサングラス、帽子をかぶっていても その研究者が質問された時には、「悪人がこれを使うとは思いもしなかった。だから、私が思うに、誰もがもう少し先のことを考える能力を身につけるべきだと思います。その一環として、チームで、できれば多様なチームでこれを行うのは素晴らしいことです。この数ヶ月の間に、コンピュータビジョンの問題では、YOLOの生みの親であるJoe Redmon氏が、コンピュータビジョンにはもう手を出さないと言っています。考える必要がある時もあると思います
それから、私が思うに、本当に積極的に考えているのは、どのように、どのようなセーフガードを配置する必要があるのか、一種の、対処するために、起こっている悪用。はい？キャシー・オニールの言葉が好きな人がいたので言いたかったのですが 特権者は人間によって処理され、貧乏人はアルゴリズムによって処理される」というキャシー・オニールの言葉がとても気に入ったようで、もっと学びたい、もっとキャシー・オニールの言葉を読みたいと言っていました。お勧めの本はありますか？あります。ありますよ。キャシー・オニールは数学の博士号を持っていますが、多くの良い記事を書いています。そして、それは... この本では、アルゴリズムが様々な場所でどのように使われているのか、多くのケーススタディが紹介されています。それで、ある種の... 人間は偏っている、なぜか、なぜアルゴリズムの偏りについて騒ぐのか』の要約 そこで、1つは先ほど見た 機械学習はフィードバックループを作ることができます つまり、世界で何が起こっているかを観察するだけでなく、結果を決定し、将来のデータを決定することができるのです。機械学習はバイアスを増幅させることができます。アルゴリズムと人間は実際には非常に異なる使い方をしていますが、その上でテクノロジーは力であり、それには責任が伴います。
私たち全員がディープラーニングにアクセスできるようになるためには、私たちはまだ世界の中で、この技術を利用できる非常に幸運で、ごく一部の人しかいないと思います。次のセクションでは、分析というか、一歩、一歩、私たちにできることを説明しますので、ここで一息つくのもいいでしょう。では、7分後の7時45分にお会いしましょう。それでは、7分後の7時45分に再会しましょう。最初の質問は、「これをやるべきなのか」ということと、やるべきでない仕事があるかもしれないということです。含意がデザイン（技術）ではない場合』という論文があります。技術者である私たちは、問題に対して、「これに対応するために何を作ったり、作ったりすることができるのか」ということで対応することが多いのですが、「何も作らない」「何も作らない」ということが答えになることがあります。研究の一例として、私が思うに、非常に大きなマイナス面があり、プラス面がないと思うのは、特に少数民族の人たちの民族性を特定することでした。中国のウイグル人を特定する研究がありましたが、これは中国西部のイスラム教徒の少数民族で、それ以来、100万人以上が収容所に入れられています。私は、これは非常に、非常に、有害な、有害な研究だと思います。私が思うに、少なくとも2つの試みがありました 誰かのセクシュアリティを識別するために 分類器を構築しようとしています それはおそらく、様式的な違いを 拾うだけですが、これは非常に危険なことです 多くの国では同性愛者であることは違法なので 多くの国では、ゲイであることは違法です。これは私への質問ですが 答えはわかりません そうですね タイトルにあるように、スタンフォード大学の科学者がゲイダーを作ったと言っています。あるポイントを証明するために、「最もお粗末な」AIを使っています。私の理解では、その意味するところは、「おい、高速AIのレッスン1を使えばいいだろう」ということです。1～2時間後にはこれが作れる。誰でもできるようになる。今ある技術で簡単にできることを実証する役割がある、という考え方についてはどう思いますか？ええ、それは私が思うに... GPT-2を使ったOpenAIは、デュアルユースや、デュアルユース技術の責任あるリリースとは何か、そして何が可能なのかという意識を高めるための責任ある方法とは何か、ということについて、議論を深めようとしていたと思います。セクシュアリティの問題を研究してきた研究者の場合、私にはそれが問題解決につながるものであることを確認するために、どのように研究を行っているのか、誰と協力しているのかを十分に考えているようには見えませんでしたが、あなたの言う通り、おそらく今、広く利用できるものを人々に知ってもらうための場所はあると思います。情報セキュリティ分野でのペンテストを少し思い出すよ・・・ ああ、そこでは、ある種、考えられている・・・ まあ、会社のシステムに侵入するのは些細なことで簡単だと指摘する倫理的な方法がある。そうですね そうですね そうですね 倫理的な方法があることには同意しますが、それが何であるかを決定するためには、私たちコミュニティとしてまだやるべきことがあると思います。他にも、データにどのようなバイアスがかかっているのかということも考慮しなければなりませんが、それを強調しておきたいと思います。すべてのデータにはバイアスが含まれています。最も重要なことは、データセットがどのように作成されたのか、その限界は何かを理解し、バイアスの影響を受けないようにすることです。この分野で最も有望なアプローチは、Timnit Gebruの'Datasheets for Datasets'のような研究だと思います。
どのような目的で、どのように維持されているのか、そしてそのリスクは何かを知っています。 データのコンテキストを本当に意識してください。  コードやデータは監査できますか？  特に米国では、民間企業が刑事司法制度や雇用に影響を与えるソフトウェアを作っている場合、多くの問題を抱えています。 そうなると、多くの問題が発生します。 異なるサブグループのエラー率を見ることは本当に重要で、それがジョイ・ブオラムウィニの研究の非常に強力なところです。 もし彼女が肌の薄い人と肌の黒い人、男性と女性を比較していたら、肌の黒い女性に対してアルゴリズムがどれだけ悪い結果を出しているかはわからなかったでしょう。 単純なルールベースの代替案の精度はどうなのでしょうか？ これは先週ジェレミーが話していたことだと思いますが、ベースラインを持つことは、機械学習の良い、良い実践のようなものです。  しかし、特にCOMPASの再犯率のようなケースでは、この130変数のブラックボックスは、3変数の線形分類器よりもあまり良い結果を出していません。  これは、なぜこれを使用しているのか、なぜこれを使用しているのか、という疑問を投げかけています。 そして、データにはエラーがあるので、異議申し立てやミスを処理するためにどのようなプロセスがあるのでしょうか。 バグがあるかもしれませんし、実装にも問題があるかもしれませんし、それを解決するためのプロセスが必要です。 そうですね。 今から説明してもらえますか？ すみません、自分で質問しているので、誰も全く投票していません。 この考えの背後にあるものは何ですか？ 単純なモデルは他のすべてのことが同じなら単純なモデルを選ぶべきだと言いたいのですか？ このベースラインはそのためにあるのか？ もしそうだとしたら、その背景にはどのような考え方があるのでしょうか？ COMPAS再犯アルゴリズムでは... ブラックボックスの性質に 関連していると思います  多分、内省する方法があれば...何かに訴えることで自分たちの権利がどうなるのか。  しかし、単純なものでも同じように機能するのに、なぜより複雑なものを使うのか、と言いたいですね。  そして、それを作ったチームの多様性については後ほど、このレッスンの後半で詳しくお話します。 さて、最初はジェレミーでしたが、私は先生ではありません。 だから実際には、"Jeremy, Do you think transfer learning makes this tougher, audits the data that were led to the initial model? "ということになります。 "ジェレミー レイチェルに聞いてくれ "という意味だと思うわ いや、彼らは、彼らはあなたに尋ねていた。 それは、それは良い質問です。 繰り返しになりますが、重要だと思います。  おそらく両方のデータセットについての情報を持っていることが重要だと私は思います。 あなたはそれについて何か考えはありますか？  彼女が言ったこと。  そして、バイアスや公平性、説明責任や透明性は重要ですが、それがすべてではありません。  これは明らかに非倫理的なものですが、公正で説明責任があり、透明性があり、これらの条件を満たす方法を提案しています。  このことは、この枠組みの限界を示していると同時に、どのような枠組みを使っていても、明らかに非倫理的なものを見つけようとするための良いテクニックでもあります。 そのテクニックは本当に気に入っています。 哲学の中で一番好きなテクニックです。 哲学で一番好きなテクニックです。 この前提が与えられているから、これが何を暗示しているのか、と言います。 そして、直感的に明確に言っている暗示された結果を見つけようとするのです。 これは本当に、そうですね、大学を卒業して得た一番の 哲学的思考ツールです。  今回のように、時にはそれを使って大いに楽しむこともできます。  ありがとうございました。  それでは次の大きなケーススタディの種類ですが あなたのトピックは ディスインフォメーション（偽情報）です  2016年にヒューストンで ハート・オブ・テキサスというグループが イスラム教センターの外での 抗議活動について投稿しました  武装して来るようにと  別のフェイスブックのグループが 宗教の自由と包摂性を支持する 抗議行動を投稿しました そのようにして
信教の自由を支持する側の人たちの方が多かったです。 ヒューストン・クロニクル紙の記者は 奇妙なことに気づいたそうですが 主催者側とは連絡が取れませんでした  そして何ヶ月も経ってから、双方がロシアのトロールによって組織されていたことが明らかになった。  このように、抗議している人たちは、本物のアメリカ人で、自分たちの信念に抗議していたのですが、ロシアの工作員によって完全にハメられていた方法で抗議をしていたのです。 誤報について考えるとき、それはそうではありません。人々はしばしば、いわゆるフェイクニュースのことを考えます。 しかし、本当に偽情報とは、しばしば組織的な操作のキャンペーンのことであり、それには、ある種、すべての真実の種が含まれています。 また、誤解を招くような文脈も含まれています。そして、それに巻き込まれるような、非常に誠実で誠実な人々を巻き込むことができます。 今年の秋に発表された報告書によると、スタンフォード大学のインターネット観測所でレニー・ディレスタとアレックス・ステイモスが研究しています。  アフリカの６つの国で活動していました  地元のニュースソースと 思われていました   マルチプラットフォームでした 人々にWhatsappや電報のグループに参加するように勧め、現地の人々をレポーターとして雇っていました。 文化やスポーツ、地元の天気などです。 つまり、非常に親ロシア的な報道が多かったのです。  しかし、その後、様々なトピックをカバーするようになり、これは一種の非常に洗練されたディスインフォメーションの段階です。 多くの場合、地元の人を雇っていました。 ロシアの例を2つ挙げました。 ロシアは確かに偽情報を独占しているわけではありません。 多くの人々が関与し、それを生産しています。 話題性のある話題では、コロナウイルスとコビド19について、多くの誤報がありました。  私は、個人的なレベルでは、偽情報を見抜くためのアドバイスを探している人や、愛する人と共有したい人は、マイク・コールフィールドをフォローするのが良いでしょう。  ...それに、彼は互角だ   彼は@holdenをツイッターでつぶやき コビド19についてのブログを始めたが 彼は彼のアプローチについて語る 12年間学校で訓練を受けてきたと  しかし、プロのファクトチェッカーはその逆で、あるページにたどり着いたらすぐにそのページから離れて、より質の高い、より質の高い情報源を探して、裏付けを見つけられるかどうかを確認します。 コーフィールドはまた、これまで教えられてきた多くの批判的思考のテクニックには長い時間がかかるという考えを本当に推進しています。  30秒でできるアプローチを人に与えた方がいいんです 30秒だけ何かをしているだけでは失敗の証明にはなりません  しかし、30分もかかるものを持っているよりは、確認した方がいいでしょう。 だから私はこれを資料として出したかったのです。 lessons.checkplease.ccにあるレッスンのセットのようなものです。 そして、彼は、彼は教授です。 私が今教えているデータ倫理学のコースでは、最初のレッスンを最初の半分にしました。私は私の最初のレッスンをしました前半は、コロナウイルスの偽情報についてのようなものです。 YouTubeで公開した すでに共有した フォーラムにリンクを追加しておきます。もし、もっと詳しく知りたい場合は、ここにある短い情報よりも、  でも、話を戻しますが、偽情報とは何か？ エコシステムとして考えることが重要です。単一の投稿やニュース記事だけではありません。しかし、それは本当にこのようなより広い生態系なのです
クレア・ワーテル初稿ニュースは、この分野の第一人者であり、ジャーナリストのトレーニングや、ジャーナリストが責任を持って報道する方法について多くのことを行っていますが、増幅のトランペットについて語っています。そこからRedditやYouTubeの陰謀論コミュニティへ、そしてより主流のソーシャルメディアへ、そして専門的なメディアや政治家に拾われていきます。このようなマルチプラットフォームであるため、多くの場合、キャンペーンは異なるプラットフォーム間のルールや抜け穴を利用している可能性があります。オンラインでの議論は非常に重要です なぜなら、私たちは自分の意見を形成するのに役立つからです。私たちは自分自身をかなり独立心の強い人間だと思っていると思うので、これは難しいことですが、私たちは社会的な存在として進化してきました。人々はオンラインであらゆる種類のことを議論します。ここでは、アメリカは国防費を削減すべきかどうかについてRedditで議論していて、あなたは間違っている、国防費はアメリカの軍事費の支出がいかにひどいかを示す良い例だ、というコメントがあります。私は、軍への支払いを止める、のように聞こえることを意図していませんでした、私は、私たちが法案を支払うことができないと言っているわけではありませんが、国防費を削減することは理にかなっていると思います。unpopularopinion, news, changemyview, netneutrality. これらは良い推測だが、間違っている。でも、私はあなたの言い方が大好きです。これは全部何から来ているのかというと それは、サブsimulatorgpt2 ohからですので、これらのコメントはすべてGPT-2によって書かれたものであり、これは良い楽しみの中にあります。サブredditでは、GPT-2で来るのはOpenAIの言語モデルであることが明記されていました。多くのグループが研究の軌跡を辿っていたので、1年ほど前にリリースされたと思いますが、ユニコーンの話を読むべきでしょうか？皆さんの多くはおそらくご覧になったことがあると思いますが、これは桜の花を選んだものですが、それでも非常に印象的です。人間が書いたプロンプトは 言語モデルに与えられました "衝撃的な発見がありました。科学者たちはアンデス山脈の未踏の谷間に住むユニコーンの群れを発見しました。研究者にとってさらに驚くべきことは、ユニコーンが完璧な英語を話していたという事実でした。そして、次の部分はすべて言語モデルによって生成されています。つまり、これはディープラーニングモデルが生成したもので、コンピュータモデルが生成した「Dr. ホルヘ・ペレスは、岩と銀色の雪の2つのピークに囲まれた自然の噴水のように見えるものを見つけました。ペレス博士と他の人たちは、その後、谷の中にさらに踏み込んだ。私たちが1つのピークの頂上に到達する頃には、水は青く見え、上部にはいくつかの結晶がありました。ペレスと彼の友人たちは、ユニコーンの群れを見て驚いた。これらの生き物は、それらを見るためにあまりにも多くを移動することなく、空気から見ることができました。彼らはとても近くにいたので、彼らは彼らの角に触れることができました。これらの奇妙な生き物を調べている間、科学者たちは、生き物がまた、いくつかのかなり規則的な英語を話していることを発見しました。ペレスは述べています 彼らは共通言語を持っていることを 例えば見ることができます 方言や弁証法のようなもの" これは本当に説得力のある散文だと思います コンピュータがこのような形で生成したものです また、コンピュータがGANとして絵を生成するという進歩も見てきました。ケイティ・ジョーンズはLinkedInにロシアとユーラシアの研究者としてリストアップされていました。彼女は主流のワシントンのシンクタンクの何人かとつながっていましたが、AP通信は彼女が実在の人物ではないことを発見しました。この写真はGANによって生成されたものです。それで、これは、ちょっと怖いことだと思います。生成されたテキストがどれだけ説得力のあるものかを考え始めると、写真と組み合わせると オンラインでの議論が偽物の工作員に振り回されてしまう危険性があります。世論に影響を与える可能性があります だから...ああ、これは...まあ、話を続けるよ。で、時を遡って2017年、FCCはネット中立性の廃止を検討していました。
しかし、私は、これは、人間の政府がどのように機能するのかということに多くの意味があると思います。人間が社会の中にいることには何かがあると思います 規範やルールや仕組みがありますが それは本当に弱体化させたり、困難にしたりします GPT2が発表された時、fastaiの共同設立者であるジェレミー・ハワードはVergeの記事の中で次のように述べています。我々はtwitter、メール、ウェブを完全に埋め尽くす技術を持っていて、合理的に聞こえる、文脈に合った散文で埋め尽くすことができます。そこで、これに対処するためのある種のステップとして、電子署名の必要性がある。 AIに関するアレン研究所の責任者であるオレン・エツィオーニ氏は、このことについてHBRに書いています。彼は、「AIの最近の発展は、文書、写真、音声記録、ビデオ、オンラインでの身分証明書の偽造が、かつてないほど簡単に起こる時代を指し示している」と書いています。AIは、高忠実度の偽造を安価で自動化し、民主主義、セキュリティ、社会に潜在的に悲惨な結果をもたらす準備ができている」とし、認証の手段としてデジタル署名の種類を提案しています。 ここで言いたいのは、このような偽造や偽物のリスクは、真実を語る人々を弱体化させるということです。 また、世界中の抗議活動や様々な社会運動について多くの研究をしているZeynep Tufekci氏によると、彼女はしばしば内部告発者や反体制派の人たちに声をかけられることがあるそうですが、彼らは多くの場合、命をかけて不正行為や人権侵害のようなことを公表しようとします。"ああ、あの写真は写真をコピーしたもので、捏造されたものだ" 内部告発者や反体制派にとって、今、大きな問題になっています。
そして、このトピックで絶対にフォローすべき人物は、レネー・ディレスタです。彼女は昨年、マイク・ゴドウィンと一緒に素晴らしい記事を書いています。情報操作と悪質な行為者の協調的なキャンペーンが見られ、スタンフォード大学でも重要な研究が行われていると思います。 では、偽情報についての質問は？
さて、次のステップは倫理的基盤です。 さて、このファッタイ・アプローチですが... 私たちがいつも好んでいるのは... 全ての物事を実際のケーススタディに基づいて 進めていくことです... その前に、それを支える理論に入ります...
そして、「アベンジャーなら何をする？ これを提案してくれた ケイシー・フィエスラーに脱帽です  そして、それは3つの一般的な倫理哲学のようなものを 通しています 利用主義とアイアンマンの例を挙げています。私は、キャプテン・アメリカを例にして、善良なデontological Ethicsと一致させようとしているのですが、これは右に固執しています。そして、美徳倫理学、ソーは名誉の掟に基づいて生きています。
レイチェル：はい？質問です。ソーシャルメディア会社は中立的なプラットフォームに過ぎず、問題のあるコンテンツはユーザーの全責任であるという議論について、あなたはどこに立っているのでしょうか？ レイチェル: だから、プラットフォームが中立的だとは思いません。 そして、ハラスメントは多くの人をプラットフォームから追い出す可能性があることを念頭に置いて、それらの決定の多くは、「ああ、執行がなければ誰もが言論の自由を守ることができる」ということではありません。誰が黙らされるかを変えているだけなんです。プラットフォームは出版社ではないので、本当に難しい問題がたくさん出てくると思います。プラットフォームは出版社ではありませんが、出版社がかつて行っていた機能の多くを、中間的な領域で行っていると私は考えています。つまり、新聞のように、どの記事が掲載されているかをキュレーションするようなものです。つまり、私が言いたいのは、民間企業が持つには不快な力の大きさだということです。 そうですね、だからこそ多くの難しい決断を迫られることになります。
しかし、私は、私は彼らが中立であることを信じていません。  だから、この部分のために、私は以前にMarkkula Centerに言及しましたが、間違いなく彼らのサイト、Ethics in Technology Practiceをチェックしてください。  彼らのサイトにはたくさんの有用なリソースがあります。 ここでは、比較的簡単に例を挙げて説明します。  このサイトでは、技術者が問いかけることができるような、ある種のデontologicalな質問が書かれています。これは、人間論的倫理学、つまり、あなたが尊重したいと思うかもしれない様々な権利や義務を持っているということです。  これにはプライバシーや自律性のような原則が含まれます。 各ステークホルダーの尊厳や自律性はどのようにしてこのプロジェクトによって影響を受けるのでしょうか。  信頼と正義のどのような考慮事項が関連しているか。 このプロジェクトは他の人への矛盾した道徳的義務を伴うか。 いくつかのケースでは、あなたは知っているように、あなたが考慮している異なる、異なる権利や義務の間にある種の競合があるでしょう。  そして、これは、これは一種の例であり、彼らはより多くの、より多くを持っている、彼らはあなたが尋ねることができる質問の種類の読書の中で、一種の評価するときの、ちょうどの、さらにはどのようにあなたが評価するかどうか、一種のかどうか、プロジェクトが倫理的であるかどうか。 結果論的な質問 -- 誰が直接影響を受けるのか、誰が間接的に影響を受けるのか？ 結果論的な質問 - 誰が直接影響を受けるのか、誰が間接的に影響を受けるのか、（結果論的な質問には共通の善だけでなく、実利主義も含まれます）、集合的な効果は害よりも多くの善を生み出すのか、そしてどのような善と害の種類があるのか？心理的、政治的、環境的、道徳的、認知的、感情的、制度的、文化的など、関連するすべての種類の害と利益について考えているか？ また、長期的、長期的な利益と害を見て、その後、誰がそれらを経験するのか？害のリスクが、最も力のない者に不釣り合いに降りかかるようなものなのでしょうか？ 誰が利益を得るのか？ 二重使用を考えたことはありますか？ これらは、プロジェクトを評価しようとするときに、また、このような質問をすることができます。 また、マーククラセンターの推奨事項としては、これはチームやグループで行うには素晴らしい活動だと思います。 そうなんですか？ このツールがどれだけ有用であるかを 誇張することはできないと言おうと思いました。  "ただの質問のリストだ "と思っていたが  ええ、でも、私にとっては、これは、あなたがどう対処するか、どう対処するかのための大きな武器になるんです。 誰かが、正しい質問を考えるのを 手伝ってくれているようなものです。 そして、その質問を、多様な人たちと一緒に 議論してみましょう。 つまり、これは、これは、これは金だ。 これを読み返してはいけません。  読み飛ばしてはいけない  仕事に持って行け  次にプロジェクトについて話す時に使うんだ 本当に素晴らしい、素晴らしい質問集です。  あなたのツールボックスの中の偉大なツールです。 そして、オリジナルのリーディングに行くと、質問についてさらに詳しく、より精巧に書かれています。 そして、彼らは一種の5つの潜在的な倫理的なレンズの要約を与えます。  権利アプローチ - どの選択肢が利害関係を持つすべての人の権利を最も尊重するか？ 正義のアプローチ - どの選択肢が人々を平等に、あるいは比例して扱うか？  そして、この2つはどちらもデontologicalです。 功利主義的アプローチ - どの選択肢が最も善を生み出し、最も害を及ぼさないか？ 共通善のアプローチ - どの選択肢が、一部のメンバーだけでなく、全体としてのコミュニティに最もよく役立つか？ そして、ここでの３と４はどちらも結果主義者である。 そして - 美徳アプローチ、どのオプションは、私がなりたい人のようなものとして行動するために私をリードし、それが関与することができ、あなたが知っているの特定の美徳を知っている、あなたは信頼性や真実や勇気を大切にしていますか？ チームメイトと一緒に勉強したり、職場で話したりするのに最適な活動です。マーククラセンターには、いくつかのケーススタディがあります。 それが、あなたの行動にどのような影響を与えているのか、正しい行動とは何かについてのあなたの考え方です。 プログラマーやコンピュータプログラマー、データサイエンティストにとってはちょっと変な話ですが、ある意味ではfast.aiやpandasのようなツールだと思っています。  これは脳のためのソフトウェアツールのようなもので、あなたの思考をデバッグするのに役立つようなプログラムを作るのを助けてくれます。  いいね ありがとうございます  先ほど誰かが持ち出してくれたように、倫理哲学への西洋中心のイントロダクションのようなものでしたが、他にも倫理的なレンズや他の文化があります。 私は特にマオリの世界観について少し読んでみました。  自分の理解に自信があるわけではありませんが、それを表現できるほどの自信があるわけではありません。
他にも、他にも倫理的なレンズはありますが、私は非常に思うのですが、このような技術の影響を受ける人々の倫理的なレンズが重要なのです。  これは特別な問題で、私たちには多国籍企業がたくさんあります。 今、ニュージーランドでは興味深いプロジェクトが行われていて、ニュージーランド政府はAIのアプローチを検討していて、少なくとも表向きはマオリ族の意見を取り入れたいと考えています。 これはちょっとした理論的な話です。 でも次は、職場で実践できるようなことをお話したいと思います。  これはマーククラセンターのものです。  これは彼らの倫理ツールキットで、私が特に気に入っているものです。  すべてを網羅するつもりはありませんが、私のお気に入りのものをいくつか紹介します。  ツール1は倫理的リスクスイープで、これはペンテスト（ジェレミーが先ほどセキュリティの話をしました）のような考え方に似ていると思いますが、定期的にスケジュールされた倫理的リスクスイープを行うというものです。 脆弱性が発見されなかった、脆弱性が発見されたというのは一般的には良いニュースですが、それは無駄な努力だったという意味ではありません。 そして、あなたはそれをやり続け、探し続け、倫理的リスクを探し続けるのです。 ちょっと待って  そして、最初のプロジェクト開発で何らかのリスクを見逃したと仮定する。  また、新たな倫理的リスクを発見したチームメンバーに報酬を与えるようなインセンティブを適切に設定する必要があります。 以上です。 ここでいくつかのコメントがあります。  ここでの私のコメントは学習率ファインダーについてのものですが、正確な数学的定義をわざわざ説明するつもりはありません（私が数学が下手だということもありますし、どうでもいいことだということもあります）。 だから、それは私が私の言語モデルに挨拶したのであって、本当の私ではないのです。 ありがとうございます。 これはツール１です。これはツール１です。これはレッド・チーミングのようなもので、組織内にチームを作り、脆弱性を見つけようとしています。  ツール3、私が本当に好きなもう一つのもの、「倫理的なサークルの拡大」。  誰の利益、欲望、スキル、経験、価値観を思い込み、実際に相談するのではなく、思い込んでいたのは誰なのか？ 直接影響を受けるすべての利害関係者は誰ですか？そして、私たちは実際に彼らの利益が何であるかを彼らに尋ねたことがありますか？ 私たちが想定していなかったこの製品を使うかもしれない人、あるいは私たちが当初意図していなかった目的のためにこの製品を使うかもしれない人は誰だろうか？  ワシントン大学のテック・ポリシー・ラボでは「Diverse Voices」というプロジェクトを実施しました。 これについての学術論文と、これをどのように実装するかについての長いガイドのようなものがあります。  しかし、このアイデアは、新技術を中心に専門家パネルをどのように組織するかというもので、彼らはいくつかのサンプルを行いました。 一つは、拡張現実を検討していて、障害者、元服役中の人、女性を対象にした専門家パネルを開催して、彼らの意見を聞き、それが含まれているかどうかを確認しました。 また、自律走行車の戦略文書についても、若者や車を運転しない人、非常に低所得者を対象にした専門家パネルを開催しました。 このように、社員の輪を広げ、より多くの人を参加させ、社員の中にはあまりいないような視点を得るために、どのようにしてこのようなことを設定していけばいいのかわからないという方には、素晴らしいガイドだと思います。  だから、このリソースがあることをお知らせしたいのです。 ツール6は「ひどい人について考える」です。  私たちはしばしば、あなたが知っていると思うので、これは難しいかもしれませんが、私たちは、あなたが知っている、前向きに考えているか、またはひどい意図を持っていない自分自身のような人々のことを考えています。  しかし、実際には、私たちが作ったものを悪用したり、盗んだり、解釈を誤ったり、ハッキングしたり、破壊したり、兵器化したりする可能性のある人のことを考えてみてください。 誰が驚くほどの愚かさや非合理性でそれを使用しますか？ どのような報酬、インセンティブ、開口部、私たちのデザインは、それらの人々のためにうっかり作ってしまったのでしょうか？ そして、メトリクスのセクションを思い出してみてください。  そして、どうやって報酬やインセンティブを取り除くことができるのでしょうか？ これは重要なステップです。  そして
そして、ツール7はClosing the Loop, Ethical Feedback and Iterationで、これは決して完成したタスクではないことを覚えていて、信頼できるデータを提供してくれるフィードバックチャネルを特定し、このプロセスを品質管理やユーザーサポートと統合し、倫理的な反復のための正式な手順と責任の連鎖を開発することです。 そして、このツールを見て、私はAlex Feerst氏のブログ記事を思い出しました。  Alex Feerstは以前Mediumの最高法務責任者を務めていました。  1年前だったと思いますが、彼は信頼と安全の分野で働いてきた15人か20人にインタビューをしました。  信頼と安全にはコンテンツのモデレーションも含まれますが、コンテンツのモデレーションだけではありません。  その中で、私がとても気に入ったアイデアの一つが、ある人の話でした。その人たちの多くは、大企業で何年も信頼と安全に携わってきた人たちで、その中の一人はこう言いました。 もしこのままでは、製品とエンジニアリングがモーツァルトであり、他の誰もが執事のアルフレッドであるように、大きなものは変わらないでしょう。 このように、信頼性と安全性をより良く統合する必要があるということについては、少なくとも2人の参加者が話していると思います。 信頼と安全性をより密接に製品や環境と統合することで、それをより直接的に組み込むことができ、何が間違っているのか、どのようにして、どのように設計することができるのかについて、よりタイトなフィードバックループを持つことができるようになります。 これらは、関連性があると思われるブログ記事や研究にリンクしていますが、Markkula Centerの技術倫理ツールに触発されたもので、あなたの会社や会社で実装することを考えてみてください。 次は多様性についてお話したいと思います。  機械学習の研究者のうち女性は12％しかいません。  これは非常に悲惨な統計です。  また、人種の多様性や年齢の多様性、その他の要因が極端に不足しています。  ダイバーシティが何に役立つのかという一種のポジティブな例で、Quoraで初期の、初期のエンジニアで、後にPinterestで働いていたTracy Chouさんの投稿には、最初の機能（だから彼女はQuoraで最初に働いていた5人の従業員の1人のようなものだったと思う）、「私がQuoraで働いていたときに最初に作った機能はブロックボタンでした。 私は個人的にサイト上で反感を買い、罵倒されていると感じていたので、この機能に熱心に取り組んでいました」と書き、「もし彼女がそこにいなかったら、彼らはすぐにブロックボタンを追加しなかったかもしれないことを知っているでしょう」と続けています。  これは、多様性のあるチームを持つことがどのように役立つかの直接的な例のようなものです。 だから、多様性を高めたいと考えている人への私からの重要なアドバイスは、人々が職場について語るパイプラインの反対側の端から始めることです。  5年前に書いたブログ記事にもありますが、「テック業界での女性の活躍はパイプラインの問題だと思っているなら、注意を払っていなかったことになる」と。 先月ジェレミーと私がコヴィド19の記事を書くまでは これが私が書いた中で最も人気のある記事でした だから私が書いた中では ２番目に人気のある記事です   しかし、私はこの中でトン、トン、トンの研究にリンクしています。 理解すべき重要な統計としては、技術系で働く女性の41％が離職しているのに対し、男性の17％は離職しているということが挙げられています。 もし女性の離職率が非常に高いままであれば、より多くの女性をコーディングや技術分野に採用しても、この問題に対処することはできないでしょう。YouTubeのチャットを少し覗いてみましたが、みんなが質問しているのが見えました。  私はただ、レイチェルと私はそれを見ていないことを人々に思い出させたいと思います。もし質問したい場合は、フォーラムのスレッドを使ってください。もし気に入った質問があれば、このような質問をしてください。
倫理的な問題を発見した人に報酬を与えるという、あなたの考えは素晴らしいと思います。 女性がテック業界を離れる可能性が高い理由は、200冊以上の書籍やホワイトペーパーの記事のメタ分析で明らかになっていますが、女性がテック業界を離れる理由は、不公平な扱いを受けたり、低賃金であったり、男性の同僚よりも早く昇進できる可能性が低く、昇進できないからです。  そして、多様性への取り組みが白人女性だけに焦点を当てて終わることがあまりにも多く、それは間違っています。  幹研究に従事する60人の有色人種の女性へのインタビューによると、100％の女性が差別を経験しており、彼らの特定のステレオタイプは人種によって異なることがわかりました。  ですから、多様性への取り組みにおいて、有色人種の女性に焦点を当てることは、最優先事項として非常に重要なのです。  同じ台本を読んでいても、男性の声は女性の声よりも説得力があり、事実に基づいた論理的なものと認識されるという研究結果が出ています 研究者たちは、女性がフィードバックや人格批判、業績評価を受けることが多いのに対し、男性は具体的なビジネス成果に結びついた実行可能なアドバイスを受けることが多いことを発見しました。
女性がメンターシップを受けるとき、それは自分がどう変わっていくべきか、どうやって自己認識を深めていくべきかというアドバイスであることが多いです。  男性がメンターシップを受ける場合、それは自分の権威に対する公的なお墨付きを得ることです。 この中で統計的に昇進に結びついているのは1つだけで、それは権威の公的な承認です。 これらの研究はすべて、私が書いた「女性が技術職を辞める本当の理由」とその対処法にリンクしています。 それは質問ですか？ジェレミー   興味があれば、この2つのブログ記事にリンクしています。  そして、これは職場での取り組みを開始するべき場所だと思います。 もう一つの問題は、技術面接は誰にとってもひどいものだということです。 だから今は、すでにあなたの職場にいる人たちから一歩引いて、面接のプロセスを考えてみましょう。 そして、彼らは、技術的な面接を少し悪くしない方法についての記事を書いて、研究のトンを通過しました。 面接の問題は難しい問題だと思います。 人にうまくインタビューするのは非常に時間がかかり、難しいことだと思います。 しかし、私が出くわした研究の中で最も興味深いものは2つあります -- 1つはTriplebyte社からのもので、これはリクルート会社で、面接をして、一種の人々のためのこの第一次技術面接を行い、その後、彼らはY Combinator（それはY Combinatorの会社です）で面接をして、彼らはY Combinatorの会社で面接をしています。 彼らは非常に興味深いデータセットを持っていて、全員に同じ技術面接を行い、どの企業から内定を得たかを見ることができます。  彼らの調査から得られた第一の発見は、各企業が求めるプログラマーのタイプは、その企業が必要としていることややっていることとはほとんど関係がなく、むしろ企業文化や創業者のバックグラウンドが反映されていることが多いということでした。  これは理にかなっていますが、特定の人にとっては、他の人よりもずっと簡単にできることです。  特に、VCの資金調達における男女や人種の格差を考えると、大きな違いが出てくると思います。  そうですね。 実際、私がベイエリアで創業者になった時にVCから聞いた最も一般的なアドバイスは、「リクルートの際には、自分のネットワークから、できるだけ同じ志を持ち、似たような人を集めることに重点を置くべきだ」というものでした。これは私が聞いた中で最も一般的なアドバイスでした。  これは私の意見には賛否両論あるかもしれませんが、最終的には、なぜ人は自分のネットワークから採用するのか、その理由を理解しているような気がしますし、長期的には全員が成長する必要があると思います。特に白人は、より多様なネットワークを構築する必要があります。 それは10年単位のプロジェクトのようなものです。採用時にすぐにできることではありませんが、友人や信頼できる知人の多様なネットワークを、時間をかけて構築していく必要があります。 でも、そうですね、ジェレミーにそのような視点をありがとうございました。 それから、他の研究のようなものです。私が本当に面白いと思ったのは、彼らが人々に履歴書を渡した研究です。  あるケースでは、ある履歴書には学歴が多く、ある履歴書には実務経験が多く書かれていたのですが、あるケースでは、ある履歴書には学歴が多く、ある履歴書には実務経験が多く書かれていました。  そして、性別を変えて、1人は女性、1人は男性（または男性名と女性名）としました。 基本的には男性の方が採用されやすく、その場しのぎの正当化をして、「ああ、彼の方が学歴が豊富だから彼を選んだんだ、あるいは彼の方が実務経験が豊富だから彼を選んだんだ」というようにしていました。  その場しのぎの正当化をするのは非常に人間的なことだと思いますが、それは採用に確実に現れる現実的なリスクです。 最終的には、AIや、私が開発したり、企業が財務的な優位性、つまりより多くの利益を得るために実装したりした他のテクノロジーは、倫理的な行動をインセンティブするための最善の方法は、財務的なリスクや評判のリスクを良い行動に結びつけることなのかもしれません。  ある意味では、企業が次のEquifaxのようになりたくないという理由でサイバーセキュリティに投資しているのと似ています。 草の根のキャンペーンは、AIの利用に関して、より良い倫理的な行動に役立つのでしょうか。 ああ、それは良い質問ですね。サイバーセキュリティには多くの例えがありますが、長い間、なぜサイバーセキュリティに投資しなければならないのかを上司に説明するのが難しかったり、苦労したりしていました。
特に、サイバーセキュリティは、機能していても気づかないようなものだからです。 だから、それは、ケースを構築するのは難しいかもしれません。 だから、草の根キャンペーンの場所があると思います。  また、政策についても少しお話しします。 このようなケースでは、必ずしも意味のある代替案がない場合もあります。
だから、私は思うのですが... ...独占はそれを難しくしているような気がします。 それはそれでいい、いい質問だ。  さて、次のステップは... このスライドには、政策の必要性が書いてあります 企業が行動を起こすためには何が必要なのでしょうか？先ほども言いましたが、国連の調査員が、Facebookがロヒンギャ虐殺で決定的な役割を果たしたことを発見しました。  私が読んだ中で最高の記事はティモシー・マクラフリンによるもので、彼はミャンマーにおけるフェイスブックの役割について非常に深く掘り下げています。 人々は2013年、2014年、2015年にFacebookの幹部に警告を発しました。プラットフォームがヘイトスピーチを広め、暴力を扇動するために使われていることを。 2015年に1人の人がFacebookの幹部にさえ言っていました Facebookはミャンマーでラジオ放送がルワンダ虐殺の間に演じたのと同じ役割を果たすことができ、ラジオ放送はルワンダ虐殺で非常に恐ろしい、ある種の重要な役割を果たしました。 それに近い誰かが、これは20/20の後知恵ではないと言いました、この問題の規模は重要で、それはすでに明らかでした。  2015年にもかかわらず、Facebookにはビルマ語を話す契約者が4人しかいませんでした。  質問ですか？ それは興味深いものですね。 人間に見られる行動に対して、人工システムのバイアスを修正する機会について、どのように考えていますか？例えば、判決のアルゴリズムを監視して調整することができますが、長い間その役割に留まっている特定の偏った裁判官とは対照的です。 理論的にはそうなのですが、アルゴリズムの偏りを修正するのは簡単だと思うのですが、それには少し躊躇してしまいますね......なぜなら、それを優先させるための意思決定をする人がまだ必要だからです。 それにはシステムの優先順位のオーバーホールが必要だと思います。  クビにできない人や、懲戒処分を受けられない人がいるという前提から始まっています。 一部の裁判官にとってはそうかもしれませんが、裁判官を終身雇用にすべきではないということを示唆しているのかもしれません。  その場合でも、新しい制度を支持する人たちの心の変化が必要だと思います。  それが、システムの価値観の見直しを望む人々の心の変化を得るための重要な部分です。  ロヒンガの大量虐殺の問題に戻ります。  これは継続的な問題です。 多くの警告があり、多くの人々がこの問題に警鐘を鳴らそうとしたのに、ほとんど何の行動も取られなかったことには、本当に驚かされます   去年のことですが、ザッカーバーグはついにFacebookが追加すると言い出しました。これは2年前のことかもしれませんが、Facebookが追加すると言い出しました。  対照的に、これはフェイスブックがミャンマーでの対応に失敗したことを示しています。ドイツはヘイトスピーチとNetzDGについてのより厳しい法律を可決しました。 フェイスブックはこのペナルティをとても心配して 1年以内に1200人を雇いました  私はこの法律をここで再現したいと 言っているわけではありません 大虐殺に貢献していると言われた時の違いを 説明しているだけです 大虐殺に決定的な役割を果たしていると言われた時の  私たちは、Facebookに行動を起こさせるものが何であるかを見てきました。 このことは、高額の罰金を科すという信頼できる脅しの力が何であるかを思い出す上で、本当に重要なことだと思います。  そして、それはビジネスを行うためのコストのように、あなたが知っている以上のものでなければなりません。
ですから、産業界では政策と倫理的行動の両方が必要だと私は本当に信じています。政策は、負の外部性、経済的インセンティブのずれ、底辺との競争、説明責任の強制などに対処するための適切なツールだと思います。しかし、個人の倫理的な行動、データサイエンティストやソフトウェアエンジニアの倫理的な行動も非常に必要です。なぜなら、法律が常に追いついているとは限らないからです。すべてのエッジケースをカバーできるわけではありません。私たちは、産業界の人々が倫理的な倫理的判断をすることが本当に必要なのです。私は、この2つは重要で重要なことだと考えています。そして、ここで注意すべきことは、AIの倫理的な問題の例がたくさんあります。すべての例については話していませんが、アマゾンの顔認識についてです。あと、これはひどい記事でした。記事は良かったのですが、記事はひどいものでした。ある市がIBMのダッシュボードを使って予測的な取り締まりをしていて、市の職員が言ったのですが、機械学習を使っている時はいつでも99％の正確さがある。2016年にProPublicaは、Facebookに住宅広告を掲載して、「ラテン系や黒人には見て欲しくない」とか、「車いすの人には見て欲しくない」と言うことができるということを発見しましたが、これは公正住宅法に違反しているようです。それでこの記事が出てきて フェイスブックは「申し訳ありませんでした」と言っていました それから1年以上経ってもまだ続いていて ProPublicaがまた記事を書いてくれました 何十社もの企業がfacebookに求人広告を掲載していて、「若い人にしか見てもらいたくない」と言っていたという問題もあります。アマゾンがリクルートツールを作っていて、レジュメに「女性用」という言葉が入っているとペナルティを課していたという問題もあります。これらの例や今日お話しした例の多くは、人権や公民権についてのものです。これについては、アスペン研究所のドミニク・ハリソンの良い記事があります。そして、私はアニル・ダッシュのフレーミングに少し同意しています。つまり、彼は「テクノロジー産業はもう存在しない、テクノロジーはあらゆる産業で使われている」と書いています。だから私は特に、住宅、教育、雇用、刑事司法、投票、医療などの人権や市民権を考え、どのような権利を保護したいのかを考える必要があると考えています。そして、規制について落胆するのは非常に簡単ですが、時にはポジティブなことや、それがうまくいったケースを見落としてしまうこともあると思います。Timnit Gebru らのデータセットのデータシートで私がとても気に入ったのは、標準化と規制がどのようにして異なる産業にもたらされたのか、3 つのケーススタディを紹介していることです。電子産業では、回路や抵抗器などの標準化が行われていますが、これは仕様がどうなっているのか、何を書いているのかということです。製薬業界や自動車の安全性など、どれも完璧ではありませんが、ケーススタディは非常に勉強になりました。特に自動車の安全性については非常に興味を持ちましたし、「99％見えない」という素晴らしいエピソードもあります。初期の車のダッシュボードには鋭利な金属製のノブが付いていて、衝突時に人の頭蓋骨に刺さる可能性がありました。折りたたみ式ではないステアリングコラムはドライバーの命を奪うことが多く、折りたたみ式のステアリングコラムが発明された後も、それを実現する経済的なインセンティブがなかったため、実際には導入されなかったのです。しかし、自動車の安全性に関しては、シートベルト以外の何よりも多くの命を救ってきたのは、折りたたみ式ステアリングコラムなのです。車は運転する人のせいで危険だという考えが広まっていましたが、消費者の安全擁護者が、このことについて議論する文化を変え、データの収集と追跡を始め、安全性に関して自動車会社に責任を負わせるまでには、何十年もかかりました。GMは私立探偵を雇い、ラルフ・ネイダーを尾行し、彼の汚れを掘り起こそうとしました。
これは、私たちが今では当たり前のように受け止めている戦いであり、針を変えるためには、どれだけの時間が必要かを示しています。 さらに最近の問題としては、2011年になってから、衝突テスト用のダミーに平均的な女性の解剖学的特徴を持たせることが求められるようになりました。 同じ衝撃で衝突した場合、女性の方が男性よりも40％多く怪我をする可能性がありました。 私は、これらのことは非常に興味深いと思いましたし、これまでの成功例を思い出し、思い出すのに役立つと思います。  また、もう一つの関連分野は、環境保護です。  振り返ってみると、Maciej Ceglowskiが素晴らしい記事を書いています。 しかし、アメリカのように覚えていると思いますが、かつては火事になるような川がありましたし、ロンドンではひどいスモッグが発生していました。私たちは本当に調整された、調整された規制のようなものを必要としていました。 それでは、最後の締めくくりになります。私が今夜触れた問題の多くは、本当に巨大で、巨大で、難しい問題です。  私はいつも解決に向けたステップのようなものを提供しようとしていますが、必ずしもそうとは限らないことを理解しています。 ジュリア・アングウィンはProPublicaの元ジャーナリストで、現在はThe Markupの編集長を務めていますが、昨年、プライバシーに関する素晴らしいインタビューをしてくれました。 彼女は、「問題を解決するためには、問題を診断する必要があると強く信じています。 世紀の変わり目と工業化について考えてみましょう。児童労働、無制限の労働時間、ひどい労働条件が３０年も続いていましたが、問題を診断し、それが何であるかを理解し、法律を変えるための活動をするためには、多くのジャーナリストの雑踏やアドボカシーが必要でした。私の役割は、何が問題なのかをできるだけ明確にし、それを正確に診断して解決できるようにすることだと思っています。  これは大変な作業ですが、より多くの人がそれを行う必要があります。 私はそれがとても励みになりましたし、私たちは解決に向けて努力すべきだと思っています。 しかし、私たちが直面している複雑な問題を診断し、理解することは貴重な仕事だと思います。 何人かの人が、あなたの倫理に関するフルコースを見たいと言っています。それは、彼らが参加したり、購入したりできるようなものなのでしょうか？ですから、今年の夏には無料で公開される予定です。 また、有料の対面式バージョンもあり、データインスティテュートで証明書のようなものとして提供されていました。 このコースと同じように、このコースは実際に行われることになっていました。 データ倫理学のコースは1月と2月に行われました。 そして、私は現在、USFのデータサイエンス修士課程の学生のためのバージョンを教えていますが、7月までには無料のオンラインバージョンをリリースする予定です。 ありがとうございました。また次回お会いしましょう。