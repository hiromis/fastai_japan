ニューラルネットワークを訓練するときに何が起こっているのかを深く掘り下げていきます。私たちは確率的勾配降下を見ていたのですが、アーサー・サミュエルが言ったことを思い出してください。"現在の重みの割り当て（あるいはパラメータと呼ぶ）の有効性を実際のパフォーマンスの観点からテストする自動手段を用意し、そのパフォーマンスを最大化するために重みの割り当てを変更するメカニズムを提供したとします。これを完全に自動化することができ、機械は経験から学習するようにプログラムされています。パラメータがなかったのです そこで先週、どうやってパラメータ化するかを考えました どうやってパラメータを持った関数を作るかを考えました そして、私たちが考えたのは、ある特定の数値である確率を、その数値のピクセルと重みで表現して、それらを掛け合わせて足し算するようなことです。先週、確率的勾配降下がどのように動作するかを見てきましたが、基本的な考え方は、まずパラメータをランダムに初期化することから始めます。そのパラメータを使って、このような関数を使って予測を行います。次に、損失関数を使って、その予測がどれくらい良いかを測定し、あるパラメータを少し変えると損失がどれくらい変わるかという勾配を計算し、それを使って各パラメータを少しずつ変える小さなステップを作ります。そして、単純な二次方程式の場合には、このような感じのものができました。このセクションの最初に、シルヴィアンと私がノートや本の中に持っている勾配降下のまとめを少しまとめました。これを使ってMNISTの "3 "と "7 "のモデルを作成しましょう モデルを作成するためには、関数に渡すことができるようなものを作成する必要があります。そこで必要なのは、すべて並んだピクセルと、すべて並んだパラメータ、そしてそれらを合計します。この場合は各ピクセルにパラメータを掛けて合計するだけなので、グリッドにレイアウトされている効果は重要ではないので、グリッドをリシェイプしてベクトルに変換しましょう。Pytorch でリシェイプする方法は ".view" メソッドを使うことです。viewメソッドでは、各次元の大きさを指定することができます。この場合、列の数は各画像のピクセル数の合計と同じになるようにしたいと思います。そして、行の数はデータにある行の数になります。ビューを呼び出すときにマイナス1を使うと、データにある数と同じ数の行を意味します。これで、3つの要素を集めて、torch.catで連結して、7つの要素を連結して、各行が1つのImageで、すべての行と列が1つのベクトルに並ぶようなマトリクスに再構築します。次にラベルが必要になるので、これがXです。ラベルが必要になりますので、ラベルは3のそれぞれに1、7のそれぞれに0となります。
基本的には、"is 3 model "を作成している。つまり、これはベクトルを作成することになるが、実際にはPytorchでは行列にする必要があるので、.unsqueezeは1つ目の位置に単位次元を追加することになる。これがPytorchが期待しているものです。ここで、X, YをDatasetに変換してみましょう。これは、角括弧を使ってインデックスを作成することができるもので、そうするとタプルを返すことが期待されます。このDatasetを作成する方法を見てみましょう。このDatasetにインデックスを作成すると、各行の独立変数と従属変数を含むタプルを返します。これはリストを与えてくれて、それにインデックスを付けると、1つの画像と1つのラベルを含むことになります。これは本当に重要な概念です。データセットとは、インデックスを作成してTupleに戻すことができるものです。これはタプルの2つの部分を取って、最初の部分を1つの変数に、2番目の部分をもう1つの変数に入れていることを意味します。検証セットに対しても同じ3つのステップを繰り返します。これで、学習データセットと検証データセットができました。これで、学習データセットと検証データセットができました。パラメータを初期化する必要があるので、これまで説明したように、ランダムに初期化します。ここに関数があります。ある程度の大きさや形が与えられています。ランダムに初期化します。PyTorchの通常の乱数分布を使って、.Randnがどのように動作するかは、シフトタブで確認できます。ここには分散が1と書いてあります。だから、これを標準偏差と呼ぶべきではなかったのですが、実際には分散と呼ぶべきだったのです。だから、これに分散を掛けてください - 要求された分散を変更するには、デフォルトでは1になります。そして、先ほど説明したように、勾配を計算するときには、どのような勾配が必要かを PyTorch に伝えなければなりません。最後のアンダースコアは、この関数が参照しているものを実際に変更することを PyTorch に伝えるための特別なマジックシンボルです。これはこのテンソルを変更し、放射を必要とするようにします。 ここに重みがありますので、重みは28×28×1の28×28の形になります。これがPyTorchの期待するところです。これが重みです。ピクセル単位の重みは常にゼロに等しいからです。ピクセルがゼロに等しい場合、切片はゼロになります。だから、W * X + Bのような線が欲しいんです。そこで、Bはバイアスと呼ばれるもので
だから、それは単一の数字になるだけです。だからバイアスのために1つの数字を掴んでみましょう パラメータと重みの間には違いがあります 実際に言えば、ここでは重みはこの式のWで、バイアスはこの式のBです。重みとバイアスを合わせたものが関数のパラメータで、我々が変更しようとしているものです。重要な専門用語があります：モデルの重みとバイアスがパラメータです。我々は...はい、質問！
R: "勾配降下 "と "確率的勾配降下 "の違いは？
J: 今のところ勾配降下しかやっていないので、あと数分で確率勾配降下をやる予定です。
これで、1枚の画像に対して予測値を作成して計算することができるようになりました。最初の画像のような画像に重みをかけて、行と列が揃うように転置し、それを加算してバイアスを加えると予測値が得られます。これをすべての画像に対して行いたいのですが、forループで行うこともできますが、それでは本当に時間がかかります。GPU上では動作しませんし、最適化して見るコードでも動作しません。そこで実際には、ピクセルのループや画像のループのようなことを常に行うために使用したいと考えています。この場合、たくさんの行と列の計算をするのは行列の乗算と呼ばれる数学的な操作です。カーンアカデミーか何かで見てもらった方がいいと思いますが、実際には私が簡単に答えを出します。これはウィキペディアからの引用ですが、もしこれらが2つの行列AとBならば、出力のこの要素、1、2は、ここの1番目のビットにここの1番目のビットを掛けたものと等しくなり、さらにここの2番目のビットにここの2番目のビットを掛けたものと等しくなります。つまり、A1,2 * A1,1 + B 2,2 * A 1,2 となり、オレンジ色がオレンジ色と一致していることがわかります。ここでも同様です。これは、B1,3 * A 3,1 + B2,3 * A 3,2 と等しくなります。matrixmultiplication.XYZ を見ていただくと、このような動作の素晴らしい写真があります。別の方法としては、2 番目のビットを上に反転させて、それぞれのビットを掛け合わせて足し算し、それぞれのビットを掛け合わせて足し算すると、ここでは常に 2 番目のビットが 2 番目の位置で終わり、1 番目のビットが 1 番目の位置で終わることがわかります。これが行列の乗算です。これが行列の乗算です。Pythonでは行列の乗算は@記号演算子を使って行います。これは行列乗算を意味するので、学習集合に重みを加えて行列乗算すると20.2336となり、バイアスを加えると20.2336となります。これを見てください これは全部やってるんだよ！これが本当に重要なことです 行列の乗算は単純な線形関数を最適化する方法を提供してくれますが これはニューラルネットワークの2つの基本的な方程式の1つです。いくつかの行、データの行、データの列は、いくつかの重みを乗算して、バイアスを加えます。これはランダムに初期化されたモデルからの予測値ですので、モデルがどれくらい良いかをチェックすることができます。 そのためには、0より大きいものを3と呼び、0より小さいものを7と呼ぶことができます。 つまり、0.0より大きい予測値は、何かが3であると予測されているかどうかを教えてくれます。そして、これをfloatに変換して、trueとfalseではなく、0の1にします。これは訓練セットに含まれるものなので、しきい値を設定した予測値が訓練セットと等しいかどうかをチェックします。
これらの真と偽をすべて浮動小数点数に変換すると1と0になり、その平均値が得られます。0.49なので、当然のことながら、ランダムに初期化されたモデルは、7から3を予測する際に約半分の時間で正解となります。ここにもう1つメソッドを追加しました。それは .item() というアイテムなしのテンソルです。これには行がありません。しかし、実際には通常のPythonスカラを作成するためにこれをアンラップしたかったのですが、主に小数点以下のフルセットを簡単に見ることができるようにしたかったのと、精度の微分を計算する方法をお見せしたかったからです。パラメータを少し変更することで、1つのパラメータweights[0]を取り、それに1を掛けてみましょう。 0001 パラメータを少し大きくして、重みの変化に基づいて精度がどのように変化するかを計算すると、そのパラメータに対する精度の勾配となるので、新しい予測値のセットを計算して、それらを閾値化して、それらが学習セットと等しいかどうかをチェックして、平均値を取ると、全く同じ数値が得られます。うまくいけば、あなたはカーンアカデミーでそれを復習してきたので、Yの変化なので、y_new - y_oldは0.4912などを差し引いた0.4912など、0で割ったこの変化は私たちに0を与えるので、この時点で我々は問題を持っています私たちの誘導体は0ですので、我々は0勾配を持っています。さて、問題が発生しました。問題は勾配がゼロで、勾配がゼロの場合、ステップを踏むことができず、より良い予測ができないということです。直感的に言えば、なぜグラデーションがゼロなのかというと、1ピクセルをほんの少し変えただけで、実際の予測が3から7に変わったり、その逆になったりすることはないかもしれないからです。言い換えれば、この精度損失関数は非常にでこぼこしています。フラットステップフラットステップフラットステップフラットステップのようなものです。つまり、ゼロの勾配があちこちにあります。そこで、精度以外のものを損失関数として使う必要があります。 そこで、新しい関数を作ってみましょう。精度がより良い値を与えるのと同じようにね つまり、これは損失が小さい方が良いという損失のメンバーですので、精度が良い場合には損失が小さくなりますが、ゼロの勾配はありません。つまり、わずかに良い予測は、わずかに良い損失を持つ必要があるということです。ターゲットのラベルが3つあるとします。ちょうど3つの行があります3つの画像がここにあります1ゼロ1、大丈夫我々はニューラルネットからいくつかの予測を行いましたそれらの予測は私たちにポイントを与えました。[0.9, 0.4, 0.2]
を使ってみましょう。torch.where()は基本的にこのリスト内包と同じですが、基本的にはif文です。ここではtargetが1なので、1から0.9を引いた値となり、Where targetが1ではない場合は予測値となります。最初のターゲットが1に等しい場合は1 - 0.9 = 0.1となり、次のターゲットは0に等しいので、予測値は0.4となり、3番目のターゲットは1となります。このようにして、予測が正しいかどうかを見ることができます。正解です。言い換えれば、数字ですよね。 目標が1の時は高い数字で、目標が0の時は低い数字ですが、これらの数字は小さくなっていきます。だから最悪なのは0.2を予測した時です これは実際には0だと思っていましたが、実際には1なので、0.8になりました。これは1から予測1を引いたものですから、0.2 = 0.8となります。予測が正確に正しければ、この損失は最も小さくなります。予測が正確に正しければ、この損失は最小になります。もし予測が実際にターゲットと同じであれば、これは[0., 0., 0.]になります。つまり、予測が目標に近い方が損失は小さくなります。ここで平均値を取ると0.433になります。最後の悪い方の正確な予測を 0.2 から 0.8 に変更すると、損失は 0.43 から 0.23 になりますが、この関数は torch.where() です。ですから、これは実際にはかなり良いです。これは損失関数で、精度が高いほど損失は小さくなりますが、ゼロ勾配がないので、予測を変更するたびに損失が変わるので、文字通り予測が難しくなります。一つの問題は、これがうまくいくかどうかです。予測値が0と1の間にある限り、そうでなければ、この1 - 予測は少し変な感じになります。予測値が常に0と1の間であることを保証する方法を見つける必要があります。見てください、これらの大きな数字を取ることができる何か、そしてそれらをすべて0から1の間の数字に変えることができ、それはまさに正しい関数を持っていることが起こるのです。これはシグモイド関数と呼ばれています シグモイド関数は次のように見えます 本当に小さな数を渡すと ゼロに非常に近い数が得られます大きな数を渡すと 1に非常に近い数が得られます 1を超えることはなく ゼロよりも小さくなることはありません そして、この滑らかな曲線のようなものの間と中間にあります y = x線のように見えます これはシグモイド関数の定義です 1の上の1 + eからマイナスxまでの1です expとは何ですか？ expはeから何かのべき乗ですのでeを見てみましょう。
これはπのような数値なので、簡単に言えば、特定の値を持つ数値です。e Squaredを使って、テンソルになりそうなので、PyTorchを使ってfloatにしてみましょう。このような面白い関数を見たとき、私は定義はあまり気にしませんが、私が気にするのは形なんです。これは、すべての数値を無意味と1の間でつぶすものです だから、巣の損失を以前と全く同じに変更することができます しかし、最初に、すべてをシグモイドにして、それからtorch,where()を使います これは、私たちが望むすべての特性を持つ損失関数です。これは、私たちが望むすべての特性を持つ損失関数です。これは、何かになろうとしているものは、それらの厄介なゼロ勾配を持っていないことを確認しています。私たちのグラデーションを得るために使うことはできません。パラメータを改善するためのステップを作成するだけなので、我々の精度を似たような別の関数に変更することができます。 精度が良ければ良いのですが、このようなゼログラデーションを持っていないので、なぜメトリックとロスがあるのかがわかります。例えば、我々はよく二乗平均誤差を使いますが、分類の場合は残念ながら使いませんので、これを使ってパラメータを更新する必要があります。これは本当に時間がかかりそうですね。なぜなら、1つの画像に対して1つのステップを行っているからです。つまり、1エポックにはかなりの時間がかかるということです。データセット内の全ての画像を処理して、大きな行列の乗算を行うことで、GPU上で全ての画像を麻痺させることができます。だから、それも良くない考えかもしれません。では、なぜ妥協しないのでしょうか？損失とステップを計算するために、いくつかのデータアイテムを一度に取得すると、その２つのデータアイテムはミニバッチと呼ばれます。
しかし、より正確になればなるほど、グラデーションは真のデータセットのグラデーションにかなり近くなります。バッチサイズが小さくなればなるほど、各ステップの処理速度は速くなりますが、これらのステップは項目数が少なくなりますので、データセット全体の真の勾配の正確な近似値にはなりません。中央値の方が外れ値の影響を受けにくいからです。あなたが与えた例では、誤って外れ値として予測された3番目のポイントがある場合、SGDを行いながら、誘導体は関数を離れてプッシュし、中央値は、その場合にはより良いかもしれません。正直なところ、中央値を使ってみたことはありません。中央値の問題は、1 つの数値（真ん中の数値）だけを気にしてしまうことです。だから、両端のすべてのものを無視して終わる可能性があり、それが本当に気にするのは物事の順序だけです。だから、私の推測では、真ん中の1つのことだけを予測するのが得意なものになってしまうのではないかと思っています。でも、試してないんですよ。見てみたいと思います。中央値を使った場合に起こるであろうもう一つのことは、ゼロの勾配がたくさんあるということだと思います。中央値を選んでいるので、値を変更することができますが、中央値はゼロ勾配ではなく、でこぼこした勾配になります。真ん中のものは、突然別のアイテムにジャンプしてしまうと思います。だから、あまりうまくいかないかもしれません。それが私の推測です。試してみてください。さて、では、一度にいくつかのアイテムをお願いするにはどうすればいいのでしょうか？PytorchとFastaiがそれをしてくれることがわかった。DataLoaderというクラスに任意のデータセットを渡すと、そのデータセットから一度にいくつかのアイテムを取得することができます。バッチサイズを指定することで、何個集めるかを指定することができます。ここでは、0から14までのすべての数字を含むコレクションを作成してみましょう。これをバッチサイズが5のDataLoaderに渡して、Pythonのイテレータと呼ばれるものにします。これは、イテレータにもう一つ何かを求めることができるものです。Pythonでイテレータをリストに渡すと、イテレータから全てのものを返してくれます。ここに私の3つのミニバッチがありますが、ここには0から15までのすべての数字が表示されています。順番はランダムで、一度に5つずつ出現します。シャッフル=真なので、ランダムな順番で表示されます。そのため、通常、学習セットではシャッフルするように要求しています。ランダム化を増やすと、データセットがどのように見えるかを学習するのが難しくなるので、ランダム化を増やすのは良いことです。これがDataLoaderの作成方法です。しかし、データセットは実際にはタプルを返すことを覚えておいてください。では実際にタプルを作成してみましょう。英語のすべての文字を列挙すると、 (0, 'a'), (1, 'b'), (2, 'c') などを返すことになります。これをデータセットにしよう。これをバッチサイズが6のDataLoaderに渡すと、見ての通り、最初のものを6つ、2番目のものを6つ含むタプルが返されます。これが独立変数のようで、これが従属変数のようです。最後に、バッチ・サイズが必ずしもDatasetのフル・サイズにきれいに分割されていないことがわかります。基本的には、既にDatasetを覚えているので、それをDataLoaderに渡して、基本的に次のように言うことができます。Pythonのイテレータは実際にループすることができるものです。DataLoaderでforと言うと、タプルを返します。予測値を計算したり、予測値と目標値からの損失を計算したり、勾配を計算してもらったり、二次方程式の例で行ったようにパラメータを更新したりすることができます。これで、先ほどと同じ 2 行のコードでウェイトとバイアスを再初期化します。
実際のMNISTデータセットを使って大きなバッチサイズのデータを作成します。DataLoader'から最初のものを取得してみましょう。'first' は高速な AI 関数で、イテレータから最初のものを取得するだけです。これは便利なんですよね、任意のミニバッチのようなものを見るのに。これがこのような形になります 最初のミニバッチは256行、長さ784で、28×28です。つまり、256個の画像と256個のラベルが1になっています。3なのか7なのかに応じて、0か1の数字がありますので、検証セットも同じようにします。ここに検証用のデータローダーがあります... ここでバッチを取得して、テストして、それを渡します...なぜそんなことをするのか？テストのために最初の4つを 手動で取得してみるよ 最初の4つのものだけを 集めよう これをバッチと呼ぶ 先ほど作成した線形関数に渡します 線形関数とは、xバッチに重み行列を乗じてバイアスを加えたものだと覚えておいてください。これで4つの結果が得られます これが4つの画像のそれぞれの予測です。損失を計算するには、先ほど使用した損失関数を使用します。学習セットの最初の4つの項目から損失を計算します。これが損失です これでグラデーションを計算できます。グラデーションは784×1です。言い換えれば、すべての重みがグラデーションになっている列です。これは、そのパラメータの小さな変化に対する損失の変化です。そして、勾配としてのバイアスは単一の数値です。この3つのステップを踏んで、関数に入れることができます。もしパスを渡すと... もしあなたが... これは「勾配の計算」です。Xバッチ、Yバッチ、モデルを渡すと、予測値を計算し、損失を計算し、バックステップを行います。ここでは「勾配を計算」と表示されているので、重み勾配の平均値とバイアス勾配を求めることができます。これがそうです。これを2回目に呼び出して見てみましょう。ここでは何もしていないことに注意してください。これは全く同じパラメータです。違う値が出てしまいます。これが気になるところです。同じデータで呼び出すたびに同じグラデーションが得られると思っていたはずです。なぜグラデーションが変わったのか？それは 'loss.backward' が単にグラデーションを計算するだけではないからです。グラデーションを計算して、既存のグラデーションに追加します。.grad' 属性の中にあるものです。その理由については後ほど説明しますが、今のところ知っておくべきことは、単にそれを行うということです。実際に必要なのは 'grad.dot.zero_' を呼び出すことです。dot.zero' はゼロを含むテンソルを返しますが、'_' はテンソルである 'weights.grad' 属性をゼロを含むように更新することを覚えておいてください。これを実行してもう一度呼び出すと、全く同じ数値が得られます。そこで、SGD を使って 1 つのエポックを学習する方法を説明します。DataLoader をループして X バッチと Y バッチを取得し、勾配、予測、損失を逆算します。それぞれのパラメータを調べます。ここでは、これらのパラメータを渡していきます。768個の重みと1つのバイアス、そしてそれぞれのパラメータを更新して、マイナスに等しい勾配に学習率をかけます。これが勾配降下のステップです そして次回のループのためにゼロにします。pマイナスイコールとは言いません。p.data' から等号を引いた値を言っているのですが、なぜかというと、PyTorch は我々が行ったすべての計算を記録しているからです。さて、私はグラデーション降下ステップのグラデーションを計算したくありません。それはモデルの一部ではないようなものですよね？
つまり、ドットデータは Pytorch の特別な属性であり、これに書き込むと、その計算を使ってグラデーションを更新しないように Pytorch に指示します。これが、最も基本的な標準的なSGD、確率的勾配降下ループです。これで、先ほどの質問に答えられるようになりました。確率的グラデーション降下とグラデーション降下の違いは、グラデーション降下にはミニバッチごとにループするこのような機能がないということです。勾配降下では、毎回データセット全体に対してそれを行います。その代わりに、データセット全体の勾配を計算して、データセット全体に基づいてパラメータを更新しますが、実際にはこれを行うことはありません。私たちは常に様々なサイズのミニバッチを使用します。さて、以前の関数を使って、予測値がゼロより大きいか小さいかを比較していましたが、今は、予測値がゼロより大きいか小さいかを比較していますよね？しかし今はシグモイドをしています シグモイドは無と１の間の全てを 縮めてしまいます だから今 予測値が0.5より大きいかどうかを 比較してみましょう 0.5より大きければ シグモイド関数を見返してください だからゼロはゼロだったものが 今はシグモイド上で0.5になっています OK それで精度の測定にわずかな変更を加える必要があります そこで、いくつかのXバッチとYバッチの精度を計算するために、これは実際に予測されたものだと仮定して、予測値のシグモイドを取ります。0.5と比較して3かどうかを判断し、実際の目標が何であったかをチェックして、どれが正しいかを確認し、ブーリアンをfloatに変換した後、それらの平均値を取ります。これで精度をチェックすることができます。バッチを単純な線形モデルに通して、学習セットの4つの項目と比較してみましょう。検証セットのすべてのバッチについてこれを行うとリスト理解をループさせることができます検証セットのすべてのバッチをモデルに基づいて精度を取得して このリストをテンソルに変換したい場合、リストの項目がテンソルの項目になります。それがスタックの役目です これらをすべてスタックして平均値を取り、標準的なPythonのスカラーに変換し、その項目を呼び出し、表示のために小数点以下4桁に丸めて表示します。ご想像の通り、ランダムなので約50%です。これで1エポック分の学習ができるようになりました。つまり、"train_epoch "がパラメータを必要としていたのを覚えていますか？この場合のパラメータは重みテンソルとバイアステンソルです。学習者と "linear1 "モデルを用いて、学習率1、これら2つのパラメータで1エポックの学習を行い、検証してみましょう。精度は68.8%になりました これでエポックを学習したことになります。これを何度も繰り返しましょう 訓練して検証すると 精度がどんどん上がっていくのがわかるでしょう 97%まで上がっていきます これでいいんだ！単純な一次関数のSGDオプティマイザを構築しました。単純化されたMNISTの精度は約97%です。多くのステップがあるので、リファクタリングで単純化してみましょう。これから行う単純なリファクタリングはいくつかありますが、 基本的な考え方は、オプティマイザークラスと呼ばれるものを作ることです。まず最初にやることは、"linear1 "関数を削除することです。しかし、「linear1」関数は'x' '@' 'w'に'b'を加えたものであることを覚えておいてください。実際にPytorchにはこの式を処理するクラスがあるので、それを使うと良いだろう。
nn.linearと呼ばれるもので、nn.linearは2つのことをしてくれます。nn.linearクラスを作成し、サイズ(28, 28, 1)の行列とサイズ1のバイアスを作成します。これは requires_grad=True を設定してくれます。これはすべてこのクラスにカプセル化されていて、これを関数として呼び出すと、私のXハットW + Bを実行することになります。784個の重みと1個のバイアスが含まれています。これはクールですね。このクラスを自分でゼロから作ってみるのも面白いかもしれません。この時点では、できるはずです。nn.linearのような振る舞いを再現できることを確認できるはずです。さて、パラメータメソッドにパラメータを格納したオブジェクトができたので、オプティマイザを作成しましょう。オプティマイザに最適化するパラメータと学習率を渡すと、それらを保存しておき、ステップと呼ばれるものを作成します。また、ゼロ・グラッドと呼ばれるものがあります。これは各パラメータを通過してゼロにするものです。これが基本オプティマイザーと呼ばれるものです。これらのコードは、今まで見てきたコードと全く同じものがクラスにまとめられています。これでオプティマイザを作成し、線形モデルのパラメータと学習率を渡して、学習ループを作成することができます。検証関数を変更する必要はありませんので、学習ループを関数に入れて、エポックの束をループさせ、エポックを呼び出し、validate_epochを出力して実行します。そして実行してみましょう。ここでは少し違った結果が得られていますが、考え方はほとんど同じです。これで、独自のオプティマイザを作成して、PyTorchの組み込みNN.linearクラスを使ってリファクタリングしています。ちなみに、実際にはBasicOptimを使う必要はありません。驚くことではありませんが、PyTorchにはこれを正確に実行するものが付属しており、SGDと呼ばれています。このSGDはfastaiによって提供されています: fastaiとPyTorchは重複する機能を提供しています。fastaiとPyTorchは重複した機能を提供しています。そしてそれを学習させても、同じ結果が得られます。このように、fastai や PyTorch にあるクラスは、不思議なものではなく、自分たちで書いた機能を薄くラッパーしたものです。ですから、かなりの数のステップがあり、もしグラデーション降下をやったことがないのであれば、解凍する必要があります。ですから、このレッスンは一種の重要なレッスンです。ここでは、本当に私たちを連れて行ってくれ、この時点で立ち止まって深呼吸をして、あなたが快適であることを確認してください。データセットは？データローダは？nn.linearって何？SGDって何？これらのうちのどれか、どれか、またはすべてが意味をなさない場合は、最初に定義したところに戻ります。
Pythonのコード。データローダはゼロから定義したわけではありませんが、機能的には特に面白いものではありません。もしそうしたいのであれば、ゼロから自分のものを作ることもできます。fastaiには'dataloaders'クラスがあります。これは前にも述べたように小さなクラスで、データローダの束を渡すだけで.trainと.validとして保存されます。小さなクラスですが、これはとても便利なものです。これがdataloadersクラスの役割です。次にfastaiの次のクラスは学習者クラスです。学習者クラスはデータローダを渡し、モデルを渡し、最適化関数を渡し、損失関数を渡し、メトリクスを渡します。今まで手動で行ってきたことをすべて学習者が行うのはこれだけです! 学習者がやることはそれだけです! この train_model と train_epoch を呼び出すだけだ これは学習者の中にあります。これでlearn.fit()を実行してみると、同じことをして同じ結果を得ていることがわかります。これにはいくつかの素晴らしい機能があります。それをきれいな表に出力してくれて、損失と精度と所要時間を表示してくれます。でも魔法のようなものはないわよね？PythonやPyTorchを使えば 全く同じことができるんですね これらの抽象化は、コードを書く時間を減らし、時間を節約し、認知的なオーバーヘッドを節約するためのものですが、自分でできないことは何もしません。これは重要なことですよね？なぜなら、自分でできないことをしているのであれば、カスタマイズもデバッグもできないし、プロファイルもできないからです。だから、私たちが使っているものは、それが何をしているのかを理解しているものであることを確認したいのです。つまり、これは単なる線形関数であり、優れたものではありません。では、これをニューラルネットワークに変換するにはどうすればいいのでしょうか？これは線形関数 x@w+B であることを覚えておいてください。これをニューラルネットワークに変換するには、全く同じですが、重みとバイアスが異なる2つの線形関数があり、その間に、最初の線形関数の結果を取り、その結果と0の間のmax()を行う魔法のコードがあります。 つまり、resと0のmax()は、負の数値を取り、それを0に変換します。つまり、一次関数を実行して、負の値を0に置き換え、それを別の一次関数にかけます。これが（信じられないかもしれないが）ニューラルネットだ！w1とw2は重みのテンソルで、b1とb2はバイアスのテンソルです（以前と同じ）。つまり、res.max(0)は整流線形単位と呼ばれています。これは常にReLUと呼ばれています。PyTorchではすでにこの関数を持っていて、f.relu()と呼ばれています。これをプロットしてみると、予想通り、負の数では 0、正の数では y=x となります。整流線形単位」という専門用語は怖くて複雑に聞こえますが、実際には信じられないほど小さなコードで、信じられないほどシンプルな関数です。これはディープラーニングではよくあることです 複雑で洗練されていて印象的に聞こえるものが、通常は超単純なものであることが判明するのです、率直に言って... 少なくとも一度は、それが何であるか知っている...
だから なぜそうするのか。直線的なレイヤー ReLu 直線的なレイヤー もし真ん中のReLuをなくして、線形層を線形層にしたら、それを単一の線形層として書き換えることができると思います。これは今、普遍的な近似定理と呼ばれるものが保持されている場所です重みとバイアス行列のサイズが十分に大きい場合、これは実際に任意の関数を近似することができます関数を含む任意の関数を近似することができますどのように私は7から3を認識するか、または何でもそれは一種の驚きのようなものです、右、この小さなものは、あなたがW1 B1 W2とB2を持っている限り、実際に普遍的な関数の近似器です正しい数を持っていると我々はそれらを正しい数にする方法を知っているSGDCを使用しています非常に長い時間がかかるでしょう。それはメモリの多くを取ることができますが、基本的な考え方は、任意の計算可能な問題へのいくつかの解決策があることであり、これは最大の課題の一つです初心者の多くは、深層学習に持っていることは、そのようなそれに他に何もないということですか？多くの場合、これのように、どのように私はニューラルネットを作るにはどうすればよいのでしょうか？じゃあ、どうすればいいのかというと、SGDでディープラーニングのトレーニングをするにはどうすればいいのかというと、「訓練を少し速くする」というようなことがあります。パラメータを少なくするとか、ここから先は全部性能の微調整だから、これがニューラルネットワークのトレーニングの重要な理解だよね。 線形の重みとバイアスを置き換えるために、線形層の両方にそれを行いましょう、そして、我々は単純に1つの関数の結果を取っているので、次の関数にそれを渡すその関数の結果は、次のように受動的に次の関数に渡して、最後に返されますこれは関数の合成と呼ばれています関数の合成は、あなたがちょうど1つの関数の結果を取るときに新しいものにそれを渡すときです。ニューラルネットワークの多くは線形層の関数合成をしていて、活性化関数や非線形性と呼ばれています。F.ReLUは使っていません。私はnn.ReLUを使っています これは全く同じものを返しますが、これは関数ではなくクラスです。Yes, Rachel "By using the nonlinearity Won't use the function that makes all negative output zero, and stop the learning process dueto many zero gradients? " でも、すべての画像に対してゼロにはならないし、ミニバッチはシャッフルされているので、1つのミニバッチですべての画像に対してゼロになったとしても、次のミニバッチではゼロにはならないし、次のミニバッチではゼロにはならないし、次のエポックではゼロにはならないんです。そう、ゼロを作ることができて、ニューラルネットがパラメータを設定すると、たくさんの入力がゼロになります。ミニバッチ全体がゼロになることもあるし、いくつかのニューロンが活動的でないままであるという状況に陥ることもある。
これは大きな問題で、基本的には計算を無駄にしてしまうことになるので、それを避けるためのコツがいくつかあります。簡単なコツは、ここを平らにするのではなく、急峻でないようにすることです。まあ、あなたはリーキー整流された線形単位とそれは彼らが少し助けてくれましたが、さらに良いのは、我々はちょうど我々が大きすぎず、小さすぎない賢明な初期値に初期化することを確認することです、一般的に我々はそれを行う場合、彼らはほとんどの時間の正のゾーンに物事を維持することができますが、我々は実際にネットワークの中で分析する方法について学ぶつもりです、そして、我々はどのように多くのデッドユニットを持っているかを見つけるために、これらのゼロのいくつかを持っているので、あなたが指摘しているように、それらは悪いニュースです。これでニューラルネットができたので、以前とまったく同じ学習者を使うことができますが、今回は線形ではなく単純なネットを使います。他のことはすべて同じで、以前と同じようにフィットを呼び出せます。ここでは1つのレイヤーから2つのレイヤーになりました。パラメータ化されたレイヤーだけをレイヤーとして数えています。3つと言ってもいいかもしれませんね。私は2つと呼ぼうと思っていました。2つのTrainableレイヤーがあります。1つのレイヤーから学習率を1から0に落としました 1から0に落としたんだ 深いモデルはすべてのモデルがより複雑になる傾向があるから 学習率を低くする必要があるんだ それでしばらく訓練してみたんだが 学習者の中を見れば訓練の様子がわかるんだ レコーダーの属性を作って この表に表示されるすべてのものを記録するんだ そうですね......この３つのこと......トレーニングの損失、検証の損失、そして精度......つまり、記録された値には、結果の表のようなものが含まれていますので、各行の２番目の項目が精度となります。悪くないですね98 3％ですから、これはかなりすごいことですね。どんな問題でも解決できる関数ができたのです。RachelHow could we could use what we're learning what we're learning here to get a idea of the network is learning along the wayLike Zieler and Fergus did more or lessWe will look at the later......Not the full detail of their paper......but basically you can look in the dot parameters to see the values of those parametersand at this point. まあ、自分でやってみればいいんじゃない？だろ？実際にパラメータが表示されているので、モデルを把握したい場合は、学習したモデルを見ることができます。学習したモデルの中には、学習したモデルが表示されています。これらは線形であり、線形よりもReLUであり、私がやりたいことは、変数に入れて、少し作業を簡単にすることです。
これはジェネレータと呼ばれるものを与えてくれます。これは、私がパラメータを要求したときに、パラメータのリストを与えてくれるものです。これは私が要求したものだからです。ここで注意すべきことの1つは、ニューラルネットを作成するために、1つ以上のレイヤーを持つものを作成することです。実際には30の出力を持っているので、たくさんの特徴を生成していると考えることができます。そのうちの1つを見てみてください。最初の行に数字がありますので、それを元の画像の形にリシェイプすることができます。これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、これは何かというと、このようなものである。これが何を示しているのか分からないので、いくつかは必要以上に多くのものを持っていて、それが目立たない理由です。これは基本的な考え方ですが、最初の層ではなく、後の層の特徴を理解するためには、もう少し洗練されている必要がありますが、最初の層のものを見るためには、それらをプロットすることができます。そこで、比較するために、完全なfastaiツールキットを使うことができます。前にやったようにフォルダからデータローダを取り出して、 cnn_ learnerとResNetを作成して、単一のエポックに適合させます。 7! 40エポックで98.3という結果になりました。このコースの終わりまでに、あるいは少なくともこのコースの両方のパートで、1エポックで99.7という結果をゼロから出せるようになるでしょう。だから専門用語。 損失は、我々が微分を取ろうとしている関数であり、その後、勾配は、各パラメータに関して損失の微分である我々はそれらの勾配を計算するときに後方のパスは、我々はそれらの勾配を計算するときに、勾配降下は、損失を計算した後、資本によって勾配に反対方向にステップを取ることの完全なものであり、その後、学習率は、我々が取るステップの大きさです。おそらく最も重要な専門用語は、ニューラルネットワーク内のすべての数値で、学習している数値はパラメータと呼ばれ、計算している数値はすべての値が計算され、すべての行列の乗算要素が計算されます。これらは活性化と呼ばれ、活性化とパラメータはニューラルネット内のすべての数値です。これは、基本的にはニューラルネットの中に存在するほぼ全ての数字の集合なので、活性化は計算され、パラメータは学習されます。私たちはテンソルを使ってこのようなことをしていますが、テンソルは普通に配列の形をしていて、ランク0のテンソルはスカラ、ランク1のテンソルと呼ばれています。だから、より高い次元数に上がることを怖がらないでください。それでは休憩に入りましょう......質問があるんですが、いいですか？
R: "多くの非線形性があることを考えると、どのような非線形性を選択するかの経験則はありますか？" 非線形性にはたくさんの種類がありますが、どれを選ぶかは一般的にはあまり重要ではありません。ReLUかLeaky ReLUか、そうですね、どのようなものでも大丈夫です。いい質問ですね。先に進む前に、この章のアンケートを終わらせておくことが本当に重要です。7分間の休憩を取りましょう7分後にお会いしましょう さて、おかえりなさい、ニューラルネットの作成と訓練の方法を知っています。戻って、いくつかのアプリケーションを見てみましょう。そこで、ある端からある種の補間をしてみましょう... ...ある種のゼロからのバージョンをやってみました... ...ある種の４行コードバージョンをやってみました... ...ある種の４行コードバージョンをやってみました... ...ある種の４行コードバージョンをやってみました... ...ある種の４行コードバージョンをやってみました... では、PETに戻って考えてみましょう。どのようにして、新しいデータセットから始めて、それをどのように使うかを考えてみましょう。データセットの場合は、ターミナルやPythonでも何でもいいので、何かを指しているパスがあると仮定して、それが何なのか分からないようにして、まずLSを使って中身を見てみましょう。レッスン1で見たPETsのデータセットには、3つのアノテーション、画像、モデルが含まれていますが、ここにちょっとしたトリックがあります。これをプリントアウトしても何も表示されません。このパスからの相対パスを表示してくれるので、ちょっと便利です。オリジナルの PETs データセットの readme を見てみましょう。そこには、画像と注釈のフォルダが何であるか、そして驚くことに画像のパスが書いてあります。ここに書いてあるように、fastaiのほとんどの関数やメソッドはPythonのリストを返さないので、コレクションを返します。強化されたリストの1つは、それが表示されることで始まる表現を印刷する方法です。リストの中にコレクションの中にどれだけのアイテムがあるかを表示します。この出力から、レッスン1で説明したように、ファイル名の最初の文字が大文字の場合は「猫」、小文字の場合は「犬」ということがわかります。しかし、今回はもう少し複雑なことをしなければならないのですが、それは品種を特定することです。最後のアンダースコアまでが品種で、この数字の前が品種です。
そこで、すべてのものに品種のラベルを付けたいので、この構造を利用したいと思います。正規表現とは、文字列を見て、基本的には非常に柔軟な方法で文字列をバラバラにすることができるものです。そのためのシンプルで小さな言語です。もし正規表現を使ったことがないのであれば、今すぐ「正規表現チュートリアル」でググってみてください。私はほぼ毎日それらを使用しています.Iは非常に多くの素晴らしいチュートリアルがあるので、それらを使用する方法についての詳細に行きます。また、エクササイズのような素晴らしいものもたくさんあります。正規表現のクロスワード、正規表現のQ&A、私のような多くの人がこのツールを愛用していますが、FastAI NLPコースの正規表現レッスンもあります。そうそう、初日のことを忘れていてごめんなさい。だって、なんという素晴らしいリソースなんだから! というわけで、RegularExpressionsは最初のうちはどうやって正解するかということです。だから、最良の方法は、サンプルの文字列を取得することです。そのための良い方法は、ファイル名の一つを取得することです。これをFnameに入れて、reg式を使って実験してみましょう。reはPythonの正規表現モジュールで、find allは正規表現の括弧で囲まれた部分をすべて取得します。この正規表現とRはPythonでは特殊な文字列で、基本的にはバックスラッシュを特殊なものとして扱わないようにしてくださいと書かれています。というのも、Pythonでは通常バックスラッシュnは改行を意味するからです。1回以上の文字とアンダースコア、1回以上の数字の後に何かが続き、バックスラッシュtは使わなくても大丈夫ですが、jpgの後に文字列の最後が続きます。さて、これでデータブロックを作成して、独立変数を画像、従属変数をカテゴリとしたデータブロックを作成できました。この正規表現はパスlibパスオブジェクト上で直接呼び出すことはできませんが、実際にはname属性上で呼び出すことになります。fast AIにはattr using attributeという小さな関数があります。これは、ズームイン、ズームアウト、ワープ、回転、コントラストの変更、明るさの変更などを行うことができるもので、ほとんどのデータを合成的に生成することができます。ランダムリサイズクロップについても学びました。ランダムリサイズクロップとは、正方形の画像を確実に取得するためのとてもクールな方法です。つまり、実際にはランダムなリサイズクロップを使って、より小さいサイズにリサイズします。
なぜそんなことをしているのか？この2つのステップを組み合わせることで、Fastaiにしかできないことができると思うのですが、これはプリサイジングと呼ばれています。一番良い方法は、私が興奮しているパワーポイントの魔法のような美しい例をお見せすることです。プリサイジングが何をするかというと、まず最初のステップで、460×460にリサイズすると、正方形を掴んで、それをランダムに掴みます。横向きの写真であれば、それをランダムに取り込みます。つまり、高さを全部取って、横からランダムにどこかを掴むということです。縦向きの写真であれば、横幅全体を取得して、上から下までランダムに取得します。そうすると、この領域はここになります。これが最初のリサイズです。次に、2番目のaug_transformsビットは、ランダムに反り返った切り抜きを取得し、おそらく回転させたものを正方形に変換します。つまり、2つのステップがあります。まず最初に大きな正方形にリサイズし、次に2つ目のステップとして、回転、反り、ズームの段階を経て、より小さなものにします。この最初のステップでは正方形のものが作成され、常に同じサイズであるため、次のステップはGPU上で実行されます。通常、回転や画像ワープなどの処理はかなり遅くなります。また、通常、ズームや回転、ワープを行うと、それぞれ補間ステップを必要とするため、画像に大きなダメージを与えます。これは単に遅いだけでなく、実際には画像の品質が低くなってしまいます。だから、Fastaiでは特別な方法でそれを行っています。これはユニークなことだと思います。回転やワープ、ズームなどの座標変換を、実際のピクセルではなく、その代わりに、変化する座標値を非損失の方法で記録していて、浮動小数点の値を完全に記録し、最後に補間を行います。結果は非常に目を見張るものがあります。以下はその違いを示しています。ビデオを見ていただければわかると思います。左側がプリサイジングのアプローチで、右側が他のライブラリが使用している標準的なアプローチです。右側のものはピントが合っていないのがわかると思いますが、ここに草が生えているはずなのに、実際にはお尻が突き出ています。これはちょっと変な歪みがありますが、これはたくさんの変な歪みがあります。このように、プレサイズ版の方が本当にずっと良い仕上がりになっているのがわかります。DataBlockのブロックは順序付きのリストですか？入力と出力の構造はそれぞれ指定されていますか？ブロックは常に2つですか、それとも2つ以上あってもいいですか？例えば、セグメンテーションモデルが欲しかったら、2つ目のブロックはセグメンテーションに関するものになりますか？そうですね、これは順序付きのリストです。最初の項目は画像を作成したいと書いてあり、2番目の項目はカテゴリを作成したいと書いてあります。これが独立変数と従属変数です。ここには1つの項目があってもいいし、3つの項目があってもいいし、好きなだけの項目があってもいいのです。明らかに、大多数の場合は2つの変数だけになります：独立変数と従属変数があります。これについては後ほど詳しく説明します。
とはいえ、前のレッスンでデータブロックを紹介したときに戻ってみると、これらのパーツがどのように組み合わされているのかを示す写真があります。データブロックを組み立て、データローダを作成したら、それが正しく動作しているかどうかを確認する必要があります。コンピュータビジョンのDataBlockでは、show_batchとshow_batchで項目が表示されます。unique=Trueを追加すると、同じ画像に異なる拡張を加えたものが表示されます。これは、オーグメンテーションが正しく機能するかどうかを確認するための良い方法です。DataBlockを間違えてしまうと、この例ではリサイズがないので、異なる画像は異なるサイズになってしまったり、バッチにまとめることができなくなってしまいます。そこで'.summary'を呼び出すと、これは本当にすてきなもので、何が起こっているのかをすべて教えてくれます。それで私は... 何個あった？分割したらどうなった？異なる変数は何か？独立変数、従属変数を作成しています これを作ってみよう それぞれのステップはこうだ 自分のイメージを作る。カテゴライズを作成します。最初に出てきたのはこれです アメリカンブルドッグです。これが最終的なサンプルです。この画像、このサイズ、このカテゴリですか？そして最終的には、ああ、ああ、それはあなたのアイテムを照合することはできませんと言います。私はあなたのタプルのゼロインデックスメンバーを照合しようとしました。つまり、これが独立変数で、これはサイズ500×375、これは375×500でした。サイズが違うので、これらをテンソルに照合することはできません。というわけで、これはDataBlockをデバッグするための超強力なデバッグツールです。質問があります。リサイズが画像よりも小さい場合、アイテムトランスフォームのプリサイズはどのように機能するのでしょうか？横幅や高さが全部取られるのでしょうか？それとも修正された値でランダムにトリミングされるのでしょうか？レッスン2を思い出していただければ、このようなアイテムを作成するためのさまざまな方法を見てきました。もし画像が正確な値よりも小さい場合、スクイッシュは本当にズームしてくれます。そして、パターンクロップも同じようなことをします。そうすると、最終的には同じようなものができあがります。このように見えますが、少し拡大する必要があるので、解像度が低くなります。多くの人が、モデル化する前に、かなりの量のデータクリーニングをすべきだと言いますが、私たちはしていません。私たちはそうではありません。できるだけ早くモデル化した方がいいと言っています。なぜなら、私たちがノート2で見つけたことを思い出してください。モデルはデータの問題点を教えてくれます だから、データブロックが動作しているところまで来たらすぐに、データローダを持ってきて、モデルを構築します。そして、このようにして、私がどのように進んでいるかを教えてくれます。それで、7%のエラーが出ているんです。うわー、これはペットのモデルにしては本当に良い結果ですね。この時点でモデルを持っているので、先ほどのノート02で学んだことができます。分類、混乱行列、トップロス、画像クリーナーウィジェットなどを見ることができます。ノートブック4では、学習者を作成する際に損失関数が含まれていましたが、ここでは損失関数が含まれていません。なぜですか？fastAIが自動的に適切な損失関数を選択しようとするからです。画像の分類タスクでは、どのような損失関数を選択するのが普通であるかを知っていて、それを実行してくれます。そこで、'learn.loss_func'を見てみると、クロスエントロピー損失であることがわかります。交差エントロピー損失って一体何なの？よくぞ聞いてくれた。では、調べてみましょう。クロスエントロピー損失は 我々が作った MNISTの損失とほとんど同じです シグモイドや予測値や予測値を引いたものですが それは一種の拡張版です その拡張版とは、ノート4で見た'torch.where'は、バイナリの結果がある場合にのみ機能します。この場合は「３かどうか」でしたが、この場合は３７種類のペットのうちのどの犬種なのかがわかります。
そこで、シグモイドと'torch.where'のようなものを作りたいのですが、これは2つ以上のカテゴリでもうまく機能します。どのようにできるか見てみましょう まず最初にバッチを掴みましょう ありますよね・・・はい？疑問があります。なぜデータをきれいにする前に モデルを構築したいのか？きれいなデータセットは訓練に役立つと思うんだが 確かにデータセットがきれいなのは 学習に役立ちますが ノートブック02で見たように 初期モデルはデータセットをきれいにするのに役立ちます plot_top_losses' はラベルが間違っている画像を識別するのに役立ち、混乱マトリックスはどのようなものが混乱していて、修正が必要なのかを認識するのに役立ち、'ImageClassifierCleaner' は実際に、1匹の熊ではなく2匹の熊が含まれている画像を見つけ、それをクリーンアップしてくれました。モデルは、重要なデータをズームインして、どのデータに問題があるのか、どのデータが最も重要なのか、ということを把握するための素晴らしい方法なのです。そんな感じです。つまり、モデルを使ってデータをクリーンアップしてから、再びクリーンなデータを使ってトレーニングを行うのです。素晴らしい質問をありがとうございました。クロスエントロピー損失を理解するために、'dls.one_batch'を使ってデータのバッチを取得してみましょう。また、first(dls.train)を使っても全く同じことができます。そして、これを独立変数と従属変数に分解することができます。これは64のカテゴリを示しています。これらの数字は、単に語彙のインデックスを表していることを覚えておいてください。例えば16はボクサーです。show_batch'を実行すると、これらの文字列が自動的に表示されます。これが最初のミニバッチで、'get_prieds'を呼び出すことで、ネットワークの最終層の活性化の予測を見ることができます。データローダを渡すことができます。データローダはミニバッチのシーケンスを返すものであれば何でも構いません。ミニバッチを含むリストをデータローダとして渡すことができます。ここに予測値があります。実際の予測値は、'preds[0].sum'で最初の画像の予測値を取得し、それらをすべて足し合わせると、1つになります。そのうち37個です。これは意味がありますね。だろ？まず最初に、それが'dls.vocab'である確率は何か、最初に、それがアビシニアンキャットである確率は何か、というような感じです。それは10からマイナス6です。となっていますね。とかね。基本的にこれではない、これではない、これではない、これではない、というような感じで、目を通してみると、ああ、これはここにある、これはここにある、というような感じで、明らかにそれが何であるかが分かるのです。どうやって？つまり... 確率の合計が1になるようにしたいんだ もしそうしないと、かなり変なことになるからな そうしないと、これらのうちのどれかになる確率が１以上か１未満か、ということになり、非常に奇妙なことになります。では、これらの予測値を作成するにはどうすればいいのでしょうか？ そのためには、ソフトマックスと呼ばれるものを使います。softmaxは基本的にはシグモイドの拡張で、2つ以上のレベル、2つのカテゴリを扱うことができます。だから、シグモイド関数は次のように見えたのを覚えています。私たちはこれを3対7のモデルに使いました。では、2つのカテゴリではなく、37のカテゴリが必要な場合はどうでしょうか。すべてのカテゴリに1つの活性化が必要です。
3 と 7 のモデルでは、「is-3」モデルとして考えるのではなく、「これには 2 つのカテゴリーがあるので、実際に 2 つの活性化を作りましょう。一つは３のようなものを表すもので、もう一つは７のようなものを表すものです。例えば... MNISTの桁数が 6桁だとすると... これは... これでいいですか？この最初の列は 私のモデルの活性化です 1つの活性化のためのもので 2番目の列は2つ目の活性化のためのものです それで、私の最終層は2つの活性化を持っています これは3のようなものでしょうか？そして、これは7のようなものでしょうか？しかし、これは３のような感じではありませんし、７のような感じでもありません。これは３にとても似ていて、７にはあまり似ていません。だから我々はそのモデルを取ることができます ３のように１つの活性化を持つのではなく ３のように１つの活性化を持つのではなく ３のように２つの活性化を持つことができます ７のように１つの活性化を持つことができます そのシグモイドを取ると 無と1の間の2つの数字が得られます でも1には加算されません それは何の意味もありません 0.66の確率で3と 0.56の確率で7はありえない データセットの全ての桁は 1か他の桁しかないからです これではうまくいきませんが、できることは、この値とこの値の差を使って、3になる可能性がどれくらいあるかを計算してみましょう。言い換えれば、ここにある数字が高くて、ここにある数字が低いと、3になる可能性が非常に高いということになります。つまり、基本的には、これらの活性化のバイナリーケースでは、本当に重要なのは「3」か「7」かの相対的な信頼度であると言えます。つまり、１列目と２列目、あるいは０列目と１列目の差を計算することができますね？ここに２つの列の差があります 大きな差があります その差のシグモイドを取ることができます だろ？これは無と1の間の1つの数字を与えてくれます そして2つの列が欲しかったので 列のインデックス0をシグモイドにして列のインデックス1を1から引くことができます そしてこれらはすべて1に加算されます ここでは3の確率7の確率ですが、2番目の確率はおそらく3、7の確率、などです。このようにして、画像ごとに2つの確率を作る方法ですが、2つの確率を作ることができますそれぞれの確率は0から1の間で、それぞれのペアは1に加算されます いいね どうやって2列以上に拡張するの？これを2列以上に拡張するには，softmaxと呼ばれるこの関数を使います．ソフトマックスはeとxの和をeとxの和で割ったものです ソフトマックスで計算すると 0.6025, 0.3975, 0.6025, 0.3975, 全く同じ値が得られます だろ？つまり２値の場合のソフトマックスは 先ほど見たシグモイドと同じです
しかし、マルチカテゴリの場合は、基本的にはこのようになります。例えば、テディベア、グリズリーベア、ヒグマをやっていたとしましょう そのために、我々のニューラルネットには最終層があり、3つの活性化があります 0.02, -2.49, 1.25とします ソフトマックスを計算するには、まず、これらの3つのパワーにeをかけますeは0.02のパワー、eは-2.49のパワー、eは3.4のパワー、eは1.25のパワーです これを足し算して、指数の和を求めると、softmaxは単純に1.02÷4.6となり、これは0.08÷4.6となります。これは3.49を4.6で割ったものですから、それぞれの数値を和で割ったものを表していますので、合計は1ということになります。これらはすべて正の値であり、それぞれの値は合計で割った値なので、すべての値がゼロから１の間にあることを意味します。つまり、ソフトマックスは常に1から0の間の値を与え、その合計が1になることを示しています。 実際には、トーチドットのソフトマックスを呼び出すだけで、次のような結果が得られます。そうすると、この関数の結果が得られます。これを自分の時間で実験してみてください。手書きで書き出してみて、これらの数値を入力してみてください。ソフトマックスの興味深い点の一つは...指数は何かの力に対するeだと お話ししましたね つまり何かの力に対するeは とても速く成長するということです だろう？例えば、４の指数は５４、８の指数は２９、２９８０です。これは非常に速く成長します。つまり、他のものよりも少しだけ大きい活性化があれば、そのソフトマックスは他のものよりも大きくなります。直感的には、ソフトマックス関数は他のクラスの中から1つのクラスを選ぼうとします。これは一般的に、どの品種かという分類器を訓練しようとするときに必要なことです。これがソフトマックス関数の目的です。ソフトマックスはそれを実現しています。いつもそうしたいわけではありません。推論の時には少し慎重になってほしいと思うこともあります。ソフトマックスは常に完璧なアプローチではありませんが、これがデフォルトなのです。これは私たちがよく使うもので、多くの状況でうまく機能しています。これがsoftmaxです。さて、MNISTの3対7のバイナリのケースでは、MNISTの損失を計算しました。あなたが見たようにうまくいったでしょう？これも全く同じことができます もうトーチドットは使えません ターゲットは0や1だけではないので ターゲットは0から36までの任意の数になります そこで、トーチドットをインデックスに置き換えることで、そのようなことが可能になります。バイナリの場合の例を示します。これがターゲット 0 1 0 1 1 1 0 0 で、これがソフトマックスの活性化で、前に計算したものです。そこで、トーチドットの代わりに、これを見てみましょう。
0から5までのすべての数字と目標値、0 1 0 1 0 1 0 1 1 0 1 0 それから何をするかというと、0行目に0.6を選びます。そして、1行目は0.49の1を選び、2行目は0.13の0を選び、4行目は0.003の1を選びます。これは非常に気の利いたインデキシング式で、ぜひ使ってみてほしいもので、基本的には複数のものを pytorch のインデキサーに渡すというトリックだ。第一に、どの行を返すか、第二に、それらの行のそれぞれについて、どの列を返すか、ということが書かれている。つまり、これはすべての行とこれらの列を、それぞれの行に対して返すということで、実際にはトーチのドットがどこにあるかと同じです。難しいですよね？これで、2つの値以外にも使えるようになりました。これが完全に完成したもので、3列、7列、ターゲット、ここにインデックスがあります。0, 0, 0, 0.6; 1, 1, 0.49; 0, 2, 0.13, などです。このように、これは2つ以上の列があっても同じように動作します。これを追加して、完全なMNISTを行うためには、0から9までのすべての桁を追加することができます。10列あってもいいし 10列をインデックス化するだけでいい つまり、活性化行列から活性化行列を引いて、 無数からNまでの全ての数字と目標値を計算することは、 pytorchに既に存在する F dot nll_loss と呼ばれるものと全く同じものです。全く同じだ。このように、pytorchやfastAIの中にあるものは、我々が自分で書くことができるもののための小さなショートカットであることがわかります。Nll_lossは負の対数尤度の略で、複雑に聞こえるかもしれませんが、実際にはこのインデックス式です。紛らわしいことに、この中にはログがありません。その理由はすぐにわかります。ではログについて話しましょう この損失、損失関数はノート04で見たように非常によく機能します。基本的にはノート04で学んだことと全く同じですが、表現の仕方が違うだけで、実際にはもっと良いものができます。確率はゼロから1までの間にあることを覚えておいてください 0より小さくてはいけません 1より大きくすることはできません。つまり、我々のモデルが.990か.999を予測するかどうかを決定しようとしている場合、これらの数字は非常に近くにあると考えるでしょうが、実際には気にしません。しかし、実際に誤差について考えてみると、もし100個、1000個の誤差があるとしたら、これは10個の誤差があり、1個の誤差があるようなものです。しかし、これはこれよりも10倍も良いので、実際にやりたいことは、ゼロと1の間の数値を、負の無限大と無限大の間の数値に変換することです。これを正確に行う関数があります 対数と呼ばれるものです つまり、ゼロと１の間にある数値はゼロに近づくにつれて無限大になり、１になるとゼロになります。この対数は、忘れてしまったかもしれませんが、高校で習った対数のことを ぼんやりと覚えていると思いますが、基本的には次のように定義されています：もし、あなたがyで、bがaの累乗になるような数があるとします
そして、対数は、aがyのコンマbの対数に等しくなるように定義されます。言い換えれば、yに等しいものの何乗までbを教えてくれます。小さなものをたくさん掛け合わせると小さな数になりますが、大きなものをたくさん掛け合わせると大きな数になります。大きくなったり小さくなったりして、コンピュータの浮動小数点の精度が本当に悪くなるのに対し、ここでの足し算は制御不能になることはありません。私たちは対数を使うのが大好きで、特に何層もあるディープ・ニューラル・ネットでは、何度もかけたり足したりしていますが、このような対数はとてもきれいに出てくる傾向があります。先ほど見た確率、この関数から出てきたものを取って、その対数を取って平均を取ると、負の対数尤度と呼ばれるものが出てきます。ソフトマックスを取り、ログを取り、それをnll_lossに渡すと、名前にもかかわらず実際にはログを取っていないことを覚えておいてください。なぜ nll_loss は実際にログを取らないのかという明白な疑問が残ります。その理由は、ソフトマックスステップで実際にログを取った方が計算上便利だからです。そのため、pytorch は log_softmax という関数を持っており、softmax の段階でログを取る方が実際には簡単なので、より速く、より正確にログを取ることができる。Pytorch は soft log max を使用し、それを nll_loss に渡すことを前提としている。nll_lossはログを実行しない。つまり、log_softmax の後に nll_loss が続くのが pytorch のクロスエントロピー損失の定義である。これが損失関数で、いくつかの活性化やターゲットを渡して、数値を返すことができる。pytorch のドキュメントでは通常クラスバージョンを使用していますが、通常はクラスバージョンを使用していることがわかります。これは平均値を取得するためですが、もし平均値を取得する前に基礎となる数値を見たいのであれば、 reduction=none を渡すだけで、平均値を取得する前の個々のクロスエントロピー損失を表示してくれます。さて、これで損失関数などの議論はここまでにしましょう。 レイチェル これについて何か質問は？なぜ損失関数が負の値である必要があるの？まあ、そうですね、そうではないと思いますが......私たちは低い方がいいと思っていて........どこかで切り離す必要があると思っているんです。今週はもっと考えないといけないんだけど、ちょっと大変だし、ちょっと疲れてるから。うん、だから、起きているときに記憶をリフレッシュさせてみるよ
はい、わかりました。 来週は...いや、ビデオのためじゃない。 来週は先週の出来事なので、私が言おうとしていることは、実際にはあなたのことです。 来週はデータ倫理についての話になりますが、私の一週間の出来事を話すことで、私の一週間がどのようなものであったかを話したいと思いました。  人前でマスクをすることについてですが、マスクの効果は非常に高いようで、誰もがマスクをした方がいいのではないかということを指摘しました。 そうすると、いつのまにか私は世界的なキャンペーンの顔になっていました。 masks4all.coに行けば、マスクについてのサイトがあります。  南アフリカ、アメリカ、イギリス、オーストラリアの テレビ番組にも出演しました ラジオでもマスクの話をしていました  どうして？ データサイエンティストとして 気付いたからです マスクに関するデータは 誤解されているようです その誤解が何十万人もの命を 犠牲にしているようです   ご存知のように、文字通りマスクを使用している場所では、死亡者数が桁違いに少なくなっています。  データサイエンティストとしてのあなたの役割とは何か、ということです。 そこで私は、ワシントン・ポスト紙に掲載された記事を書いて、マスクの着用を真剣に考えるべきだと呼びかけました。 そして、私は運が良かったんです、優秀なボランティアの巨大なチーム（巨大ではありませんが、まともな規模の優秀なチームです）に助けてもらいました。 しかし、明らかになってきたのは、政治家や上院議員、職員と話していて、明らかになってきたのは、人々は科学的な根拠に納得していないということです。 WHOやCDCがマスクをしなくてもいいと言っているのに、無作為にデータを作っている科学者が言っていますが、データが示しているものとは違うようです。 半分の脳みそを持っている人なら、ランダムなデータサイエンティストではなく、WHOやCDCを選ぶでしょう。 だから、私は本当に感じていたのですが、効果的な擁護者になるためには、科学を整理する必要があると。  そして、あなたは知っていると思いますが、信任主義は強力です。 だから、私が言うだけでは十分ではありません。他の人を探す必要がありました  そこで私は19人の科学者からなるチームを作りました。社会学の教授、エアロゾル力学の教授、結核の予防法を研究しているアフリカの運動の創始者、マスクの廃棄と洗浄方法を研究しているスタンフォード大学の教授、
UCLAの教授で、感染症の疫学者の中でもトップレベルの専門家、とか。 世界中から集まったこのようなオールスターチームのようなもので、私はこの人たちに会ったことがありませんでした（いや、そうではなくて、オースティンは少し知っていたし、ゼイネップも少し知っていたし、レクスも少し知っていました）。 でも全体的には（レシャマもそうだけど、彼女がすごいのはみんな知ってるよね。 だから実際にfast.aiのコミュニティの人がいるのは素晴らしいことだと思います。それで、でもね、でもね、人を集めようとしたんだけど、できるだけ多くの地域の人を集めて、できるだけ多くの専門分野の人を集めました。  グローバルなコミュニティのおかげで、あらゆることについての論文を見つけることができました。 様々な物質がどのように機能するのか、液滴がどのように形成されるのか、疫学、マスクをしている人としていない人の感染事例研究など、様々なことについてです。  そして、先週、私たちはこの論文を書き上げました  84の引用が含まれています  基本的には24時間体制で チームとして働きました そして完成しました  3、4日前にはいくつかの政府機関に送ったのですが、そのうちのいくつかは、この論文の中でも特に重要なことがあります。 だから、このチームの中には、その一つがあります。私は政府の指導者と密接に仕事をしている人を探すようにしています 彼らが科学者であるということだけではありません  これは何人かの政府の閣僚に送りました   ここ数日で、政府がマスクに関するガイドラインを変更する際に 非常に重要な役割を果たしたと聞いています  戦いは決して終わったわけではありません 特に英国は少し孤立しています  しかし、私は明日ITVに出て、次の日にはBBCに出ます  ただのデータサイエンティスト以上の存在になるためには、一歩踏み出す必要があります。  だから、政治家や職員を集めなければなりませんでした。  私は、メディアに取材してもらうためには、メディアとの交渉をしなければなりませんでした。 今日、私は組合と協力して、組合にこのことを理解してもらおうと多くの仕事を始めています。データサイエンティストとして、そして実際の科学者と協力して、私たちは本当に強い理解を築いてきました。 これを意思決定者に効果的に伝えることができなければ、何の役にも立ちません。今日、私は電話で、この意味を説明しました。この国のトップの労働組合のリーダーの一人と。  基本的にアメリカのバスのエアコンは後ろから前に向かって吹き出すように設定されています。 レストランのエアコンの風下の席に座っていた人がコビド１９号に感染したという事例が医学文献に載っています   バスの運転手が死んでいく理由がわかります  それは、彼らが間違った場所にいて乗客がマスクをしていないからです  私はこの科学を組合のリーダーに説明しました。 労働者の安全を守るためには、運転手だけでは不十分で、バスに乗っている人全員がマスクを着用する必要があることを理解してもらいました。 これは基本的に、データサイエンティストとして、データを研究して何かをする責任があると思います。 ただの研究ではありませんし、ただの計算でもありません。 何かにつながらないと何の意味があるんだ？ というわけで、ええ、それでは、来週。 これについてはもっとたくさん話しますが、私にとっては、データを掘り下げていくことで、本当に驚くようなことが起こるという、とても興味深い例だと思います。 このケースでは、私は強く信じていますし、多くの人が私に言っていますが、このデータ分析から生まれたこの種の支援活動は、すでに命を救っているのです。これが、あなたのデータ分析を、本当に変化をもたらす場所に持っていくための、あなたのインスピレーションの一助になればと思います。 それでは、ありがとうございました。また来週お会いしましょう。


