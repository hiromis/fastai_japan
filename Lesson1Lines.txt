




すでにダウンロードされている場合は、再度ダウンロードすることはありませんし，解凍済みなら解凍しません。
ご覧のように、fastAIはすでに多くの有用なデータセットを定義しています。
データセットは深層学習で想像できるように超重要です。
これからたくさんのデータセットを見ていくでしょう。
そして、これらのデータセットは多くのヒーロー（とヒロイン）によって作成され、基本的には数ヶ月から数年かけてデータを照合し、これらのモデルを構築するために使用することができます。
次のステップは、このデータが何であるかをfastAIに伝えることであり、データについて私たちは多くのことを学んでいきます。
しかし、今回は、基本的には「これには画像が含まれている」と言っています。
このパスにある画像が含まれています。
untar_dataは解凍済みの
データのパスを返します。
あるいはすでに解凍されている場合は、以前に解凍された場所を教えてくれます。
そのパスの中に実際にどんな画像があるのかを教えてくれます。
本当に興味深いものに label_func があります。
ファイルごとに、それが猫なのか犬なのかをどうやって判別するのでしょうか。
実際にオリジナルのデータセットのReadMEを見てみると、少し風変わりなものが使われています。
しかし彼らが決めたことです。
そこで、ここにis_catという小さな関数を作って、最初の文字が大文字かどうかを返すようにしました。
これで猫かどうかを判断する方法をfastaiに伝えました。
この2つについては後で説明します。
次に、データが何であるかを伝えます  次にlearnerと呼ばれるものを作らなければなりません。
learnerとは学習するものです。
訓練をします。
だから、どんなデータを使うか教えなければなりません。
そして、どのようなアーキテクチャを使うかを教えなければなりません。
このコースではアーキテクチャについてたくさんお話します。
しかし、基本的には、事前に定義されたニューラルネットワークのアーキテクチャがたくさんあり、それぞれ長所と短所があります。
コンピュータビジョン用のアーキテクチャはResNetと呼ばれています。
これは非常に素晴らしい出発点なので、ここでは小さ目なものを使うことにします。
これらはすべて事前に定義されていて、すぐに使えます。
そして、訓練中にプリントアウトしたいものをfastaiに伝えることができます。
ここでは、「ああ、誤差を教えてください、トレーニング中に」と言っています。
そして、fine_tuneと呼ばれるとても重要なメソッドを呼び出すことができます。
次のレッスンで説明しますが、fine_tuneが訓練を行います。
valid_pctは非常に重要なことをします。
この場合、データの20%は、モデルの学習には使用しません。
その代わりに、モデルの誤差率を知るために使います。
したがって、常にfastaiでは、このメトリック、error_rateは常に訓練されていないデータの一部で計算されます。
この考え方については、今後のレッスンで詳しく説明します。
しかし、ここでの基本的な考え方は、過学習していないことを確認したいということです。
説明しましょう。
過学習は次のようなものです。
例えば、これらの点にフィットする関数を作ろうとしているとしましょう。
素敵な関数はこのようになりますよね？しかし、この関数をはより正確にフィットしています。
見てください、これはこちらよりもはるかにすべての点に近づいています。
ですから、明らかにこちらの方が優れた関数です。
ただし、点がある場所の外に出るとすぐに、特に端から外れてしまうと、明らかに意味がありません。
これが過学習と呼ばれるものです  過学習は様々な理由で起こります。
大きすぎるモデルを使ったり、十分なデータを使っていなかったり...この話はこれからですね。
しかし、ディープラーニングの技術は、適切なフィットを持つモデルを作成することがすべてです。
モデルが適切にフィットしているかどうかを知る唯一の方法は、それを訓練するために使用されていないデータでうまく機能するかどうかを見ることです。
そのため、私たちは常にデータの一部を脇に置いて、バリデーション・セットと呼ばれるものを作成します。
バリデーション・セットとは、モデルを訓練しているときには全く触らないようにしているデータですが、モデルが実際に機能しているかどうかを把握するためだけに使用しています。
シルヴァンが本の中で言っていたことですが、fastaiを勉強していて面白いことの一つは、多くの面白いプログラミングを学ぶことができるということです。
私は子供の頃からプログラミングをしていたので、かれこれ40年くらい経ちます。
シルヴァンと私は二人ともpythonで多くのことを行うために本当に一生懸命働いていて、プログラミングのプラクティスを知っています。
私たちのコードの中では、今まで見たことのないようなことをやっていることがよくあります。
以前のコースを受講した多くの学生は、このコースでコーディングやPythonコーディング、ソフトウェアエンジニアリングについて多くを学んだと言っています。
だから、何か新しいものを見たときはチェックして、なぜそのような方法で行われたのか気になったらフォーラムで気軽に質問してください。
一つ言及しておきたいのは、先ほども述べたように、ほとんどのPythonプログラマーがimport *を行うことはありません。
私たちはそのようなことをたくさんやっています。
私たちは伝統的なPythonプログラミングのアプローチに従わないことをたくさんやっています。
私は長年にわたって多くの言語を使ってきたので、特にPython的な方法ではなく、他の多くの言語や他の多くの表記法からのアイデアを取り入れて、データサイエンスに適したものをベースにPythonプログラミングへのアプローチを大幅にカスタマイズしています。
つまり、あなたがfastaiで見たコードは、あなたの職場でPythonを使っている場合、おそらく、あなたの職場のスタイルガイドや通常のアプローチには合わないでしょう。
ですから、私たちのやり方に従うのではなく、あなたの組織のプログラミングのやり方に合うようにする必要があります。
しかし、おそらくあなた自身の趣味の仕事では、私たちのものに従ってみて、それが面白くて参考になるかどうかを見てみてもいいでしょうし、もしあなたが管理職で、そうすることに興味があるのであれば、あなたの会社でそれを試してみるのもいいでしょう。
さて、最後に、かなり面白いものをお見せしましょう、それは、このコードを見てみてくださいuntar_data、ImageDataLoaders.from_name_funcから、learner、fine_tuneします。
untar_data、SegmentationDataLoaders.from_label_func、label_func、learner、fine_tune。
ほとんど同じコードですが、これは何かをするモデルを構築しました。
これは画像を撮影したものです。
左側がラベル付きのデータです。
色は、それぞれ、車、木、建物、空、線、道路などを示しています。
右側は私たちのモデルですが、私たちのモデルは各ピクセルごとに、車なのか、ラインマークなのか、道路なのかを判別することに成功しました。
たった20秒以内でこれを実現しました。
ですから、非常に小さなモデルです。
いくつかのミスをしています -- この線のマークを見落としていたり、いくつかの車が家だと思っているような？しかし、数分間これを訓練すれば、ほぼ完璧になることがわかります。
基本的な考え方は、ほぼ同じコードを使って、猫や犬を分類するのではなく、セグメンテーションと呼ばれるものを非常に速く作ることができるということです。
見てください、同じものがあります。
Import *、TextDataLoaders.from_folder，learner、fine_tune
基本的なコードは同じです。
これは、文章が表している感情が肯定的か否定的かを理解するできるようになりました。
同じ3行のコードで15分の訓練による93%という正確度は、1000から3000語の何千もの映画レビューからなるIMDBデータセットの分類においては2015年時点で世界最高のものだったと思います。
私たちは基本的に同じコードを使って、私たちのブラウザで、世界クラスのモデルを作成しています。
ここでも同じ基本的な手順です。
from import *、untar_data、TabularDataLoaders.from_csv、Learner、fit
これは今、これらの列を含むcsvに基づいて給与を予測するモデルを構築しています。
これは表形式のデータですね。
ここでは基本的な手順は同じです。
Import *、untar_data、CollabDataLoaders.from_csv、learner，fine_tune
これはユーザーと映画の組み合わせごとに、視聴履歴をもとに，ユーザが映画をどう評価するかを予測するものを構築しています。
これは協調フィルタリングと呼ばれ、レコメンデーションシステムで使用されています。
ここでは、fastaiの4つのアプリケーションの例を見てきました。
このコースを通してお分かりになると思いますが、基本的に同じコードと、同じ数学とソフトウェア工学の基本的な概念によって、同じようなアプローチを使って、大きく異なることができるのです。
なぜかというと、アーサー・サミュエルのおかげです。
モデルをパラメータ化する方法と、重みを更新して損失関数を改善する更新手順があれば、何ができるのかという基本的な説明があるからです。
この場合、ニューラルネットワークを使うことができます。
他のレッスンよりも少し短くなりますが、その理由は、先ほど述べたように、私たちは世界的なパンデミックの始まりの時期にあるからです（少なくとも欧米では（他の国ではもっと進んでいます）。
このことについては、コースの最初の方でお話しましたが、そのビデオは別の場所で見ることができます。
今後のレッスンでは、より深層学習について学ぶことになるでしょう。
次のレッスンに取り組む前に、次の週までに以下に取り組むことをお勧めします。
GPUサーバをスピンアップして、終了したらシャットダウンして、ここにあるすべてのコードを実行できることを確認して、自分が認識できる方法でPythonを使っているかどうかを確認してください。
自分のやり方を知ることができれば、快適に過ごせるようになるでしょう。
この学習スタイル、トップダウン学習で最も重要なことは、実験を行うことであり、コードを実行できるようになる必要があります。
ですから、私のお勧めは、コードを実行できるようになるまでは先に進まないで、本の章を読んで、アンケートに答えてください。
検証セットやテストセット、転送学習については、まだまだやるべきことがあります。
ですから、まだすべてのことができるわけではありませんが、これまでのコースを見てきたことに基づいて、できる部分はすべてやってみてください。
レイチェル、何か追加したいことがあれば教えてください。
それでは、レッスン１に参加してくれてありがとうございました。
次回は転移学習について学び、その後、実際にインターネット上で公開できるアプリの制作に移ります。
