0:00:00.640,0:00:06.920
皆さんこんにちは、コーダーのためのディープラーニング、レッスン１へようこそ。

0:00:06.920,0:00:18.140
今年で4年目になりますが、これまでとは違った特別なバージョンになっています。

0:00:18.140,0:00:25.980
まず第一に、完全にシャットダウンされた初日から生放送でお届けします。

0:00:25.980,0:00:29.860
完全なシャットダウンではありませんがサンフランシスコはほぼ完全にシャットダウンしています。

0:00:29.860,0:00:34.960
この世界的なパンデミックの真っ只中で ２ヶ月間に渡って 録画する予定です。

0:00:34.960,0:00:39.520
もしこのコースで時々少し慌ただしいように見えたら謝罪します。

0:00:39.520,0:00:42.000
しかし、このようなことが起きているのが理由です。

0:00:42.000,0:00:53.000
もう一つの特別な理由は これを私たちの決定版にしようとしているからです。

0:00:53.000,0:01:00.500
長い間続けてきたことで やっと自分たちが何を言ってるのか、わかった気がしてきました。

0:01:00.500,0:01:05.480
シルヴァンと私は実際に本を書いて、

0:01:05.480,0:01:12.000
ゼロからfastai2というソフトウェアも書きました。

0:01:12.020,0:01:17.660
このライブラリについては査読付きの論文も書いています。

0:01:17.660,0:01:26.980
ですから、このバージョンのコースは、うまくいけばしばらくは続くと思います。

0:01:26.980,0:01:32.000
シラバスはこの本に非常に密接に基づいています。

0:01:32.000,0:01:38.140
だから、もしあなたがちゃんと読みたいのであれば、ぜひ買ってください。

0:01:38.140,0:01:45.860
そして、「買ってください」と言っているのは、実際にはジュピターノートブックという形で全てが無料で手に入るからです。

0:01:45.920,0:01:54.420
これはオライリー・メディアの寛大なご厚意のおかげです。

0:01:57.440,0:02:03.680
コースのウェブサイトにアクセス方法が掲載されていますが、

0:02:05.600,0:02:11.000
ここにあるfastbookのレポでは全ての内容を読むことができます。

0:02:11.880,0:02:18.000
今のところ、ご覧のようにそれは草稿ですが、あなたがこれを読む頃にはそうはなっていないでしょう。

0:02:18.000,0:02:22.000
そこで、ここで大きな要望があります。

0:02:23.360,0:02:30.380
ジュピターノートブックとして無料で読むことができますが、

0:02:30.380,0:02:36.000
Kindleや紙の本などで読むのと比べると便利ではありません。

0:02:36.000,0:02:39.360
だから、これをPDFにするのはやめてください。

0:02:39.360,0:02:44.520
読むことを目的としたフォーマットにはしないでください。

0:02:44.520,0:02:50.440
そもそもの目的はよかったらあなたに買ってもらうことです。

0:02:50.440,0:03:00.320
オライリーの寛大さを利用して、タダで貰えないと分かっているものを作るのはやめてください。

0:03:00.320,0:03:06.320
実際にはそれが、私たちがこれを提供しているライセンスなのです。

0:03:06.640,0:03:09.500
これは主にまともな人間であってくださいとのお願いです。

0:03:09.500,0:03:15.240
もし他の誰かがまともな人間ではなく、書籍版を盗んでいるのを見たら、

0:03:15.240,0:03:19.000
「そんなことしないでくれ、迷惑だから 」と言ってあげてください。

0:03:19.000,0:03:20.700
そして、そんな人にならないようにしましょう。

0:03:21.280,0:03:27.000
ということで、どちらにしても、本の中のシラバスに沿って読んでください。

0:03:28.000,0:03:34.000
このノートにはいくつかのバージョンがあります。

0:03:38.120,0:03:46.500
全部の文章、写真、全てが載っている完全なノートがあります。

0:03:46.800,0:03:54.520
私たちは実際にジュピターノートブックを印刷する本にするためのシステムを作ったたのですが、

0:03:54.520,0:03:56.880
それがちょっと変な感じに見えることがあります。

0:03:56.880,0:04:00.920
例えば、ここに変な表がありますが、

0:04:01.020,0:04:04.680
実際の本の中を見てみると、

0:04:05.380,0:04:07.480
実際にはちゃんとした表のように見えますよね。

0:04:07.560,0:04:11.300
時々変なところが出てきますが、

0:04:11.300,0:04:13.300
これは間違いではありません。

0:04:13.420,0:04:20.000
本を素敵な本にするための情報を追加するためのものですので、無視してください。

0:04:20.660,0:04:23.940
さて「私たち」と言えば、私たちとは誰でしょう？

0:04:23.940,0:04:30.000
「私たち」の重要な部分の一つがシルヴァンです。

0:04:30.000,0:04:39.000
シルヴァンは本とfastaiバージョン2ライブラリの私の共著者ですので、彼は私の犯罪のパートナーです。

0:04:39.000,0:04:45.880
「私たち」のもう一人はレイチェル・トーマスです。

0:04:45.880,0:04:48.460
レイチェル、挨拶をしに来てください。

0:04:48.520,0:04:52.040
彼女はfastaiの共同設立者です。

0:04:52.040,0:04:55.600
こんにちは、私はfastaiの共同創設者です。

0:04:55.600,0:04:57.220
そして、あ、低く。

0:04:57.220,0:04:58.120
すみません。

0:04:58.120,0:04:59.740
私はジェレミーよりも背が高いんです。

0:04:59.740,0:05:05.500
そして私はサンフランシスコ大学の応用データ倫理センターの創設ディレクターです。

0:05:05.500,0:05:08.000
このコースに参加できることを本当に楽しみにしています。

0:05:08.000,0:05:12.000
そして私の声がフォーラムからの質問を聞く声になります。

0:05:14.820,0:05:19.000
レイチェルとシルヴァンは、このグループの中で実際に数学を理解している人たちです。

0:05:19.000,0:05:21.480
私は単なる哲学の卒業生です。

0:05:21.480,0:05:23.300
レイチェルは博士号を持っています。

0:05:23.300,0:05:26.520
シルヴァンは数学について10冊の本を書いているので、

0:05:26.520,0:05:32.000
もし数学の質問が来たら、私はそれを委託すかもしれません。

0:05:32.000,0:05:38.000
でも、この課題をよく理解している人たちと一緒に仕事をする機会があるのは、とても嬉しいことです。

0:05:38.000,0:05:41.940
はい、はいレイチェル、

0:05:41.940,0:05:44.020
あぁ、ありがとうございます。

0:05:45.120,0:05:52.500
レイチェルが言ってたように、彼女が実際の世界クラスの専門知識を持っているのは

0:05:52.500,0:05:58.860
データ倫理であり、彼女は応用データ倫理センターの創設ディレクターです。

0:05:59.000,0:06:00.580
サンフランシスコ大学です 

0:06:00.580,0:06:02.020
サンフランシスコ大学ですね、ありがとうございます。

0:06:02.020,0:06:05.820
私たちはコースを通してデータ倫理について話します。

0:06:05.820,0:06:10.000
なぜなら、私たちはたまたまそれが非常に重要だと考えているからです。

0:06:10.500,0:06:13.960
私が一般的にそれらを発表することになりますが、

0:06:13.960,0:06:18.680
全体的にはレイチェルの仕事に基づいたものになります。

0:06:18.680,0:06:20.900
彼女は実際に何を言っているのかを知っているので。

0:06:21.140,0:06:26.260
でも、彼女のおかげで、私も私が話していることを少しは知っています。

0:06:26.560,0:06:29.120
それはそれとして。

0:06:31.280,0:06:34.600
あなたはここにいるべきでしょうか。

0:06:34.600,0:06:38.500
あなたがを理解することにどんな目的があるのか

0:06:38.500,0:06:40.520
（私は正しいボタンを押したと思った）

0:06:40.520,0:06:43.460
深層学習を理解しようとすることに意味があるのでしょうか？

0:06:44.720,0:06:49.120
OK 、あなたは何を・・・あなたはここにいるべきでしょうか。

0:06:49.120,0:06:52.800
あなたが深層学習を学んでメリットがありますか？

0:06:52.800,0:06:55.320
あなたがあまり頭がよくないですか？

0:06:55.320,0:06:59.480
または十分高速なコンピューターを持っていないですか？、などなど。

0:06:59.480,0:07:01.780
それは多くの人々が私たちに言ってくることです。

0:07:01.780,0:07:06.940
彼らは、博士号を持ったチームとGPUを搭載した大規模なデータセンターが必要だと言っています。

0:07:06.940,0:07:08.540
そうでなければ無意味だと。

0:07:08.550,0:07:12.080
心配しないでください、それは全く真実ではありません。

0:07:12.080,0:07:14.020
真実からこれ以上離れたものはありません。

0:07:14.020,0:07:21.740
実際、大多数の世界的な研究や世界的な産業プロジェクトの多くは、

0:07:21.740,0:07:33.689
fastaiの卒業生やfastaiライブラリを使ったプロジェクトや他の場所から生まれたもので、

0:07:33.689,0:07:41.040
大学院レベルの技術的な専門知識を持たない人たちから、

0:07:41.040,0:07:49.780
数十、数百のデータポイントを使って単一のGPUで作られたものです。

0:07:49.780,0:07:52.540
私はといえば大学レベルの専門知識もありません。

0:07:52.550,0:07:55.080
私は哲学部です。

0:07:55.080,0:07:59.719
しかし、ディープラーニングを使って素晴らしいことをするためには、

0:07:59.719,0:08:03.770
たくさんの数学は必要ないし、たくさんのデータも必要ないし、

0:08:03.770,0:08:08.250
高価なコンピュータも必要ないという明確な実証的証拠がたくさんあります。

0:08:08.250,0:08:10.240
だから我々と一緒に我慢して付いてきてみてください。

0:08:10.240,0:08:12.229
あなたは大丈夫です。

0:08:12.229,0:08:15.110
このコースを受けるには コードを書く必要があります。

0:08:15.110,0:08:18.750
できればPythonでコードを書く方法を 知っていることが望ましいです。

0:08:18.750,0:08:21.900
他の言語をやったことがあれば Pythonを学ぶことができます。

0:08:21.900,0:08:26.939
もしあなたがこれまでにやったことのある言語がMatlabのようなもので、

0:08:26.939,0:08:32.570
スクリプトのようなものを使ったことがあるのであれば、少し難しく感じるかもしれません。

0:08:32.570,0:08:35.880
しかし、それでいいんです。
頑張ってください。

0:08:35.880,0:08:40.990
Pythonはどんどん学習していけばいいのです。

0:08:40.990,0:08:42.690
深層学習を学ぶ意味はありますか？

0:08:42.690,0:08:46.220
何かディープラーニングの得意なことはありますか？

0:08:46.220,0:08:52.560
もしあなたが脳を作りたいと思っているのであれば、それはAGIです。

0:08:52.560,0:08:55.600
なのでこのコースがあなたをの役に立つとは約束できません。

0:08:55.680,0:08:58.860
AGIは 人工知能（Artificial General Intelligence）の略です。

0:08:58.870,0:09:00.339
ありがとうございます。

0:09:00.339,0:09:06.870
しかし私が言えることは これらの分野のすべてにおいて 少なくとも多くのバージョンでは 

0:09:06.870,0:09:12.760
ディープラーニングが最もよく知られたアプローチであるということです。

0:09:12.760,0:09:18.130
ですから、これが有用なツールであるかどうかは、現時点では推測ではありません。

0:09:18.130,0:09:21.880
たくさんの、たくさんの、たくさんの、たくさんの場所で役に立つツールなのです。

0:09:21.880,0:09:23.040
極めて有用なツールです。

0:09:23.040,0:09:29.150
そして、これらの多くのケースでは、人間のパフォーマンスと同等かそれ以上であるのです。

0:09:29.150,0:09:35.320
（少なくとも、この種の分野で人間が行うことのいくつかの特定の狭い定義によると）

0:09:36.240,0:09:38.880
ディープラーニングは非常に素晴らしいものです。

0:09:38.900,0:09:45.680
ここでビデオを一時停止して、興味がありそうなものをいくつかピックアップしてみてください。

0:09:45.680,0:09:48.980
そしてそのキーワードとディープラーニングをGoogleで検索すれば、

0:09:48.980,0:09:53.180
たくさんの論文や事例などが見つかるはずです。

0:09:55.360,0:09:59.800
ディープラーニングは、ニューラルネットワークの背景から来ています。

0:09:59.800,0:10:05.240
見ての通り、ディープラーニングはニューラルネットワーク学習の一種です。

0:10:05.240,0:10:06.920
深いものです。

0:10:06.920,0:10:08.650
それが何を意味するのかは後ほど正確に説明します。

0:10:08.650,0:10:11.660
そして、ニューラルネットワークは確かに新しいものではありません。

0:10:11.660,0:10:14.420
少なくとも1943年までさかのぼります。

0:10:14.420,0:10:19.300
マックロックとピッツが 人工ニューロンの数学モデルを作成した時です。

0:10:19.300,0:10:23.080
そして、それがどこに到達するかについて非常に期待されました。

0:10:23.080,0:10:31.040
50年代には、フランク・ローゼンブラットが、その上に数学モデルを構築しました。

0:10:31.040,0:10:36.320
彼は基本的に、その数学モデルに微妙な変更を加えました。

0:10:36.320,0:10:38.400
そして彼は、これらの微妙な変更で、

0:10:38.400,0:10:44.980
「人間の訓練や制御なしに 周囲の環境を看取、認識、識別できる機械の誕生を 目撃することができる」

0:10:44.980,0:10:46.960
と考えました。

0:10:46.960,0:10:51.200
そして彼はこの驚異的なものの開発を監督したのです。

0:10:51.200,0:10:54.860
コーネル大学のマーク１パーセプトロンです

0:10:54.860,0:11:00.269
この写真は１９６１年だったと思います。

0:11:00.269,0:11:04.610
ありがたいことに今日では、ニューラルネットワークを構築するために、

0:11:04.610,0:11:07.089
ニューロンからニューロンへ（人工ニューロンから人工ニューロンへ）配線をを走らせる必要はありません。

0:11:07.089,0:11:10.800
しかし、多くの接続が行われているという考えが見えてきます。

0:11:10.800,0:11:14.220
このコースでは、接続（コネクション）という言葉をよく耳にするでしょう。

0:11:14.220,0:11:16.880
それはここからきています。

0:11:16.880,0:11:19.790
それから、私たちは最初のAIの冬を迎えました。

0:11:19.790,0:11:26.899
これは、MITのマービン・ミンスキー教授とパパートが ローゼンブラットの発明について 

0:11:26.899,0:11:31.810
パーセプトロンという本を書きました。その中で 彼らが指摘したのは、

0:11:31.810,0:11:38.740
これらの人工ニューロンデバイスの単一の層は、実際にはいくつかの重要なことを

0:11:38.740,0:11:40.620
学ぶことができないということです。

0:11:40.620,0:11:45.990
ブール演算子のXOR演算子のような簡単なものを学ぶことは不可能でした。

0:11:45.990,0:11:51.570
同じ本の中で、彼らは、人工ニューロン装置を何層にも重ねて使えば、

0:11:51.570,0:11:52.570
実際に問題が解決することを示しています。

0:11:52.570,0:11:54.880
でも人々は無視 - 本のその部分に気づかなかったのです。

0:11:54.880,0:11:59.960
そして、制限にだけ気付き、人々は基本的にニューラルネットワークは

0:11:59.960,0:12:01.820
どこにも行かないと決めつけてしまいました。

0:12:01.829,0:12:07.000
そして何十年もの間、それらはほとんど姿を消してしまいました。

0:12:07.000,0:12:09.829
ある意味で1986年までは。

0:12:09.829,0:12:16.100
その間にいろいろなことがありましたが、1986年に大きなことがありました。

0:12:16.100,0:12:22.560
MITが「並列分散処理」という本を出版、2巻に分けてシリーズ化したものです。

0:12:22.560,0:12:28.020
その中で、並列分散処理（Parallel Distributed Processing）と呼ばれるものを説明していました。

0:12:28.020,0:12:35.769
並列分散処理とは、たくさんの処理装置と、アクティベーションと、出力機能と、

0:12:35.769,0:12:41.709
接続性のパターンと、伝播ルールと、活性化ルール、

0:12:41.709,0:12:44.910
学習ルールを持った処理ユニットが、環境の中で動作しているというものです。

0:12:44.910,0:12:50.160
そして、これらの要件を満たすものが、どのようにして理論的にはあらゆる種類の

0:12:50.160,0:12:52.300
驚くべき仕事をすることができるのかを説明しました。

0:12:52.310,0:12:56.459
これは、多くの、多くの研究者が協力して取り組んだ結果です。

0:12:56.459,0:13:02.040
このプロジェクトにはグループ全体が関わっていて、それがこの非常に重要な

0:13:02.040,0:13:03.139
本につながったのです。

0:13:03.139,0:13:09.069
そして、私にとって興味深いのは、このコースを受講した後に、

0:13:09.069,0:13:15.430
この写真を見ていただければ、私たちがまさにこのようなことをしていることがわかると思います。

0:13:15.430,0:13:21.380
私たちが学んでいることは、これらの8つのことをどのようにするかということです。

0:13:21.380,0:13:25.420
環境が含まれているのは興味深いことですが、これはデータサイエンティストが

0:13:25.420,0:13:28.329
無視することが多いからです。

0:13:28.329,0:13:31.800
モデルを構築し、それを訓練し、何かを学習しました。

0:13:31.800,0:13:33.459
それがどのようなコンテキストで動作するのか？

0:13:33.459,0:13:40.040
それについては、次のレッスンでも度々お話しします。

0:13:40.040,0:13:47.709
そして80年代に、これがリリースされた後、人々は第二層のニューロンを構築し始めました。

0:13:47.709,0:13:51.660
ミンスキーの問題を回避するためです。

0:13:51.660,0:13:59.860
And in fact, it was shown, that it was mathematically
provable, that by adding that one extra layer

0:13:59.860,0:14:07.790
of neurons, it was enough to allow any mathematical
model to be approximated to any level of accuracy,

0:14:07.790,0:14:10.160
with these neural networks.

0:14:10.160,0:14:13.690
And so that was like the exact opposite of
the Minsky thing.

0:14:13.690,0:14:17.440
That was like: “Hey there's nothing we can't
do.

0:14:17.440,0:14:19.649
Provably there's nothing we can't do.”

0:14:19.649,0:14:23.540
And so that was kind of when I started getting
involved in neural networks.

0:14:23.540,0:14:25.190
So I was - a little bit later.

0:14:25.190,0:14:28.560
I guess I was getting involved in the early
90s.

0:14:28.560,0:14:30.779
And they were very widely used in industry.

0:14:30.779,0:14:34.970
I was using them for very boring things like
targeted marketing for retail banks.

0:14:34.970,0:14:40.319
They tended to be big companies with lots
of money that were using them.

0:14:40.319,0:14:46.389
And it certainly though was true that often
the networks were too big or slow to be useful.

0:14:46.389,0:14:51.870
They were certainly useful for some things,
but they - you know they never felt to me

0:14:51.870,0:14:55.820
like they were living up to the promise for
some reason.

0:14:55.820,0:15:02.070
Now what I didn't know, and nobody I personally
met knew was that actually there were researchers

0:15:02.070,0:15:08.510
that had shown 30 years ago that to get practical
good performance, you need more layers of

0:15:08.510,0:15:09.510
neurons.

0:15:09.510,0:15:14.430
Even though mathematically, theoretically,
you can get as accurate as you want with just

0:15:14.430,0:15:16.019
one extra layer.

0:15:16.019,0:15:20.850
To do it with good performance, you need more
layers.

0:15:20.850,0:15:26.100
So when you add more layers to a neural network
you get deep learning.

0:15:26.100,0:15:29.470
So deep doesn't mean anything like mystical.

0:15:29.470,0:15:32.139
It just means more layers.

0:15:32.139,0:15:35.800
More layers than just adding the one extra
one.

0:15:35.800,0:15:39.460
So thanks to that, neural nets are now living
up to their potential.

0:15:39.460,0:15:42.680
As we saw in that like what's deep learning
good at thing.

0:15:42.680,0:15:46.360
So we could now say that Rosenblatt was right.

0:15:46.360,0:15:52.600
We have a machine that's capable of perceiving,
recognising and identifying its surroundings

0:15:52.600,0:15:54.720
without any human training or control.

0:15:54.720,0:15:56.360
That is - That's definitely true.

0:15:56.360,0:16:00.420
I don't think there's anything controversial
about that statement based on the current

0:16:00.420,0:16:01.470
technology.

0:16:01.470,0:16:04.939
So we're gonna be learning how to do that.

0:16:04.939,0:16:09.290
We're gonna be learning how to do that in
exactly the opposite way, of probably all

0:16:09.290,0:16:13.770
of the other math and technical education
you've had.

0:16:13.770,0:16:24.949
We are not gonna start with a two-hour lesson
about the sigmoid function or a study of linear

0:16:24.949,0:16:29.750
algebra or a refresher course on calculus.

0:16:29.750,0:16:37.709
And the reason for that, is that people who
study how to teach and learn have found that

0:16:37.709,0:16:41.639
is not the right way to do it for most people.

0:16:41.639,0:16:50.019
For most people - So we work a lot based on
the work of Professor David Perkins from Harvard

0:16:50.019,0:16:56.740
and others who work at similar things, who
talk about this idea of playing the whole

0:16:56.740,0:16:57.740
game.

0:16:57.740,0:17:01.260
And so playing the whole game is like it's
based on the sports analogy if you're gonna

0:17:01.260,0:17:03.949
teach somebody baseball.

0:17:03.949,0:17:10.791
You don't take them out into a classroom and
start teaching them about the physics of a

0:17:10.791,0:17:20.320
parabola, and how to stitch a ball, and a
three-part history of 100 years of baseball

0:17:20.320,0:17:24.290
politics, and then 10 years later, you let
them watch a game.

0:17:24.290,0:17:27.050
And then 20 years later, you let them play
a game.

0:17:27.050,0:17:31.930
Which is kind of like how math education is
being done, right?

0:17:31.930,0:17:37.180
Instead with baseball, step one is to say,
hey, let's go and watch some baseball.

0:17:37.180,0:17:38.180
What do you think?

0:17:38.180,0:17:39.180
That was fun, right?

0:17:39.180,0:17:42.060
See that guy there...he took a run there…before
the other guy throws a ball over there...hey,

0:17:42.060,0:17:44.080
you want to try having a hit?

0:17:44.080,0:17:47.380
Okay, so you're going to hit the ball, and
then I have to try to catch it, then he has

0:17:47.380,0:17:52.940
to run,run,run over there...and so from step
one, you are playing the whole game.

0:17:52.940,0:17:58.920
And just to add to that, when people start,
they often may not have a full team, or be

0:17:58.920,0:18:03.620
playing the full nine innings, but they still
have a sense of what the game is, a kind of

0:18:03.620,0:18:05.390
a big picture idea.

0:18:05.390,0:18:12.510
So, there is lots and lots of reasons that
this helps most human beings, (though) not

0:18:12.510,0:18:14.050
everybody, right?

0:18:14.050,0:18:19.430
There's a small percentage of people who like
to build things up from the foundations and

0:18:19.430,0:18:24.270
the principles, and not surprisingly, they
are massively overrepresented in a university

0:18:24.270,0:18:28.510
setting, because the people who get to be
academics are the people who thrive with,

0:18:28.510,0:18:33.350
(according) to me, the upside down way of
how things are taught.

0:18:33.350,0:18:40.450
But outside of universities most people learn
best in this top-down way, where you start

0:18:40.450,0:18:42.390
with the full context.

0:18:42.390,0:18:47.290
So step number two in the seven principles,
and I'm only going to mention the first three,

0:18:47.290,0:18:49.620
is to make the game worth playing.

0:18:49.620,0:18:53.590
Which is like, if you're playing baseball,
you have a competition.

0:18:53.590,0:19:00.140
You know, you score, you try and win, you
bring together teams from around the community

0:19:00.140,0:19:02.350
and you have people try to beat each other.

0:19:02.350,0:19:08.640
And you have leaderboards, like who's got
the highest number of runs or whatever.

0:19:08.640,0:19:14.800
So this is all about making sure that the
thing you're doing, you're doing it properly.

0:19:14.800,0:19:23.000
You're making it the whole thing, you're providing
the context and the interest.

0:19:23.000,0:19:30.490
So, for the fastai approach to learning deep
learning, what this means is that today we're

0:19:30.490,0:19:33.200
going to train models end to end.

0:19:33.200,0:19:38.350
We're going to actually train models, and
they won't just be crappy models.

0:19:38.350,0:19:45.070
They will be state-of-the-art world-class
models from today, and we can try to have

0:19:45.070,0:19:50.910
you build your own state-of-the-art world-class
models from either today or next lesson, depending

0:19:50.910,0:19:52.810
on how things go.

0:19:52.810,0:19:59.200
Then, number three in the seven principles
from Harvard is, work on the hard parts.

0:19:59.200,0:20:10.050
Which is kind of like this idea of practice,
deliberate practice.

0:20:10.050,0:20:19.490
Work on the hard parts means that you don't
just swing a bat at a ball every time, you

0:20:19.490,0:20:22.340
know, you go out and just muck around.

0:20:22.340,0:20:27.460
You train properly, you find the bit that
you are the least good at, you figure out

0:20:27.460,0:20:31.340
where the problems are, you work damn hard
at it.

0:20:31.340,0:20:39.530
So, in the deep learning context, that means
that we do not dumb things down.

0:20:39.530,0:20:40.530
Right?

0:20:40.530,0:20:45.210
By the end of the course, you will have done
the calculus.

0:20:45.210,0:20:47.400
You will have done the linear algebra.

0:20:47.400,0:20:54.380
You will have done the software engineering
of the code, right?

0:20:54.380,0:21:04.290
You will be practicing these things which
are hard, so it requires tenacity and commitment.

0:21:04.290,0:21:11.290
But hopefully, you'll understand why it matters
because before you start practicing something

0:21:11.290,0:21:14.470
you'll know why you need that thing because
you'll be using it.

0:21:14.470,0:21:19.450
Like to make your model better, you'll have
to understand that concept first.

0:21:19.450,0:21:24.490
So for those of you used to a traditional
university environment, this is gonna feel

0:21:24.490,0:21:31.190
pretty weird and a lot of people say: “that
they regret (you know after a year of studying

0:21:31.190,0:21:37.560
fastai) that they spent too much time studying
theory, and not enough time training models

0:21:37.560,0:21:39.500
and writing code.

0:21:39.500,0:21:43.250
That's the kind of like, the number one piece
of feedback we get from people who say, “I

0:21:43.250,0:21:44.570
wish I've done things differently.”

0:21:44.570,0:21:45.790
It's that.

0:21:45.790,0:21:53.120
So please try to, as best as you can, since
you're here, follow along with this approach.

0:21:53.120,0:21:59.400
We are gonna be using a software stack - Sorry
Rachel.

0:21:59.400,0:22:00.400
Yes?

0:22:00.400,0:22:02.510
I just need to say one more thing about the
approach.

0:22:02.510,0:22:07.390
I think since, so many of us spent so many
years with the traditional educational approach

0:22:07.390,0:22:12.030
of bottom-up, that this can feel very uncomfortable
at first.

0:22:12.030,0:22:16.620
I still feel uncomfortable with it sometimes,
even though I'm committed to the idea.

0:22:16.620,0:22:21.850
And that, some of it is also having to catch
yourself and being okay with not knowing the

0:22:21.850,0:22:22.850
details.

0:22:22.850,0:22:28.190
Which I think can feel very unfamiliar, or
even wrong when you're kind of new to that.

0:22:28.190,0:22:31.930
Of like: “Oh wait, I'm using something and
I don't understand every underlying detail.”

0:22:31.930,0:22:36.370
But you kind of have to trust that we're gonna
get to those details later.

0:22:36.370,0:22:39.560
So I can't empathise because I did not spend
lots of time doing that.

0:22:39.560,0:22:44.050
But I will tell you this - teaching this way
is very, very, very hard.

0:22:44.050,0:22:49.430
And I very often find myself jumping back
into a foundations first approach.

0:22:49.430,0:22:51.810
Because it's just so easy to be like: “Oh
you need to know this.

0:22:51.810,0:22:52.810
You need to know this.

0:22:52.810,0:22:53.810
You need to do this.

0:22:53.810,0:22:55.140
And then you can know this.”

0:22:55.140,0:22:56.540
That's so much easier to teach.

0:22:56.540,0:23:01.760
So I do find this much much more challenging
to teach, but hopefully it's worth it.

0:23:01.760,0:23:06.980
We spent a long long time figuring out how
to get deep learning into this format.

0:23:06.980,0:23:11.620
But one of the things that helps us here,
is the software we have available.

0:23:11.620,0:23:23.010
If you haven't used Python before - it's ridiculously
flexible and expressive and easy-to-use language.

0:23:23.010,0:23:28.210
We have plenty of bits about it we don't love
but on the whole we love the overall thing.

0:23:28.210,0:23:33.790
And we think it's - Most importantly, the
vast, vast, vast majority of deep learning

0:23:33.790,0:23:38.000
practitioners and researchers are using Python.

0:23:38.000,0:23:42.680
On top of Python, there are two libraries
that most folks are using today; PyTorch and

0:23:42.680,0:23:44.140
TensorFlow.

0:23:44.140,0:23:47.550
There's been a very rapid change here.

0:23:47.550,0:23:51.090
TensorFlow was what we were teaching until
a couple of years ago.

0:23:51.090,0:23:54.970
It's what everyone was using until a couple
of years ago.

0:23:54.970,0:24:00.370
It got super bogged down, basically TensorFlow
got super bogged down.

0:24:00.370,0:24:05.930
This other software called PyTorch came along
that was much easier to use and much more

0:24:05.930,0:24:15.040
useful for researchers and within the last
12 months, the percentage of papers at major

0:24:15.040,0:24:21.290
conferences that uses PyTorch has gone from
20% to 80% and vice versa, those that use

0:24:21.290,0:24:24.960
TensorFlow have gone on from 80% to 20%.

0:24:24.960,0:24:29.030
So basically all the folks that are actually
building the technology were all using, are

0:24:29.030,0:24:35.340
now using, PyTorch and you know industry moves
a bit more slowly but in the next year or

0:24:35.340,0:24:38.900
two you will probably see a similar thing
in industry.

0:24:38.900,0:24:45.180
Now, the thing about PyTorch is it's super
super flexible and really is designed for

0:24:45.180,0:24:52.570
flexibility and developer friendliness, certainly
not designed for beginner friendliness and

0:24:52.570,0:24:57.950
it's not designed for what we say, it doesn't
have higher level API's, by which I mean there

0:24:57.950,0:25:05.630
isn't really things to make it easy to build
stuff quickly using PyTorch.

0:25:05.630,0:25:13.700
So to deal with that issue, we have a library
called fastai that sits on top of PyTorch.

0:25:13.700,0:25:20.330
Fastai is the most popular higher level API
for PyTorch.

0:25:20.330,0:25:27.520
It is, because our courses are so popular,
some people are under the mistaken impression

0:25:27.520,0:25:34.260
that fastai is designed for beginners or for
teaching.

0:25:34.260,0:25:43.840
It is designed for beginners and teaching,
as well as practitioners in industry and researchers.

0:25:43.840,0:25:50.290
The way we do this makes sure that it's, that
it's the best API for all of those people

0:25:50.290,0:25:59.340
as we use something called a layered API and
so there's a peer-reviewed paper that Sylvain

0:25:59.340,0:26:04.600
and I wrote that described how we did that
and for those of you that are software engineers,

0:26:04.600,0:26:08.130
it will not be at all unusual or surprising.

0:26:08.130,0:26:12.590
It's just totally standard software engineering
practices, but they are practices that were

0:26:12.590,0:26:17.030
not followed in any deep learning library
we had seen.

0:26:17.030,0:26:24.500
Just basically lots of re-factoring and decoupling
and so by using that approach, it's allowed

0:26:24.500,0:26:32.410
us to build something which you can do super
low-level research, you can do state-of-the-art

0:26:32.410,0:26:43.850
production models and you can do kind of super
easy, beginner, but beginner world-class models.

0:26:43.850,0:26:47.220
So that's the basic software stack, there's
other pieces of software we will be learning

0:26:47.220,0:26:49.940
about along the way.

0:26:49.940,0:26:54.570
But the main thing I think to mention here
is it actually doesn't matter.

0:26:54.570,0:27:01.300
If you learn this software stack and then
at work you need to use TensorFlow and Keras,

0:27:01.300,0:27:06.380
you will be able to switch in less than a
week.

0:27:06.380,0:27:13.070
Lots and lots of students have done that,
it's never been a problem.

0:27:13.070,0:27:20.700
The important thing is to learn the concepts
and so we're going to focus on those concepts

0:27:20.700,0:27:27.870
and by using an API which minimizes the amount
of boilerplate you have to use, it means you

0:27:27.870,0:27:29.730
can focus on the bits that are important.

0:27:29.730,0:27:38.150
The actual lines of code will correspond much
more to the actual concepts you are implementing.

0:27:38.150,0:27:41.450
You are going to need a GPU machine.

0:27:41.450,0:27:49.420
A GPU is a Graphics Processing Unit, and specifically,
you need an Nvidia GPU.

0:27:49.420,0:27:55.520
Other brands of GPU just aren't well supported
by any Deep Learning libraries.

0:27:55.520,0:27:56.970
Please don't buy one.

0:27:56.970,0:28:00.130
If you already have one you probably shouldn't
use it.

0:28:00.130,0:28:05.400
Instead you should use one of the platforms
that we have already got set up for you.

0:28:05.400,0:28:10.410
It's just a huge distraction to be spending
your time doing, like, system administration

0:28:10.410,0:28:16.330
on a GPU machine and installing drivers and
blah blah blah.

0:28:16.330,0:28:18.000
And run it on Linux.

0:28:18.000,0:28:19.000
Please.

0:28:19.000,0:28:22.260
That's what everybody's doing, not just us,
everybody's running it on Linux.

0:28:22.260,0:28:23.370
Make life easy for yourself.

0:28:23.370,0:28:28.200
It's hard enough to learn Deep Learning without
having to do it in a way that you are learning,

0:28:28.200,0:28:31.550
you know, all kinds of arcane hardware support
issues.

0:28:31.550,0:28:43.480
There's a lot of free options available and
so, please, please use them.

0:28:43.480,0:28:48.280
If you're using an option that is not free
don't forget to shut down your instance.

0:28:48.280,0:28:51.730
So what's gonna be happening is you gonna
be spinning up a server that lives somewhere

0:28:51.730,0:28:57.260
else in the world, and you're gonna be connecting
to it from your computer and training and

0:28:57.260,0:29:01.500
running and building models.

0:29:01.500,0:29:05.980
Just because you close your browser window
doesn't mean your server stops running on

0:29:05.980,0:29:06.980
the whole.

0:29:06.980,0:29:07.980
Right?

0:29:07.980,0:29:11.330
So don't forget to shut it down because otherwise
you're paying for it.

0:29:11.330,0:29:16.120
Colab, is a great system which is free.

0:29:16.120,0:29:18.650
There's also a paid subscription version of
it.

0:29:18.650,0:29:21.200
Be careful with Colab.

0:29:21.200,0:29:26.590
Most of the other systems we recommend save
your work for you automatically and you can

0:29:26.590,0:29:28.460
come back to it at any time.

0:29:28.460,0:29:29.460
Colab doesn't.

0:29:29.460,0:29:37.110
So be sure to check out the Colab platform
thread on the forums, to learn about that.

0:29:37.110,0:29:44.020
So, I mention the forums...

0:29:44.020,0:29:51.970
The forums are really, really important because
that is where all of the discussion and set

0:29:51.970,0:29:54.030
up and everything happens.

0:29:54.030,0:29:56.240
So for example if you want help with setup
here.

0:29:56.240,0:30:03.820
You know there is a setup help thread and
you can find out, you know, how to best set

0:30:03.820,0:30:09.150
up Colab, and you can see discussions about
it and you can ask questions, and please remember

0:30:09.150,0:30:12.310
to search before you ask your question, right?

0:30:12.310,0:30:18.620
Because it's probably been asked before, unless
you're one of the very, very earliest people

0:30:18.620,0:30:22.530
who are doing the course.

0:30:22.530,0:30:24.820
So, once you…

0:30:24.820,0:30:31.570
So, step one is to get your server set up
by just following the instructions from the

0:30:31.570,0:30:33.620
forums or from the course website.

0:30:33.620,0:30:39.880
And the course website will have lots of step-by-step
instructions for each platform.

0:30:39.880,0:30:44.680
They will vary in price, they will vary in
speed, they will vary in availability, and

0:30:44.680,0:30:46.390
so forth.

0:30:46.390,0:30:48.390
Once you are finished following those instructions

0:30:48.390,0:30:57.790
The last step of those instructions will end
up showing you something like this: a course

0:30:57.790,0:31:01.290
v4 folder, so a version four of our course.

0:31:01.290,0:31:04.820
By the time you see this video, this is likely
to have more stuff in it, but it will have

0:31:04.820,0:31:07.670
an NB's standing for notebooks folder.

0:31:07.670,0:31:15.260
So you can click on that, and that will show
you all of the notebooks for the course.

0:31:15.260,0:31:21.060
What I want you to do is scroll bottom and
find the one called app Jupyter.

0:31:21.060,0:31:27.760
Click on that, and this is where you can start
learning about Jupyter notebook.

0:31:27.760,0:31:30.220
What's Jupyter Notebook?

0:31:30.220,0:31:39.630
Jupyter Notebook is something where you can
start typing things, and press Shift-Enter,

0:31:39.630,0:31:41.250
and it will give you an answer.

0:31:41.250,0:31:47.440
And so the thing you're typing is python code,
and the thing that comes out is a result of

0:31:47.440,0:31:48.780
that code.

0:31:48.780,0:31:52.490
And so you can put in anything in python.

0:31:52.490,0:31:56.620
X equals three times four.

0:31:56.620,0:32:05.240
X plus one, and as you can see, it displays
a result anytime there's a result to display.

0:32:05.240,0:32:10.290
So for those of you that have done a bit of
coding before, you will recognise this as

0:32:10.290,0:32:11.490
a REPL.

0:32:11.490,0:32:16.370
R-E-P-L, read, evaluate, print, loop.

0:32:16.370,0:32:18.940
Most languages have some kind of REPL.

0:32:18.940,0:32:29.320
The Jupyter notebook REPL is particularly
interesting, because it has things like headings,

0:32:29.320,0:32:34.850
graphical outputs, interactive multimedia.

0:32:34.850,0:32:37.680
It's a really astonishing piece of software.

0:32:37.680,0:32:39.850
It's won some really big awards.

0:32:39.850,0:32:48.200
I would have thought the most widely used
REPL, outside of shells like bash.

0:32:48.200,0:32:50.280
It's a very powerful system.

0:32:50.280,0:32:51.330
We love it.

0:32:51.330,0:32:55.940
We've written our whole book in it, we've
written the entire FASTAI library with it,

0:32:55.940,0:32:58.970
we do all our teaching with it.

0:32:58.970,0:33:06.780
It's extremely unfamiliar to people who have
done most of their work in IDE.

0:33:06.780,0:33:11.070
You should expect it to feel as awkward as
perhaps the first time you moved from a GUI

0:33:11.070,0:33:13.200
to a command line.

0:33:13.200,0:33:14.200
It's different.

0:33:14.200,0:33:22.080
So if you're not familiar with REPL-based
systems, it's gonna feel super weird.

0:33:22.080,0:33:25.170
But stick with it, because it really is great.

0:33:25.170,0:33:31.980
The kind of model going on here is that, this
webpage I'm looking at, is letting me type

0:33:31.980,0:33:37.460
in things for a server to do, and show me
the results of computations a server is doing.

0:33:37.460,0:33:40.170
So the server is off somewhere else.

0:33:40.170,0:33:42.650
It's not running on my computer right?

0:33:42.650,0:33:45.810
The only thing running on the computer is
this webpage.

0:33:45.810,0:33:53.360
But as I do things, so for example if I say
X equals X times three.

0:33:53.360,0:33:55.930
This is updating the servers state.

0:33:55.930,0:33:56.950
There's this state.

0:33:56.950,0:34:02.530
It's like what's currently the value of X
and so I can find out, now X is something

0:34:02.530,0:34:03.530
different.

0:34:03.530,0:34:09.669
So you can see, when I did this line here,
it didn't change the earlier X plus one, right?

0:34:09.669,0:34:14.730
So that means that when you look at a Jupyter
notebook, it's not showing you the current

0:34:14.730,0:34:16.559
state of your server.

0:34:16.559,0:34:21.679
It's just showing you what that state was,
at the time that you printed that thing out.

0:34:21.679,0:34:24.889
It's just like if you use a shell like bash.

0:34:24.889,0:34:26.780
And you type “ls”.

0:34:26.780,0:34:28.629
And then you delete a file.

0:34:28.629,0:34:31.990
That earlier “ls” you printed doesn't
go back and change.

0:34:31.990,0:34:35.559
That's kind of how REPLs generally work.

0:34:35.559,0:34:38.679
Including this one.

0:34:38.679,0:34:43.280
Jupyter notebook has two modes.

0:34:43.280,0:34:48.880
One is edit mode, which is when I click on
a cell and I get a flashing cursor and I can

0:34:48.880,0:34:52.190
move left and right and type.

0:34:52.190,0:34:53.389
Right?

0:34:53.389,0:34:55.740
There's not very many keyboard shortcuts to
this mode.

0:34:55.740,0:35:01.609
One useful one is “control” or “command”
+ “/”. Which will comment and uncomment.

0:35:01.609,0:35:07.509
The main one to know is “shift” + “enter”
to actually run the cell.

0:35:07.509,0:35:09.950
At that point there is no flashing cursor
anymore.

0:35:09.950,0:35:12.319
And that means that I'm now in command mode.

0:35:12.319,0:35:13.640
Not edit mode.

0:35:13.640,0:35:17.460
So as I go up and down, I'm selecting different
cells.

0:35:17.460,0:35:23.480
So in command mode as we move around, we're
now selecting cells.

0:35:23.480,0:35:26.829
And there are now lots of keyboard shortcuts
you can use.

0:35:26.829,0:35:30.600
So if you hit “H” you can get a list of
them.

0:35:30.600,0:35:36.150
That, for example - And you'll see that they're
not on the whole, like “control” or “command”

0:35:36.150,0:35:38.049
with something they're just the letter on
its own.

0:35:38.049,0:35:41.799
So if you use like Vim, you'll be more familiar
with this idea.

0:35:41.799,0:35:45.680
So for example if I hit “C” to copy and
“V” to paste.

0:35:45.680,0:35:47.440
Then it copies the cell.

0:35:47.440,0:35:50.769
Or “X” to cut it.

0:35:50.769,0:35:55.150
“A” to add a new cell above.

0:35:55.150,0:35:58.780
And then I can press the various number keys,
to create a heading.

0:35:58.780,0:36:01.890
So number two will create a heading level
II.

0:36:01.890,0:36:08.319
And as you can see, I can actually type formatted
text not just code.

0:36:08.319,0:36:15.569
The formatted text I type is in Markdown.

0:36:15.569,0:36:22.990
Like so.

0:36:22.990,0:36:24.369
My numbered one work.

0:36:24.369,0:36:26.800
There you go.

0:36:26.800,0:36:28.880
So that's in Markdown.

0:36:28.880,0:36:34.950
If you haven't used Markdown before, it's
a super super useful way to write formatted

0:36:34.950,0:36:35.950
text.

0:36:35.950,0:36:38.359
That is used very, very, very widely.

0:36:38.359,0:36:41.760
So learn it because it's super handy.

0:36:41.760,0:36:46.390
And you need it for Jupiter.

0:36:46.390,0:36:51.930
So when you look at our book notebooks.

0:36:51.930,0:36:57.839
For example, you can see an example of all
the kinds of formatting and code and stuff

0:36:57.839,0:36:58.839
here.

0:36:58.839,0:37:05.240
So you should go ahead and go through the
“app_jupyter”.

0:37:05.240,0:37:08.869
And you can see here how you can create plots
for example.

0:37:08.869,0:37:10.900
And create lists of things.

0:37:10.900,0:37:12.869
And import libraries.

0:37:12.869,0:37:18.430
And display pictures and so forth.

0:37:18.430,0:37:25.740
If you wanna create a new notebook, you can
just go “New” “Python 3” and that

0:37:25.740,0:37:29.940
creates a new notebook.

0:37:29.940,0:37:35.450
Which by default is just called “Untitled”
so you can then rename it to give it whatever

0:37:35.450,0:37:38.460
name you like.

0:37:38.460,0:37:45.480
And so then you'll now see that, in the list
here, “newname”.

0:37:45.480,0:37:50.269
The other thing to know about Jupiter is that
it's a nice easy way to jump into a terminal

0:37:50.269,0:37:51.450
if you know how to use a terminal.

0:37:51.450,0:37:54.509
You certainly don't have to for this course
at least for the first bit.

0:37:54.509,0:38:08.269
If I go to a new terminal, You can see here
I have a terminal.

0:38:08.269,0:38:19.140
One thing to note is for the notebooks are
attached to a Github repository.

0:38:19.140,0:38:21.950
If you haven't used Github before that's fine.

0:38:21.950,0:38:27.290
but basically they're attached to a server
where from time to time we will update the

0:38:27.290,0:38:29.480
notebooks on it.

0:38:29.480,0:38:33.329
And we will see you'll see on the course website,
in the forum we tell you how to make sure

0:38:33.329,0:38:35.890
you have the most recent versions.

0:38:35.890,0:38:40.640
When you grab our most recent version you
don't want to conflict with or overwrite your

0:38:40.640,0:38:41.640
changes.

0:38:41.640,0:38:50.329
So as you start experimenting it's not a bad
idea to like select a notebook and click duplicate

0:38:50.329,0:38:52.500
and then start doing your work in the copy.

0:38:52.500,0:38:59.099
And that way when you get an update of our
latest course materials, it's not gonna interfere

0:38:59.099,0:39:06.089
with the experiments you've been running.

0:39:06.089,0:39:09.490
So there are two important repositories to
know about.

0:39:09.490,0:39:20.089
One is the fast book repository which we saw
earlier, which is kind of the full book with

0:39:20.089,0:39:26.099
all the outputs and pros and everything.

0:39:26.099,0:39:30.390
And then the other one is the course V4 repository.

0:39:30.390,0:39:34.690
And here is the exact same notebook from the
course V4 repository.

0:39:34.690,0:39:42.130
And for this one we remove all of the pros
and all of the pictures and all of the outputs

0:39:42.130,0:39:46.210
and just leave behind the headings and the
code.

0:39:46.210,0:39:51.029
In this case you can see some outputs because
I just ran that code, most of it.

0:39:51.029,0:39:53.410
There won't be any.

0:39:53.410,0:39:56.300
No, No, I guess we have left outputs.

0:39:56.300,0:39:58.009
I'm not sure to keep that or not.

0:39:58.009,0:40:01.849
So you may or may not see the outputs.

0:40:01.849,0:40:04.259
So the idea with this is.

0:40:04.259,0:40:10.480
This is properly the version that you want
to be experimenting with.

0:40:10.480,0:40:15.170
Because it kind of forces you to think about
like what's going on as you do each step,

0:40:15.170,0:40:18.799
rather than just reading it and running it
without thinking.

0:40:18.799,0:40:24.059
We kind of want you to do it in a small bare
environment in which you thinking about like

0:40:24.059,0:40:28.859
what did the book say why was this happening
and if you forget anything then you kind of

0:40:28.859,0:40:31.321
go back to the book.

0:40:31.321,0:40:36.910
The other thing to mention is both the course
V4 version and the fast book version at the

0:40:36.910,0:40:42.000
end have a questionnaire.

0:40:42.000,0:40:46.529
And a quite a few folks have told us you know
that in amongst the reviewers and stuff that

0:40:46.529,0:40:49.990
they actually read the questionnaire first.

0:40:49.990,0:40:57.869
We spent many, many weeks writing the questionnaires,
Sylvain and I.

0:40:57.869,0:41:04.380
And the reason for that is because we try
to think about like what do we want you to

0:41:04.380,0:41:07.680
take away from each notebook.

0:41:07.680,0:41:10.029
So you kind of read the questionnaire first.

0:41:10.029,0:41:12.150
You can find out what are the things we think
are important.

0:41:12.150,0:41:14.940
What are the things you should know before
you move on.

0:41:14.940,0:41:18.859
So rather than having like a summary section
at the end saying at the end of this you should

0:41:18.859,0:41:24.920
know, blah blah blah, we instead have a questionnaire
to do the same thing, so please make sure

0:41:24.920,0:41:27.730
you do the questionnaire before you move onto
the next chapter.

0:41:27.730,0:41:31.600
You don't have to get everything right, and
most of the time answering the questions is

0:41:31.600,0:41:37.999
as simple as going back to that part of the
notebook and reading the prose, but if you've

0:41:37.999,0:41:43.289
missed something, like do go back and read
it because these are the things we are assuming

0:41:43.289,0:41:44.960
you know.

0:41:44.960,0:41:50.420
So if you don't know these things before you
move on, it could get frustrating.

0:41:50.420,0:41:57.499
Having said that, if you get stuck after trying
a couple of times, do move onto the next chapter,

0:41:57.499,0:42:00.809
do two or three more chapters and then come
back.

0:42:00.809,0:42:04.480
maybe by the time you've done a couple more
chapters, you know, you will get some more

0:42:04.480,0:42:05.480
perspective.

0:42:05.480,0:42:13.099
We try to re-explain things multiple times
in different ways, so it's okay if you tried

0:42:13.099,0:42:17.329
and you get stuck, then you can try moving
on.

0:42:17.329,0:42:26.410
Alright, so, let's try running the first part
of the notebook.

0:42:26.410,0:42:37.490
So here we are in 01 intro, so this is chapter
1 and here is our first cell.

0:42:37.490,0:42:45.481
So I click on the cell and by default, actually,
there will be a header in the toolbar as you

0:42:45.481,0:42:46.481
can see.

0:42:46.481,0:42:47.481
You can turn them on or off.

0:42:47.481,0:42:53.640
I always leave them off myself and so to run
this cell, you can either click on the play,

0:42:53.640,0:42:56.940
the run button or as I mentioned, you can
hit shift enter.

0:42:56.940,0:43:03.349
So for this one this i'll just click and as
you can see this star appears, so this says

0:43:03.349,0:43:07.880
I'm running and now you can see this progress
bar popping up and that is going to take a

0:43:07.880,0:43:15.680
few seconds and so as it runs to print out
some results.

0:43:15.680,0:43:20.740
Don't expect to get exactly the same results
as us, there is some randomness involved in

0:43:20.740,0:43:23.779
training a model, and that's okay.

0:43:23.779,0:43:26.530
Don't expect to get exactly the same time
as us.

0:43:26.530,0:43:32.510
If this first cell takes more than five minutes
unless you have a really old GPU that is probably

0:43:32.510,0:43:33.510
a bad sign.

0:43:33.510,0:43:38.609
You might want to hop on the forums and figure
out what's going wrong or maybe it only has

0:43:38.609,0:43:43.400
windows which really doesn't work very well
for this moment.

0:43:43.400,0:43:45.210
Don't worry that we don't know what all the
code does yet.

0:43:45.210,0:43:52.410
We are just making sure that we can train
a model . So here we are, it's finished running

0:43:52.410,0:43:58.079
and so as you can see, it's printed out some
information and in this case it's showing

0:43:58.079,0:44:05.269
me that there is an error rate of 0.005 at
doing something.

0:44:05.269,0:44:06.569
What is the something it's doing?

0:44:06.569,0:44:14.089
Well, what it's doing here is it's actually
grabbing a dataset, we call the pets dataset,

0:44:14.089,0:44:18.849
which is a dataset of pictures of cats and
dogs.

0:44:18.849,0:44:25.829
And it's trying to figure out; which ones
are cats and which ones are dogs.

0:44:25.829,0:44:32.599
And as you can see, after about well less
than a minute, it's able to do that with a

0:44:32.599,0:44:34.809
0.5% error rate.

0:44:34.809,0:44:37.039
So it can do it pretty much perfectly.

0:44:37.039,0:44:39.509
So we've trained our first model.

0:44:39.509,0:44:40.539
We have no idea how.

0:44:40.539,0:44:41.799
We don't know what we were doing.

0:44:41.799,0:44:44.259
But we have indeed trained our model.

0:44:44.259,0:44:46.559
So that's a good start.

0:44:46.559,0:44:51.309
And as you can see, we can train models pretty
quickly on a single computer.

0:44:51.309,0:44:55.089
Which you know - Many of which you can get
for free.

0:44:55.089,0:45:00.869
One more thing to mention is, if you have
a Mac - doesn't matter whether you have Windows

0:45:00.869,0:45:05.069
or Mac or Linux in terms of what's running
in the browser.

0:45:05.069,0:45:11.470
But if you have a Mac, please don't try to
use that GPU.

0:45:11.470,0:45:16.150
Mac's actually - Apple doesn't even support
Nvidia GPUs anymore.

0:45:16.150,0:45:19.470
So that's really not gonna be a great option.

0:45:19.470,0:45:20.869
So stick with Linux.

0:45:20.869,0:45:25.010
It will make life much easier for you.

0:45:25.010,0:45:30.420
Right, actually the first thing we should
do is actually try it out.

0:45:30.420,0:45:34.750
So if - I claim we've trained a model that
can pick cats from dogs.

0:45:34.750,0:45:37.640
Let's make sure we can.

0:45:37.640,0:45:41.859
So let's - Check out this cell.

0:45:41.859,0:45:42.859
This is interesting.

0:45:42.859,0:45:43.859
Right?

0:45:43.859,0:45:47.940
We've created a widgets dot file upload object
and displayed it.

0:45:47.940,0:45:50.690
And this is actually showing us a clickable
button.

0:45:50.690,0:45:52.619
So as I mentioned this is an unusual REPL.

0:45:52.619,0:45:55.319
We can even create GUIs, in this REPL.

0:45:55.319,0:45:58.359
So if I click on this file upload.

0:45:58.359,0:46:00.170
And I can pick “cat”.

0:46:00.170,0:46:04.130
There we go.

0:46:04.130,0:46:11.230
And I can now turn that uploaded data into
an image.

0:46:11.230,0:46:14.319
There's a cat.

0:46:14.319,0:46:22.510
And now I can do predict, and it's a cat.

0:46:22.510,0:46:26.400
With a 99.96% probability.

0:46:26.400,0:46:29.910
So we can see we have just uploaded an image
that we've picked out.

0:46:29.910,0:46:30.930
So you should try this.

0:46:30.930,0:46:31.930
Right?

0:46:31.930,0:46:32.930
Grab a picture of a cat.

0:46:32.930,0:46:35.579
Find one from the Internet or go and take
a picture of one yourself.

0:46:35.579,0:46:38.910
And make sure that you get a picture of a
cat.

0:46:38.910,0:46:43.520
This is something which can recognise photos
of cats, not line drawings of cats.

0:46:43.520,0:46:46.940
And so as we'll see, in this course.

0:46:46.940,0:46:52.050
These kinds of models can only learn from
the kinds of information you give it.

0:46:52.050,0:46:57.130
And so far we've only given it, as you'll
discover, photos of cats.

0:46:57.130,0:47:06.700
Not anime cats, not drawn cats, not abstract
representations of cats but just photos.

0:47:06.700,0:47:11.470
So we're now gonna look at; what's actually
happened here?

0:47:11.470,0:47:15.930
And you'll see at the moment, I am not getting
some great information here.

0:47:15.930,0:47:26.259
If you see this, in your notebooks, you'll
have to go: file, trust notebook.

0:47:26.259,0:47:30.559
And that just tells Jupiter that it's allowed
to run the code necessary to display things,

0:47:30.559,0:47:33.509
to make sure there isn't any security problems.

0:47:33.509,0:47:35.880
And so you'll now see the outputs.

0:47:35.880,0:47:39.880
Sometimes you'll actually see some weird code
like this.

0:47:39.880,0:47:43.609
This is code that actually creates outputs.

0:47:43.609,0:47:46.349
So sometimes we hide that code.

0:47:46.349,0:47:47.800
Sometimes we show it.

0:47:47.800,0:47:51.940
So generally speaking, you can just ignore
the stuff like that and focus on what comes

0:47:51.940,0:47:52.940
out.

0:47:52.940,0:47:54.300
So I'm not gonna go through these.

0:47:54.300,0:48:00.660
Instead I'm gonna have a look at it - same
thing over here on the slides.

0:48:00.660,0:48:04.710
So what we're doing here is; we're doing machine
learning.

0:48:04.710,0:48:07.750
Deep learning is a kind of machine learning.

0:48:07.750,0:48:09.170
What is machine learning?

0:48:09.170,0:48:16.070
Machine learning is, just like regular programming,
it's a way to get computers to do something.

0:48:16.070,0:48:22.250
But in this case, it's pretty hard to understand
how you would use regular programming to recognise

0:48:22.250,0:48:24.000
dog photos from cat photos.

0:48:24.000,0:48:28.319
How do you kind of create the loops and the
variable assignments and the conditionals

0:48:28.319,0:48:31.789
to create a program that recognises dogs vs
cats in photos.

0:48:31.789,0:48:33.190
It's super hard.

0:48:33.190,0:48:34.589
Super super hard.

0:48:34.589,0:48:41.420
So hard, that until kind of the deep learning
era, nobody really had a model that was remotely

0:48:41.420,0:48:43.910
accurate at this apparently easy task.

0:48:43.910,0:48:46.970
Because we can't write down the steps necessary.

0:48:46.970,0:48:51.369
So normally, you know, we write down a function
that takes some inputs and goes through our

0:48:51.369,0:48:52.369
program.

0:48:52.369,0:48:55.569
Produces some results.

0:48:55.569,0:49:02.530
So this general idea where the program is
something that we write (the steps).

0:49:02.530,0:49:06.970
Doesn't seem to work great for things like
recognising pictures.

0:49:06.970,0:49:12.470
So back in 1949, somebody named Arthur Samuel
started trying to figure out a way to solve

0:49:12.470,0:49:16.030
problems like recognising pictures of cats
and dogs.

0:49:16.030,0:49:23.000
And in 1962, he described a way of doing this.

0:49:23.000,0:49:26.270
Well first of all he described the problem:
“Programming a computer for these kinds

0:49:26.270,0:49:31.070
of computations is at best a difficult task.

0:49:31.070,0:49:37.589
Because of the need to spell out every minute
step of the process in exasperating detail.

0:49:37.589,0:49:42.290
Computers are giant morons which all of us
coders totally recognise.”

0:49:42.290,0:49:46.769
So he said, okay, let's not tell the computer
the exact steps, but let's give it examples

0:49:46.769,0:49:50.460
of a problem to solve and figure out how to
solve it itself.

0:49:50.460,0:49:56.269
And so, by 1961 he had built a checkers program
that had beaten the Connecticut state champion,

0:49:56.269,0:50:03.450
not by telling it the steps to take to play
checkers, but instead by doing this, which

0:50:03.450,0:50:09.990
is: “arrange for an automatic means of testing
the effectiveness of a weight assignment in

0:50:09.990,0:50:15.690
terms of actual performance and a mechanism
for altering the weight assignment so as to

0:50:15.690,0:50:19.019
maximise performance.”

0:50:19.019,0:50:21.680
This sentence is the key thing.

0:50:21.680,0:50:24.440
And it's a pretty tricky sentence so you can
spend some time on it.

0:50:24.440,0:50:32.200
The basic idea is this; instead of saying
inputs to a program and then outputs.

0:50:32.200,0:50:36.430
Let's have inputs to a - let's call the program
now model.

0:50:36.430,0:50:38.140
It is the same basic idea.

0:50:38.140,0:50:40.349
Inputs to a model and results.

0:50:40.349,0:50:43.760
And then we're gonna have a second thing called
weights.

0:50:43.760,0:50:50.569
And so the basic idea is that this model is
something that creates outputs based not only

0:50:50.569,0:50:58.410
on, for example, the state of a checkers board,
but also based on some set of weights or parameters

0:50:58.410,0:51:02.320
that describe how that model is going to work.

0:51:02.320,0:51:09.039
So the idea is, if we could, like, enumerate
all the possible ways of playing checkers,

0:51:09.039,0:51:14.130
and then kind of describe each of those ways
using some set of parameters or what Samuel

0:51:14.130,0:51:15.830
called weights.

0:51:15.830,0:51:21.690
Then if we had a way of checking how effective
a current weight assignment is in terms of

0:51:21.690,0:51:27.549
actual performance, in other words, does that
particular enumeration of a strategy for playing

0:51:27.549,0:51:33.140
checkers end up winning or losing games, and
then a way to alter the weight assignment

0:51:33.140,0:51:35.599
so as to maximise the performance.

0:51:35.599,0:51:40.710
So then oh let's try increasing or decreasing
each one of those weights one at a time to

0:51:40.710,0:51:45.190
find out if there is a slightly better way
of playing checkers and then do that lots

0:51:45.190,0:51:51.950
of lots of times then eventually such a procedure
could be made entirely automatic and then

0:51:51.950,0:51:58.030
the machine so programmed would learn from
its experience so this little paragraph is,

0:51:58.030,0:52:00.200
is the thing.

0:52:00.200,0:52:08.650
This is machine learning a way of creating
programs such that they learn, rather than

0:52:08.650,0:52:11.349
programmed.

0:52:11.349,0:52:16.930
So if we had such a thing, then we would basically
now have something that looks like this: you

0:52:16.930,0:52:22.549
have inputs and weights again going into a
model, creating results, i.e. you won or you

0:52:22.549,0:52:26.769
lost, and then a measurement of performance.

0:52:26.769,0:52:30.349
So remember that was this key step and then
the second key step is a way to update the

0:52:30.349,0:52:35.609
weights based on the measured performance
and then you could look through this process

0:52:35.609,0:52:43.450
and create a) train a machine learning model
so this is the abstract idea.

0:52:43.450,0:52:49.260
So after it ran for a while, right, it's come
up with a set of weights which it's pretty

0:52:49.260,0:52:55.089
good, right, we can now forget the way it
was trained and we have something that is

0:52:55.089,0:53:02.359
just like this, right, except the word program
is now replaced with the word model.

0:53:02.359,0:53:07.239
So a trained model can be used just like any
other computer program.

0:53:07.239,0:53:13.509
So the idea is we are building a computer
program not by putting up the steps necessary

0:53:13.509,0:53:19.619
to do the task, but by training it to learn
to do the task at the end of which it's just

0:53:19.619,0:53:26.759
another program and so this is what's called
inference right is using a trained model as

0:53:26.759,0:53:37.980
a program to do a task such as playing checkers
so machine learning is training programs developed

0:53:37.980,0:53:43.309
by allowing a computer to learn from its experience
rather than through manually coding.

0:53:43.309,0:53:53.640
Ok how would you do this for image recognition,
what is that model and that set of weights

0:53:53.640,0:53:59.700
such that as we vary them it could get better
and better at recognising cats versus dogs,

0:53:59.700,0:54:02.210
I mean for checkers

0:54:02.210,0:54:06.780
It's not too hard to imagine how you could
kind of enumerate, depending on different

0:54:06.780,0:54:11.289
kinds of “how far away the opponent's piece
is from your piece,” what should you do

0:54:11.289,0:54:12.289
in that situation.

0:54:12.289,0:54:16.079
How should you weigh defensive versus aggressive
strategies, blah blah blah.

0:54:16.079,0:54:20.410
Not at all obvious how you do that for image
recognition.

0:54:20.410,0:54:29.240
So what we really want, is some function in
here which is so flexible that there is a

0:54:29.240,0:54:33.210
set of weights that could cause it to do anything.

0:54:33.210,0:54:40.059
A real--like the world's most flexible possible
function--and turns out that there is such

0:54:40.059,0:54:41.059
a thing.

0:54:41.059,0:54:44.140
It's a neural network.

0:54:44.140,0:54:50.329
So we'll be describing exactly what that mathematical
function is in the coming lessons.

0:54:50.329,0:54:56.160
To use it, it actually doesn't really matter
what the mathematical function is.

0:54:56.160,0:55:03.631
It's a function which is, we say, “parameterised”
by some set of weights by which I mean, as

0:55:03.631,0:55:12.259
I give it a different set of weights it does
a different task, and it can actually do any

0:55:12.259,0:55:17.970
possible task: something called the universal
approximation theorem tells us that mathematically

0:55:17.970,0:55:26.319
provably, this functional form can solve any
problem that is solvable to any level of accuracy.

0:55:26.319,0:55:28.589
If you just find the right set of weights.

0:55:28.589,0:55:33.210
Which is kind of restating what we described
earlier in that, like, how do we deal with

0:55:33.210,0:55:39.700
Minsky (the Marvin Minsky) problem so neural
networks are so flexible that if you could

0:55:39.700,0:55:44.609
find the right set of weights they can solve
any problem including “Is this a car or

0:55:44.609,0:55:46.289
is this dog.”

0:55:46.289,0:55:51.130
So that means you need to focus your effort
on the process of training that is finding

0:55:51.130,0:55:57.010
good weights, good weight assignments to use
Samuel's terminology.

0:55:57.010,0:55:59.770
So how do you do that?

0:55:59.770,0:56:09.239
We want a completely general way to do this--to
update the weights based on some measure of

0:56:09.239,0:56:14.200
performance, such as how good is it at recognising
cats versus dogs.

0:56:14.200,0:56:16.839
And luckily it turns out such a thing exists!

0:56:16.839,0:56:21.539
And that thing is called stochastic gradient
descent (or SGD).

0:56:21.539,0:56:26.540
Again, we'll look at exactly how it works,
we'll build it ourselves from scratch, but

0:56:26.540,0:56:28.529
for now we don't have to worry about it.

0:56:28.529,0:56:34.210
I will tell you this, though, neither SGD
nor neural nets are at all mathematically

0:56:34.210,0:56:35.210
complex.

0:56:35.210,0:56:38.829
They nearly entirely are addition and multiplication.

0:56:38.829,0:56:45.109
The trick is it just a lot of them--like billions
of them--so many more than we can intuitively

0:56:45.109,0:56:46.109
grasp.

0:56:46.109,0:56:52.940
They can do extraordinarily powerful things,
but they're not rocket science at all.

0:56:52.940,0:56:58.609
They are not complex things, and we will see
exactly how they work.

0:56:58.609,0:57:03.049
So that's the Arthur Samuel version, right?

0:57:03.049,0:57:08.580
Nowadays we don't use quite the same terminology,
but we use exactly the same idea.

0:57:08.580,0:57:12.660
So that function that sits in the middle,

0:57:12.660,0:57:14.549
we call an architecture.

0:57:14.549,0:57:20.779
An architecture is the function that we're
adjusting the weights to get it to do something.

0:57:20.779,0:57:24.190
That's the architecture, that's the functional
form of the model.

0:57:24.190,0:57:28.849
Sometimes people say model to mean architecture,
so don't let that confuse you too much.

0:57:28.849,0:57:30.559
But, really the right word is architecture.

0:57:30.559,0:57:34.619
We don't call them weights; we call them parameters.

0:57:34.619,0:57:40.410
Weights has a specific meaning- it's quite
a particular kind of parameter.

0:57:40.410,0:57:46.609
The things that come out of the model, the
architecture with the parameters, we call

0:57:46.609,0:57:49.809
them predictions.

0:57:49.809,0:57:55.660
The predictions are based on two kinds of
inputs: independent variables that's the data,

0:57:55.660,0:58:03.309
like the pictures of the cats and dogs, and
dependent variables also known as labels,

0:58:03.309,0:58:07.400
which is like the thing saying “this is
a cat”, “this is a dog”, “this is

0:58:07.400,0:58:08.400
a cat”.

0:58:08.400,0:58:09.779
So, that's your inputs.

0:58:09.779,0:58:12.769
So, the results are predictions.

0:58:12.769,0:58:18.670
The measure of performance, to use Arthur
Samuel's word, is known as the loss.

0:58:18.670,0:58:24.020
So, the loss is being calculated from the
labels on the predictions and then there's

0:58:24.020,0:58:26.720
the update back to the parameters.

0:58:26.720,0:58:33.210
Okay, so, this is the same picture as we saw,
but just putting in the words that we use

0:58:33.210,0:58:34.210
today.

0:58:34.210,0:58:40.039
So, this picture- if you forget, if I say
these are the parameters of this used for

0:58:40.039,0:58:44.220
this architecture to create a model- you can
go back and remind yourself what they mean.

0:58:44.220,0:58:45.220
What are the parameters?

0:58:45.220,0:58:46.500
What are the predictions?

0:58:46.500,0:58:47.500
What is the loss?

0:58:47.500,0:58:53.970
Okay, the loss of some function that measures
the performance of the model in such a way

0:58:53.970,0:58:56.790
that we can update the parameters.

0:58:56.790,0:59:06.170
So, it's important to note that deep learning
and machine learning are not magic, right?

0:59:06.170,0:59:13.380
The model can only be created where you have
data showing you examples of the thing that

0:59:13.380,0:59:14.869
you're trying to learn about.

0:59:14.869,0:59:20.859
It can only learn to operate on the patterns
that you've seen in the input used to train

0:59:20.859,0:59:22.030
it, right?

0:59:22.030,0:59:27.109
So, if we don't have any line drawings of
cats and dogs, then there's never going to

0:59:27.109,0:59:32.519
be an update to the parameters that makes
the architecture and so the architect and

0:59:32.519,0:59:34.420
the parameters together is the model.

0:59:34.420,0:59:39.650
So, to say the model, that makes the model
better at predicting line drawings of cats

0:59:39.650,0:59:43.799
and dogs because they just, they never received
those weight updates because they never received

0:59:43.799,0:59:46.680
those inputs.

0:59:46.680,0:59:51.239
Notice also that this learning approach only
ever creates predictions.

0:59:51.239,0:59:54.319
It doesn't tell you what to do about it.

0:59:54.319,0:59:58.019
That's going to be very important when we
think about things like a recommendation system

0:59:58.019,1:00:01.230
of like “what product do we recommend to
somebody”?

1:00:01.230,1:00:04.950
Well, I don't know- we don't do that, right?

1:00:04.950,1:00:09.759
We can predict what somebody will say about
a product we've shown them, but we're not

1:00:09.759,1:00:11.140
creating actions.

1:00:11.140,1:00:12.310
We're creating predictions.

1:00:12.310,1:00:16.619
That's a super important difference to recognize.

1:00:16.619,1:00:22.470
It's not enough just to have examples of input
data like pictures of dogs and cats.

1:00:22.470,1:00:26.309
We can't do anything without labels.

1:00:26.309,1:00:31.359
And so very often, organisations say: “we
don't have enough data”.

1:00:31.359,1:00:35.150
Most of the time they mean: “we don't have
enough labelled data”.

1:00:35.150,1:00:39.549
Because if a company is trying to do something
with deep learning, often it's because they're

1:00:39.549,1:00:43.180
trying to automate or improve something they're
already doing.

1:00:43.180,1:00:48.420
Which means by definition they have data about
that thing or a way to capture data about

1:00:48.420,1:00:49.420
that thing.

1:00:49.420,1:00:50.420
Cus they're doing it.

1:00:50.420,1:00:51.420
Right?

1:00:51.420,1:00:55.089
But often the tricky part is labelling it.

1:00:55.089,1:00:57.569
So for example in medicine.

1:00:57.569,1:01:00.789
If you're trying to build a model for radiology.

1:01:00.789,1:01:05.579
You can almost certainly get lots of medical
images about just about anything you can think

1:01:05.579,1:01:06.579
of.

1:01:06.579,1:01:11.769
But it might be very hard to label them according
to malignancy of a tumour or according to

1:01:11.769,1:01:18.480
whether or not meningioma is present or whatever,
because these kinds of labels are not necessarily

1:01:18.480,1:01:24.289
captured in a structured way, at least in
the US medical system.

1:01:24.289,1:01:31.700
So that's an important distinction that really
impacts your kind of strategy.

1:01:31.700,1:01:39.000
So then a model, as we saw from the PDP book,
a model operates in an environment.

1:01:39.000,1:01:40.000
Right?

1:01:40.000,1:01:44.420
You roll it out and you do something with.

1:01:44.420,1:01:49.640
And so then, this piece of that kind of PDP
framework is super important.

1:01:49.640,1:01:50.640
Right?

1:01:50.640,1:01:53.769
You have a model that's actually doing something.

1:01:53.769,1:01:59.069
For example, you've built a predictive policing
model that predicts (doesn't recommend actions)

1:01:59.069,1:02:02.460
it predicts where an arrest might be made.

1:02:02.460,1:02:06.670
This is something a lot of jurisdictions in
the US are using.

1:02:06.670,1:02:10.809
Now it's predicting that, based on data and
based on labelled data.

1:02:10.809,1:02:20.779
And in this case it's actually gonna be using
(in the US) for example data where, I think,

1:02:20.779,1:02:25.099
depending on whether you're black or white,
black people in the US, I think, get arrested

1:02:25.099,1:02:31.480
something like seven times more often for
say marijuana possession than whites.

1:02:31.480,1:02:37.579
Even though the actual underlying amount of
marijuana use is about the same in the two

1:02:37.579,1:02:38.579
populations.

1:02:38.579,1:02:42.079
So if you start with biased data and you build
a predictive policing model.

1:02:42.079,1:02:49.430
Its prediction will say: “oh you will find
somebody you can arrest here” based on some

1:02:49.430,1:02:50.430
biased data.

1:02:50.430,1:02:56.279
So then, law enforcement officers might decide
to focus their police activity on the areas

1:02:56.279,1:02:58.039
where those predictions are happening.

1:02:58.039,1:03:01.940
As a result of which they'll find more people
to arrest.

1:03:01.940,1:03:05.430
And then they'll use that, to put it back
into the model.

1:03:05.430,1:03:09.789
Which will now find: “oh there's even more
people we should be arresting in the black

1:03:09.789,1:03:12.640
neighbourhoods” and thus it continues.

1:03:12.640,1:03:17.000
So this would be an example of how a model
interacting with its environment creates something

1:03:17.000,1:03:19.460
called a positive feedback loop.

1:03:19.460,1:03:23.930
Where the more a model is used, the more biased
the data becomes, making the model even more

1:03:23.930,1:03:26.440
biased and so forth.

1:03:26.440,1:03:32.299
So one of the things to be super careful about
with machine learning is; recognising how

1:03:32.299,1:03:38.009
that model is actually being used and what
kinds of things might happen as a result of

1:03:38.009,1:03:39.009
that.

1:03:39.009,1:03:48.910
I was just going to add that this is an example
of proxies because here arrest is being used

1:03:48.910,1:03:56.210
as a proxy for crime, and I think that pretty
much in all cases, the data that you actually

1:03:56.210,1:04:00.049
have is a proxy for some value that you truly
care about.

1:04:00.049,1:04:06.109
And that difference between the proxy and
the actual value often ends up being significant.

1:04:06.109,1:04:10.770
Thanks, Rachel.

1:04:10.770,1:04:13.430
That's a really important point.

1:04:13.430,1:04:24.219
Okay, so let's finish off by looking at what's
going on with this code.

1:04:24.219,1:04:34.880
So the code we ran is, basically -- one, two,
three, four, five, six -- lines of code.

1:04:34.880,1:04:39.829
So the first line of code is an import line.

1:04:39.829,1:04:46.690
So in Python you can't use an external library
until you import from it.

1:04:46.690,1:04:53.339
Normally in place, people import just the
functions and classes that they need from

1:04:53.339,1:04:55.030
the library.

1:04:55.030,1:05:01.989
But Python does provide a convenient facility
where you can import everything from a module,

1:05:01.989,1:05:04.410
which is by putting a start there.

1:05:04.410,1:05:07.029
Most of the time, this is a bad idea.

1:05:07.029,1:05:12.479
Because, by default, the way Python works
is that if you say import star, it doesn't

1:05:12.479,1:05:16.640
only import the things that are interesting
and important in the library you're trying

1:05:16.640,1:05:18.520
to get something from.

1:05:18.520,1:05:23.369
But it also imports things from all the libraries
it used, and all the libraries they used,

1:05:23.369,1:05:27.190
and you end up kind of exploding your namespace
in horrible ways and causing all kinds of

1:05:27.190,1:05:28.760
bugs.

1:05:28.760,1:05:36.510
Because fastai is designed to be used in this
REPL environment where you want to be able

1:05:36.510,1:05:41.779
to do a lot of quick rapid prototyping, we
actually spent a lot of time figuring out

1:05:41.779,1:05:45.410
how to avoid that problem so that you can
import star safely.

1:05:45.410,1:05:49.630
So, whether you do this or not, is entirely
up to you.

1:05:49.630,1:05:56.609
But rest assured that if you import star from
a fastai library, it's actually been explicitly

1:05:56.609,1:06:01.999
designed in a way that you only get the bits
that you actually need.

1:06:01.999,1:06:05.799
One thing to mention is in the video you see
it's called “fastai2.”

1:06:05.799,1:06:09.849
That's because we're recording this video
using a prerelease version.

1:06:09.849,1:06:19.049
By the time you are watching the online, the
MOOC, version of this, the 2 will be gone.

1:06:19.049,1:06:25.609
Something else to mention is, there are, as
I speak, four main predefined applications

1:06:25.609,1:06:31.099
in fastai, being vision, text, tabular and
collaborative filtering.

1:06:31.099,1:06:35.130
We'll be learning about all of them and a
lot more.

1:06:35.130,1:06:41.989
For each one, say here's vision, you can import
from the .all, kind of meta-model, I guess

1:06:41.989,1:06:42.989
we could call it.

1:06:42.989,1:06:48.079
And that will give you all the stuff that
you need for most common vision applications.

1:06:48.079,1:06:55.779
So, if you're using a REPL system like Jupyter
notebook, it's going to give you all the stuff

1:06:55.779,1:07:01.619
right there that you need without having to
go back and figure it out.

1:07:01.619,1:07:06.559
One of the issues with this is a lot of the
python users don't.

1:07:06.559,1:07:12.450
If they look at something like untar_data,
they would figure out where it comes from

1:07:12.450,1:07:14.219
by looking at the import line.

1:07:14.219,1:07:15.970
And so if you import star, you can't do that
anymore.

1:07:15.970,1:07:19.829
The good news, in a REPL, you don't have to.

1:07:19.829,1:07:27.450
You can literally just type the symbol, press
SHIFT - ENTER and it will tell you exactly

1:07:27.450,1:07:28.670
where it came from.

1:07:28.670,1:07:29.940
As you can see.

1:07:29.940,1:07:33.510
So that's super handy.

1:07:33.510,1:07:43.859
So in this case, for example, to do the actual
building of the dataset, we called ImageDataLoaders.from_name_func.

1:07:43.859,1:07:51.170
I can actually call the special doc function
to get the documentation for that.

1:07:51.170,1:07:57.349
As you can see, it tells me exactly everything
to pass in, what all the defaults are, and

1:07:57.349,1:08:07.940
most importantly, not only what it does, but
SHOW IN DOCS pops me over to the full documentation

1:08:07.940,1:08:11.190
including an example.

1:08:11.190,1:08:17.180
Everything in the fastAI documentation has
an example and the cool thing is: the entire

1:08:17.180,1:08:20.770
documentation is written in Jupyter Notebooks.

1:08:20.770,1:08:25.540
So that means you can actually open the Jupyter
Notebook for this documentation and run the

1:08:25.540,1:08:33.280
line of code yourself and see it actually
working and look at the outputs and so forth.

1:08:33.280,1:08:36.760
Also in the documentation, you'll find that
there are a bunch of tutorials.

1:08:36.760,1:08:40.501
For example, if you look at the vision tutorial,
it will cover lots of things but one of the

1:08:40.501,1:08:44.910
things we will cover is, as you can see in
this case, pretty much the same kind of stuff

1:08:44.910,1:08:47.710
we are actually looking at in Lesson 1.

1:08:47.710,1:08:53.300
So there is a lot of documentation in fastAI
and taking advantage of it is a pretty good

1:08:53.300,1:08:54.300
idea.

1:08:54.300,1:08:59.310
It is fully searchable and as I mentioned,
perhaps most importantly, every one of these

1:08:59.310,1:09:05.050
documentation pages is also a fully interactive
Jupyter Notebook.

1:09:05.050,1:09:13.839
So, looking through more of this code, the
first line after the import is something that

1:09:13.839,1:09:14.910
uses untar_ data.

1:09:14.910,1:09:20.020
That will download a dataset, decompress it,
and put it on your computer.

1:09:20.020,1:09:22.770
If it is already downloaded, it won't download
it again.

1:09:22.770,1:09:25.710
If it is already decompressed it won't decompress
it again.

1:09:25.710,1:09:32.540
And as you can see, fastAI already has predefined
access to a number of really useful datasets.

1:09:32.540,1:09:34.180
such as this PETS dataset.

1:09:34.180,1:09:39.920
Datasets are a super important part, as you
can imagine of deep learning.

1:09:39.920,1:09:41.900
We will be seeing lots of them.

1:09:41.900,1:09:47.690
And these are created by lots of heroes (and
heroines) who basically spend months or years

1:09:47.690,1:09:51.260
collating data that we can use to build these
models.

1:09:51.260,1:10:00.230
The next step is to tell fastAI what this
data is and we will be learning a lot about

1:10:00.230,1:10:01.230
that.

1:10:01.230,1:10:05.560
But in this case, we are basically saying,
‘okay, it contains images'.

1:10:05.560,1:10:07.630
It contains images that are in this path.

1:10:07.630,1:10:14.100
So untar_data returns the path that is whereabouts
it has been decompressed to.

1:10:14.100,1:10:18.900
Or if it is already decompressed, it tells
us where it was previously decompressed to.

1:10:18.900,1:10:23.560
We have to tell it things like ‘okay, what
images are actually in that path'.

1:10:23.560,1:10:27.170
One of the really interesting ones is label_func.

1:10:27.170,1:10:33.600
How do you tell, for each file, whether it
is a cat or a dog.

1:10:33.600,1:10:37.330
And if you actually look at the ReadME for
the original dataset, it uses a slightly quirky

1:10:37.330,1:10:42.430
thing which is they said, ‘oh, anything
where the first letter of the filename is

1:10:42.430,1:10:45.000
an uppercase is a cat'.

1:10:45.000,1:10:46.430
That's what they decided.

1:10:46.430,1:10:51.180
So we just created a little function here
called is_cat that returns the first letter,

1:10:51.180,1:10:52.480
is it uppercase or not.

1:10:52.480,1:10:57.420
And we tell fastai that's how you tell if
it's a cat.

1:10:57.420,1:11:01.260
We'll come back to these two in a moment.

1:11:01.260,1:11:04.640
So the next thing, now we've told it what
the data is.

1:11:04.640,1:11:06.350
We then have to create something called a
learner.

1:11:06.350,1:11:10.180
A learner is a thing that learns, it does
the training.

1:11:10.180,1:11:12.510
So you have to tell it what data to use.

1:11:12.510,1:11:16.570
Then you have to tell it what architecture
to use.

1:11:16.570,1:11:19.810
I'll be talking a lot about this in the course.

1:11:19.810,1:11:25.460
But, basically, there's a lot of predefined
neural network architectures that have certain

1:11:25.460,1:11:26.660
pros and cons.

1:11:26.660,1:11:30.360
And for computer vision, the architecture
is called ResNet.

1:11:30.360,1:11:34.580
Just a super great starting point, and so
we're just going to use a reasonably small

1:11:34.580,1:11:35.820
one of them.

1:11:35.820,1:11:39.710
So these are all predefined and set up for
you.

1:11:39.710,1:11:43.380
And then you can tell fastai what things you
want to print out as it's training.

1:11:43.380,1:11:47.730
And in this case, we're saying “oh, tell
us the error, please, as you train”.

1:11:47.730,1:11:51.230
So then we can call this really important
method called fine_tune that we'll be learning

1:11:51.230,1:11:57.050
about in the next lesson which actually does
the training.

1:11:57.050,1:12:00.700
valid_pct does something very important.

1:12:00.700,1:12:08.160
It grabs, in this case, 20% of the data (.2
proportion), and does not use it for training

1:12:08.160,1:12:09.230
a model.

1:12:09.230,1:12:12.730
Instead, it uses it for telling you the error
rate of the model.

1:12:12.730,1:12:19.890
So, always in fastai this metric, error_rate,
will always be calculated on a part of the

1:12:19.890,1:12:22.290
data which has not been trained with.

1:12:22.290,1:12:27.040
And the idea here, and we'll talk a lot about
more about this in future lessons.

1:12:27.040,1:12:31.220
But the basic idea here is we want to make
sure that we're not overfitting.

1:12:31.220,1:12:33.540
Let me explain.

1:12:33.540,1:12:35.090
Overfitting looks like this.

1:12:35.090,1:12:38.860
Let's say you're trying to create a function
that fits all these dots, right.

1:12:38.860,1:12:44.050
A nice function would look like that, right.

1:12:44.050,1:12:47.940
But you could also fit, you can actually fit
it much more precisely with this function.

1:12:47.940,1:12:50.970
Look, this is going much closer to all the
dots than this one is.

1:12:50.970,1:12:53.240
So, this is obviously a better function.

1:12:53.240,1:13:00.010
Except, as soon as you get outside where the
dots are, especially if you go off the edges,

1:13:00.010,1:13:01.640
it's obviously doesn't make any sense.

1:13:01.640,1:13:06.060
So, this is what you'd call an overfit function.

1:13:06.060,1:13:08.570
So, overfitting happens for all kinds of reasons.

1:13:08.570,1:13:11.970
We use a model that's too big or we use not
enough data.

1:13:11.970,1:13:14.510
We'll be talking all about it, right.

1:13:14.510,1:13:22.370
But, really the craft of deep learning is
all about creating a model that has a proper

1:13:22.370,1:13:23.370
fit.

1:13:23.370,1:13:27.480
And the only way you know if a model has a
proper fit is by seeing whether it works well

1:13:27.480,1:13:31.620
on data that was not used to train it.

1:13:31.620,1:13:36.830
And so, we always set aside some of the data
to create something called a validation set.

1:13:36.830,1:13:41.270
The validation set is the data that we use
not to touch it at all when we're training

1:13:41.270,1:13:49.230
a model, but we're only using it to figure
out whether the model's actually working or

1:13:49.230,1:13:51.100
not.

1:13:51.100,1:13:57.080
One thing that Sylvain mentioned in the book,
is that one of the interesting things about

1:13:57.080,1:14:04.500
studying fastai is you learn a lot of interesting
programming practices.

1:14:04.500,1:14:11.000
And so I've been programming, I mean, since
I was a kid, so like 40 years.

1:14:11.000,1:14:18.060
And Sylvain and I both work really, really
hard to make python do a lot of work for us

1:14:18.060,1:14:22.960
and to use, you know, programming practices
which make us very productive and allow us

1:14:22.960,1:14:27.120
to come back to our code, years later and
still understand it.

1:14:27.120,1:14:34.700
And so you'll see in our code we'll often
do things that you might not have seen before.

1:14:34.700,1:14:39.260
And so we, a lot of students who have gone
through previous courses say they learned

1:14:39.260,1:14:44.100
a lot about coding and python coding and software
engineering from the course.

1:14:44.100,1:14:49.350
So, yeah check, when you see something new,
check it out and feel free to ask on the forums

1:14:49.350,1:14:53.410
if you're curious about why something was
done that way.

1:14:53.410,1:14:59.250
One thing to mention is, just like I mentioned
import star is something most Python programmers

1:14:59.250,1:15:05.890
don't do cause most libraries don't support
doing it properly.

1:15:05.890,1:15:07.130
We do a lot of things like that.

1:15:07.130,1:15:11.240
We do a lot of things where we don't follow
a traditional approach to python programming.

1:15:11.240,1:15:19.940
Because I've used so many languages over the
years, I code not in a way that's specifically

1:15:19.940,1:15:23.940
pythonic, but incorporates like ideas from
lots of other languages and lots of other

1:15:23.940,1:15:31.230
notations and heavily customised our approach
to python programming based on what works

1:15:31.230,1:15:34.000
well for data science.

1:15:34.000,1:15:40.750
That means that the code you see in fastai
is not probably, not gonna fit with, the kind

1:15:40.750,1:15:45.600
of style guides and normal approaches at your
workplace, if you use Python there.

1:15:45.600,1:15:52.440
So, obviously, you should make sure that you
fit in with your organization's programming

1:15:52.440,1:15:56.420
practices rather than following ours.

1:15:56.420,1:16:00.910
But perhaps in your own hobby work, you can
follow ours and see if you find that are interesting

1:16:00.910,1:16:05.270
and helpful, or even experiment with that
in your company if you're a manager and you

1:16:05.270,1:16:08.480
are interested in doing so.

1:16:08.480,1:16:17.001
Okay, so to finish, I'm going to show you
something pretty interesting, which is, have

1:16:17.001,1:16:27.580
a look at this code untar data, image data
loaders from name func, learner, fine tune.

1:16:27.580,1:16:33.740
Untar data, segmentation date loaders, from
label func, learner, fine tune.

1:16:33.740,1:16:39.070
Almost the same code, and this has built a
model that does something, whoa totally different!

1:16:39.070,1:16:42.520
It's something which has taken images.

1:16:42.520,1:16:45.420
This is on the left, this is the labeled data.

1:16:45.420,1:16:51.850
It's got images with color codes to tell you
whether it's a car, or a tree, or a building,

1:16:51.850,1:16:54.201
or a sky, or a line marking or a road.

1:16:54.201,1:16:59.410
And on the right is our model, and our model
has successfully figured out for each pixel,

1:16:59.410,1:17:02.960
is that a car, line marking, a road.

1:17:02.960,1:17:06.520
Now it's only done it in, under 20 seconds
right.

1:17:06.520,1:17:08.480
So it's a very small quick model.

1:17:08.480,1:17:13.060
It's made some mistakes -- like it's missing
this line marking, and some of these cars

1:17:13.060,1:17:15.710
it thinks is house, right?

1:17:15.710,1:17:21.400
But you can see so if you train this for a
few minutes, it's nearly perfect.

1:17:21.400,1:17:26.300
But you can see the basic idea is that we
can very rapidly, with almost exactly the

1:17:26.300,1:17:31.890
same code, create something not that classifies
cats and dogs but does what's called segmentation:

1:17:31.890,1:17:34.950
figures out what every pixel and image is.

1:17:34.950,1:17:36.980
Look, here's the same thing:

1:17:36.980,1:17:39.520
from import star
text loaders from folder

1:17:39.520,1:17:42.530
learner
learn fine-tune

1:17:42.530,1:17:43.830
Same basic code.

1:17:43.830,1:17:49.250
This is now something where we can give it
a sentence and it can figure out whether that

1:17:49.250,1:17:55.380
is expressing a positive or negative sentiment,
and this is actually giving a 93% accuracy

1:17:55.380,1:18:04.440
on that task in about 15 minutes on the IMDb
dataset, which contains thousands of full-length

1:18:04.440,1:18:08.960
movie reviews (in fact, 1000- to 3000-word
reviews).

1:18:08.960,1:18:13.500
This number here that we got with the same
three lines of code would have been the best

1:18:13.500,1:18:19.960
in the world for this task in a very, very,
very popular academics dataset in like 2015

1:18:19.960,1:18:21.670
I think.

1:18:21.670,1:18:31.700
So we are creating world-class models, in
our browser, using the same basic code.

1:18:31.700,1:18:33.390
Here's the same basic steps again:

1:18:33.390,1:18:35.110
from import star
untar data

1:18:35.110,1:18:38.270
tabular data loaders
from csv

1:18:38.270,1:18:39.970
learner fit

1:18:39.970,1:18:52.030
This is now building a model that is predicting
salary based on a csv table containing these

1:18:52.030,1:18:53.030
columns.

1:18:53.030,1:18:56.620
So this is tabular data.

1:18:56.620,1:18:57.620
Here's the same basic steps

1:18:57.620,1:18:59.600
from import *
untar data

1:18:59.600,1:19:02.700
collab data loaders from csv
learner fine-tune

1:19:02.700,1:19:10.850
This is now building something which predicts,
for each combination of a user and a movie,

1:19:10.850,1:19:17.430
what rating do we think that user will give
that movie, based on what other movies they've

1:19:17.430,1:19:18.880
watched and liked in the past.

1:19:18.880,1:19:23.230
This is called collaborative filtering and
is used in recommendation systems.

1:19:23.230,1:19:29.520
So here you've seen some examples of each
of the four applications in fastai.

1:19:29.520,1:19:34.420
And as you'll see throughout this course,
the same basic code and also the same basic

1:19:34.420,1:19:41.700
mathematical and software engineering concepts
allow us to do vastly different things using

1:19:41.700,1:19:43.980
the same basic approach.

1:19:43.980,1:19:47.180
And the reason why is because of Arthur Samuel.

1:19:47.180,1:19:56.840
Because of this basic description of what
it is you can do if only you have a way to

1:19:56.840,1:20:01.630
parameterize a model and you have an update
procedure which can update the weights to

1:20:01.630,1:20:09.850
make you better at your loss function, and
in this case we can use neural networks, which

1:20:09.850,1:20:14.350
are totally flexible functions.

1:20:14.350,1:20:18.250
So that's it for this first lesson.

1:20:18.250,1:20:23.221
It's a little bit shorter than our other lessons
going to be and the reason for that is that

1:20:23.221,1:20:29.850
we are as I mentioned at the start of a global
pandemic here, or at least in the West (in

1:20:29.850,1:20:32.710
other countries they are much further into
it).

1:20:32.710,1:20:36.520
So we spent some time talking about that at
the start of the course and you can find that

1:20:36.520,1:20:39.500
video elsewhere.

1:20:39.500,1:20:45.730
So in the future lessons there will be more
on deep learning.

1:20:45.730,1:20:53.780
So, what I suggest you do over the next week,
before you work on the next lesson, is just

1:20:53.780,1:20:58.470
make sure that you can spin up a GPU server,
you can shut down when it's finished and that

1:20:58.470,1:21:06.010
you can run all of the code here and, as you
go through, see if this is using Python in

1:21:06.010,1:21:14.750
a way you recognise, use the documentation,
use that doc function, do some search on the

1:21:14.750,1:21:20.480
fastai doc, see what it does, see if you can
actually grab the fastai documentation notebooks

1:21:20.480,1:21:22.270
themselves and run them.

1:21:22.270,1:21:26.090
Just try to get comfortable, that you can
if you can know your way around.

1:21:26.090,1:21:30.340
Because the most important thing to do with
this style of learning, this top-down learning,

1:21:30.340,1:21:34.710
is to be able to run experiments and that
means you need to be able to run code.

1:21:34.710,1:21:41.360
So my recommendation is: don't move on until
you can run the code, read the chapter of

1:21:41.360,1:21:47.850
the book, and then go through the questionnaire.

1:21:47.850,1:21:52.980
We still got some more work to do about validation
sets and test sets and transfer learning.

1:21:52.980,1:21:58.360
So you won't be able to do all of it yet but
try to to all the parts you can, based on

1:21:58.360,1:22:01.020
what we've seen of the course so far.

1:22:01.020,1:22:04.130
Rachel, anything you want to add before we
go.

1:22:04.130,1:22:08.350
Okay, so thanks very much for joining us for
lesson one everybody and are really looking

1:22:08.350,1:22:14.880
forward to seeing you next time where we will
learn about transfer learning and then we

1:22:14.880,1:22:22.150
will move on to creating an actual production
version of an application that we can actually

1:22:22.150,1:22:27.500
put out on the Internet and you can start
building apps that you can show your friends

1:22:27.500,1:22:29.960
and they can start playing with.

1:22:29.960,1:22:30.440
Bye Everybody
