0:00:00.030,0:00:05.819
Oh hello, and welcome to lesson three of practical deep learning for coders

0:00:07.510,0:00:09.510
We

0:00:09.880,0:00:11.590
Were looking at

0:00:11.590,0:00:14.609
getting our model into production last week and

0:00:15.160,0:00:21.059
So we're going to finish off that today and then we're going to start to look behind the scenes at what actually goes on when?

0:00:21.060,0:00:23.060
We train a neural network. We're going to look at

0:00:23.740,0:00:25.830
Kind of the math of what's going on

0:00:26.740,0:00:31.859
And we're going to learn about SGD and it's important stuff like that

0:00:33.219,0:00:36.719
The the order is slightly different to the book in the book

0:00:36.719,0:00:39.509
there's a part in the book which says like hey, you can either go to

0:00:40.300,0:00:46.469
Lesson 4 or lesson 3 now and then go back to the other one afterwards. So we're doing lesson 4 and then lesson 3

0:00:47.320,0:00:49.320
Chapter 4 and then chapter 3 I should say

0:00:49.960,0:00:51.370
You can choose it

0:00:51.370,0:00:53.370
Whichever way you're interested in

0:00:53.590,0:01:01.229
Chapter 4 is the more technical chapter about the foundations of how deep learning really works whereas chapter 3 is all about

0:01:01.629,0:01:03.160
ethics

0:01:03.160,0:01:06.330
And so with the lessons we'll do that next week

0:01:08.760,0:01:10.819
So we're looking at

0:01:11.790,0:01:14.119
0-2 production notebook and

0:01:15.150,0:01:19.039
We've got to look at the fast book version to run with her and in fact everything

0:01:19.040,0:01:22.009
I'm looking at today will be in the fast book version and

0:01:23.670,0:01:25.670
Remember last week. We had a look at

0:01:26.490,0:01:31.549
Our our bears and we created this data loaders object

0:01:32.220,0:01:34.220
by using

0:01:34.610,0:01:41.780
The datablock api which I hope everybody's had a chance to experiment with this week if you haven't now's a good time to do it

0:01:43.650,0:01:45.889
We kind of skipped over one of the lines a little bit

0:01:47.590,0:01:51.880
Item transforms so what this is doing here when we said resize

0:01:53.359,0:01:57.969
The the images we downloaded from the internet had lots of different sizes and lots of different aspect ratios

0:01:58.039,0:02:01.959
Some at all and some are wide. I'm a square and some are big some are small

0:02:02.479,0:02:08.949
When you say resize for an item transform, it means each item to an item in this case is one image

0:02:10.009,0:02:12.398
Is going to be resized to 128 by 128

0:02:13.099,0:02:20.319
By squishing it or stretching it. And so we had a look at you can always say show batch to see a few examples and

0:02:20.959,0:02:22.959
This is what they look like

0:02:25.379,0:02:31.279
Squishing and stretching isn't the only way that we can resize remember we have everything we have to make everything into a square

0:02:32.280,0:02:35.780
Before we kind of get it into our model by the time it gets to our model

0:02:35.780,0:02:40.639
Everything has to be the same size in each mini wedge. So that's why and they're making it a square

0:02:40.639,0:02:44.329
It's not the only way to do that, but it's the easiest way and it's the by far the most common way

0:02:45.590,0:02:47.590
um, so

0:02:49.740,0:02:52.219
Another way to do this

0:02:54.210,0:02:56.779
Is we can create a another

0:02:57.990,0:03:02.029
Data block object and we can make a data block object

0:03:02.030,0:03:07.970
That's an identical copy of an existing data block object where we can then change just some pieces

0:03:08.310,0:03:13.880
And we can do that by calling the new method which is super handy. And so let's create another data block

0:03:14.970,0:03:19.130
object in this time with different item transform where we resize

0:03:19.800,0:03:21.800
using the

0:03:22.260,0:03:29.839
Squish method we have a question. What are the advantages of having Square images versus rectangular ones?

0:03:32.739,0:03:35.529
That's a great question so

0:03:38.840,0:03:40.780
Really its simplicity

0:03:40.780,0:03:42.580
Yeah, if if you know

0:03:42.580,0:03:47.619
All of your images are rectangular of a particular aspect ratio to start with you may as well

0:03:47.620,0:03:51.850
Just keep them that way but if you've got some which at all and some which are wide

0:03:53.480,0:03:55.570
Making them all square is kind of the easiest

0:03:56.120,0:04:02.110
Otherwise, you would have to kind of organize them such as all of the tall ones kind of ended up in a mini batch nor

0:04:02.110,0:04:03.580
The wide ones ended up in a mini batch

0:04:03.580,0:04:05.889
And then you'd have to kind of then figure out

0:04:06.290,0:04:13.150
What the best aspect ratio for each mini batch is and we actually have some research that does that in fast AI too

0:04:14.150,0:04:16.150
But it's still a bit clunky

0:04:17.540,0:04:22.749
I should mention. Okay, I just lied to you. The default is not actually to squish your stretch the default

0:04:22.750,0:04:27.519
I should have said sorry the default when we say resize is actually just to

0:04:28.190,0:04:30.190
grab

0:04:31.190,0:04:32.660
Grab the center

0:04:32.660,0:04:34.809
Actually, all we're doing is regretting the center of each image

0:04:34.850,0:04:36.580
so if we want to squish your stretch

0:04:36.580,0:04:44.229
You can add the resize method squish argument to resize and you can now see that this black bear is now looking much thinner

0:04:44.720,0:04:49.059
But we have got the kind of leaves that are round on each side instance

0:04:51.740,0:04:59.049
Another question when you use the DL s dot new method what can cannot be changed is it just the

0:04:59.270,0:05:04.719
Transforms it so it's not dl s new it's bears dot new right? So we're not creating a new data Lotus object

0:05:04.719,0:05:08.949
We're creating a new data block object. I don't remember off the top of my head

0:05:08.949,0:05:13.179
so check the documentation and I'm sure somebody can pop the answer into the

0:05:14.449,0:05:16.449
into the form

0:05:17.440,0:05:18.580
So

0:05:18.580,0:05:22.020
you can see when we use dot squish that this grizzly bear is got

0:05:22.810,0:05:24.280
pretty kind of

0:05:24.280,0:05:31.109
Wide and weird-looking and this black bear has got pretty weird and thin looking and it's easiest kinda to see what's going on

0:05:31.110,0:05:32.680
if we use

0:05:32.680,0:05:37.199
Precise method pad and what dot pad does as you can see is it just add some?

0:05:37.449,0:05:41.279
Black bars around each side so you can see the grizzly bear was tall

0:05:41.650,0:05:45.720
So then when we we stretched squashing and stretching opposites of each other

0:05:45.720,0:05:49.589
So when we stretched it, it ended up wide and the black bear was

0:05:50.889,0:05:54.239
Originally a wide rectangle. So it ended up looking kind of thin

0:05:58.090,0:06:02.590
To use zero zeros means pad it with black you can also say like reflect to kind of have

0:06:04.530,0:06:07.260
The pixels will kind of look a bit better that way if you use reflect

0:06:08.890,0:06:11.489
All of these different methods have their own problems

0:06:11.650,0:06:18.239
The the pad method is kind of the cleanest you end up with the correct size you end up with all of the pixels

0:06:18.520,0:06:22.859
But you also end up with wasted pixels. So you kind of end up with wasted computation

0:06:23.800,0:06:28.380
This grish method is the most efficient because you get all of the information

0:06:30.610,0:06:37.860
You know and and nothing's kind of wasted but on the downside your neural nets gonna have to learn to kind of like

0:06:38.230,0:06:42.450
Recognize when something's being squished or stretched and in some cases, it might it wouldn't even know

0:06:42.760,0:06:44.250
So if there's two objects

0:06:44.250,0:06:48.390
You're trying to recognize one of which tends to be thin and one of it tends to be thick in other words

0:06:48.390,0:06:51.509
They're the same. They could actually be impossible to distinguish

0:06:52.720,0:06:55.260
And then the default cropping approach

0:06:56.020,0:07:01.020
Actually removes some information. So in this case

0:07:01.930,0:07:04.890
You know, this is grizzly bear here

0:07:05.440,0:07:10.440
We actually lost a lot of its legs. So if figuring it out what kind of bear it was

0:07:11.500,0:07:14.070
Required looking at its feet. Well, we don't have its feet anymore

0:07:14.950,0:07:16.950
So they all have downsides

0:07:20.170,0:07:25.319
So there's something else that you can do a different approach which is instead us to say resize you can say

0:07:25.660,0:07:31.140
Random resized crop and actually, this is the most common approach and what random resize crop does is each time

0:07:32.770,0:07:34.919
It actually grabs a

0:07:35.980,0:07:40.980
Different part of the image and kind of zooms into it. Alright, so

0:07:41.530,0:07:45.059
these this is all the same image and we're just grabbing a batch of

0:07:45.910,0:07:48.930
four different versions of it and you can see some are kind of

0:07:49.930,0:07:56.219
you know, they're all squished in different ways and we've kind of selected different subsets and so forth now this

0:07:56.950,0:08:02.909
Panna seems worse than any of the previous approaches because I'm losing information like this one here

0:08:02.910,0:08:07.020
I've actually lost a whole lot of its of its back, right?

0:08:08.440,0:08:12.630
but the cool thing about this is that remember we want to avoid overfitting and

0:08:14.230,0:08:17.640
When you see a different part of the animal each time

0:08:18.520,0:08:22.829
It's much less likely to over fit because you're not seeing the same image on each

0:08:23.650,0:08:26.759
Epoch that you go around that makes sense. So

0:08:28.870,0:08:35.280
So this random random resized crop approach is actually super popular and so min scale 0.3 means

0:08:35.800,0:08:37.750
We're going to pick at least

0:08:37.750,0:08:41.309
30% of the pixels of kind of the original size each time

0:08:42.010,0:08:45.239
And then what kind of like zoom into that that square?

0:08:50.740,0:08:52.300
So

0:08:52.300,0:08:59.490
This idea of doing something so that each time the model sees the image. It looks a bit different to last time

0:08:59.529,0:09:04.259
It's called data augmentation. And this is one type of data augmentation. It's

0:09:04.990,0:09:06.990
Probably the most common

0:09:07.390,0:09:09.220
But there are others

0:09:09.220,0:09:10.959
and

0:09:10.959,0:09:14.009
one of the best ways to do a data augmentation is to use

0:09:15.100,0:09:16.600
this

0:09:16.600,0:09:21.209
transforms function and what all transforms does is it actually returns a list of

0:09:22.779,0:09:24.279
Different

0:09:24.279,0:09:27.029
augmentations and so there are

0:09:27.760,0:09:30.599
augmentations which change contrast which change brightness

0:09:31.209,0:09:34.139
Which warps a perspective so you can see in this one here

0:09:34.140,0:09:38.909
it looks like this bits much closer to you and this moves much away from you because it's going to be in perspective what it

0:09:38.910,0:09:43.860
Rotates them see this one's actually being rotated. This one's been made really dark, right?

0:09:45.220,0:09:50.760
These are batch transforms not item transforms. The difference is that item transforms happen one image at a time?

0:09:50.760,0:09:55.709
And so the thing that resizes them all of the same size that has to be an item transform

0:09:56.529,0:09:57.899
Pop it all into a mini batch

0:09:57.899,0:10:03.539
put it on the GPU and then a batch transform happens to a whole mini batch at a time and

0:10:03.880,0:10:09.570
by putting these as batch transforms that the augmentation happens super fast because it happens on the GPU and

0:10:09.940,0:10:11.940
I don't know if there's any other

0:10:12.190,0:10:19.799
Libraries as we speak which allow you to write your own GPU accelerated transformations that run on the GPU in this way

0:10:21.250,0:10:25.409
so this is a super handy thing in first AI to

0:10:29.059,0:10:32.048
So you can check out the documentation or

0:10:33.169,0:10:39.759
Org transforms and when you do you'll find the documentation for all of the underlying transforms that it basically wraps, right?

0:10:41.179,0:10:43.358
So you can see if I shift tab

0:10:43.359,0:10:49.149
I don't remember for showing you this trick before if you go inside the parentheses of a function and hit shift tab a few times

0:10:49.579,0:10:55.598
it'll pop open a list of all of the arguments and so you can basically see you can say like oh

0:10:57.079,0:11:03.339
Can I sometimes flip it left? Right? Can I sometimes flip it up down? What's the maximum and I can rotate zoom?

0:11:04.039,0:11:05.959
range Allah lighting

0:11:05.959,0:11:07.959
What the perspective?

0:11:08.179,0:11:10.179
and so forth

0:11:10.639,0:11:14.829
How can we add different augmentations for train and validation sets?

0:11:16.970,0:11:18.970
So the cool thing is that

0:11:21.499,0:11:28.209
Automatically last a I will avoid doing data augmentation on the validation set

0:11:28.939,0:11:32.469
so all of these all transforms will only be applied to

0:11:33.319,0:11:35.319
the

0:11:35.839,0:11:37.699
Training set

0:11:37.699,0:11:43.149
with the exception of random resize crop random resize crop has a different behavior or each

0:11:43.699,0:11:49.178
The behavior for the training set is what we just saw which is to randomly pick a subset. I'm going to zoom into it and

0:11:49.729,0:11:51.049
the

0:11:51.049,0:11:56.769
Behavior for the validation set is just to grab the center the largest center square that it can

0:12:00.500,0:12:02.450
You can write your own

0:12:02.450,0:12:06.160
Transformations that they're just Python they just standard pi torch code

0:12:06.830,0:12:10.629
the way if you and and by default it will only be applied to

0:12:10.700,0:12:12.939
The training set if you want to do something fancy

0:12:12.940,0:12:15.999
Like random resize crop where you actually have different things being applied to H

0:12:16.460,0:12:22.540
You should come back to the next course to find out how to do that or read the documentation. It's not rocket science, but it's

0:12:23.870,0:12:25.870
That's something most people need to do

0:12:27.900,0:12:29.900
Um, okay, so

0:12:31.750,0:12:33.750
Last time we

0:12:33.910,0:12:39.149
Did bears dot new with a random resize crop mean scale of 0.5. We added some transforms

0:12:40.240,0:12:43.889
And he went ahead and trained actually since last week over rerun this notebook

0:12:43.890,0:12:47.759
I've got it's on a different computer and I've got different images. So it's not all exactly the same

0:12:48.460,0:12:52.860
but I still got a good confusion matrix of the

0:12:55.470,0:12:58.850
37 were classified correctly to a Grizzly's of one was a teddy

0:13:00.810,0:13:02.810
Now

0:13:03.220,0:13:06.790
Plot plot top losses and it's interesting you can see in this case

0:13:07.399,0:13:10.958
There's some clearly kind of odd things going on. This is not a bear at all

0:13:11.540,0:13:15.610
This looks like it's a drawing of a bear which it's decided is

0:13:17.120,0:13:23.079
Predicted as a Teddy, but this thinks it's meant to be a drawing of a black bear. I can certainly see the confusion

0:13:23.629,0:13:25.040
You can see

0:13:25.040,0:13:29.199
How some parts would have been cut off, but talk about how to deal with that later

0:13:29.720,0:13:33.819
Now one of the interesting things is that we didn't really do much

0:13:34.910,0:13:37.990
Data cleaning at all before we built this model

0:13:37.990,0:13:44.379
The only data cleaning we did was just to validate that each image can be opened there. Was that verify images call

0:13:44.899,0:13:52.208
and the reason for that is it's actually much easier normally to clean your data after you create a model and I'll show you how

0:13:52.759,0:13:54.350
We've got this thing called

0:13:54.350,0:13:56.350
image classifier cleaner

0:13:56.810,0:14:00.339
Where you can pick a category, right?

0:14:01.160,0:14:02.360
and

0:14:02.360,0:14:04.360
training set or validation set

0:14:05.910,0:14:09.059
And then what it will do is it will then

0:14:09.490,0:14:14.339
List all of the images in that set and it will pick the ones

0:14:14.890,0:14:16.890
which are

0:14:18.790,0:14:22.019
The which is the least confident about which is the most likely to be wrong

0:14:23.290,0:14:27.149
Where the weather loss is the worst to be more precise

0:14:27.880,0:14:29.880
and so this

0:14:30.130,0:14:32.130
this is a great way to

0:14:32.590,0:14:37.199
Look through your data and find problems. So in this case the first one

0:14:37.990,0:14:41.789
Is not a teddy or a brown bear or a black bear. It's a puppy dog

0:14:42.280,0:14:47.610
All right. So this is a great cleaner because what I can do is I can now click delete here

0:14:47.950,0:14:53.160
This one here looks a bit like an Ewok rather than a teddy. I'm not sure. What do you think Rachel isn't an Ewok?

0:14:53.160,0:14:54.940
I'm going to call it an Ewok

0:14:54.940,0:14:56.940
Ok, and so you can kind of go through

0:14:58.240,0:15:05.399
Okay, that's definitely not a teddy and so you can either say like oh that's wrong it's actually a grizzly bear or it's wrong

0:15:05.400,0:15:10.019
it's a black bear or I should delete it or by default is keep it right and you can kind of keep going through until

0:15:10.020,0:15:12.569
You think like okay, they're all seem to be fine

0:15:15.040,0:15:17.040
Maybe that one's not

0:15:18.780,0:15:21.749
Kind of once you get to the point where they also in to be fine, you can kind of say, okay

0:15:22.690,0:15:28.200
Probably all the rest to fine too because they all have lower losses. So they all fit the kind of the mold of a teddy

0:15:28.750,0:15:31.440
And so then I can run this code here

0:15:32.820,0:15:40.549
Where I just go through cleaner, dr. Leach so that's all the things which I've selected delete for and unlink them so unlink

0:15:42.090,0:15:46.280
Is just another way of saying delete a file that's the Python name

0:15:46.800,0:15:52.130
And then go through all the ones that we said change and we can actually move them to the correct

0:15:52.680,0:15:54.680
directory

0:15:54.900,0:16:00.259
If you haven't seen this before you might be surprised that we've kind of created our own little gooey inside

0:16:02.850,0:16:04.850
Jupiter notebook

0:16:05.310,0:16:11.239
Yeah, you can do this and we built this with less than a screen of code you can check out the source code in the

0:16:11.940,0:16:16.369
Past AI notebooks. So this is a great time to remind you that

0:16:20.089,0:16:22.089
This is a great time to remind you that

0:16:23.920,0:16:24.740
Ji

0:16:24.740,0:16:31.959
is built with notebooks and so if you go to the first AI repo and clone it and then go to NBS you'll find

0:16:33.350,0:16:36.380
all of the code of fast AI

0:16:38.010,0:16:43.400
Written as notebooks and they've got a lot of prose and examples and tests and so forth

0:16:43.680,0:16:49.519
So the best place to learn about how this is implemented is to look at the notebooks

0:16:50.040,0:16:52.040
rather than looking at the

0:16:52.890,0:16:54.890
module code

0:16:56.310,0:16:58.290
Okay

0:16:58.290,0:17:02.600
By the way, sometimes you'll see like weird little comments like this

0:17:03.090,0:17:06.769
These weird little comments are part of a development environment for Jupiter notebook

0:17:06.770,0:17:09.440
we use called env dev which we built so

0:17:09.870,0:17:14.839
Silva and I built this thing to make it much easier for us to kind of create books

0:17:15.390,0:17:21.650
And websites and libraries in Jupiter notebooks. So this particular one here hide

0:17:22.530,0:17:24.270
means

0:17:24.270,0:17:29.030
when this is turned into a book or into documentation don't show this cell and

0:17:29.310,0:17:32.869
The reason for that is because you can see I've actually got it in the text, right?

0:17:32.870,0:17:38.780
But I thought when you're actually running it, it would be nice to have it sitting here waiting for you to run directly

0:17:38.780,0:17:44.030
So that's why it's shown in the notebook. But not in the in the book has shown differently

0:17:47.790,0:17:51.180
Like s : with a quote in the book that would end up saying

0:17:51.370,0:17:56.130
Sylvia says and then what he says so there's kind of little bits and pieces in the

0:17:56.410,0:17:58.619
In the notebooks that just look a little bit odd

0:17:58.620,0:18:04.620
And that's because it's designed that way in order to show in order to create stuff in them

0:18:06.660,0:18:13.849
Right, so then last week we saw how you can export that to a pickle file that contains all the information from the model

0:18:14.370,0:18:18.589
And then on the server where you're going to actually do your inference

0:18:18.590,0:18:25.100
You can then load that save file and you'll get back a learner that you can call predict on so predict

0:18:30.790,0:18:34.200
Perhaps the most interesting part of predict is the third thing that it returns

0:18:35.630,0:18:38.599
Which is a tensor in this case containing three numbers

0:18:39.420,0:18:47.420
But the three numbers there's three of them because we have three classes teddy bear grizzly bear and black bear. All right, and so

0:18:48.360,0:18:55.160
This doesn't make any sense until you know what the order of the classes is kind of in in

0:18:55.710,0:18:57.710
in your data loaders

0:18:57.710,0:19:02.240
And you can ask the data loaders what the order is by asking for its vocab

0:19:02.250,0:19:06.650
So a vocab in fast AI is a really common concept

0:19:06.650,0:19:12.109
it's basically any time that you've got like a mapping from numbers to strings or

0:19:13.170,0:19:19.579
Discrete levels. The mapping is always taught in the vocab. So here this shows us that the

0:19:22.200,0:19:24.200
The activation or

0:19:26.580,0:19:28.580
Black bear is

0:19:29.799,0:19:37.388
Six the activation for grizzly is one and the activation for teddy is ten a neck six

0:19:40.450,0:19:48.150
So very very confident that this particular one it was a grizzly not surprisingly this was something called grizzly type JPEG

0:19:50.650,0:19:52.650
Um

0:19:53.670,0:19:55.000
This

0:19:55.000,0:19:57.420
This mapping in order to display the correct thing

0:19:57.420,0:20:03.330
But of course the data loaders object already knows that mapping and it's all the vocab and it's stored in with the loader

0:20:03.880,0:20:06.660
So that's how it knows to say grizzly automatically

0:20:06.660,0:20:10.350
So the first thing it gives you is the human readable string that you'd want to display

0:20:11.110,0:20:18.420
So this is kind of nice that with FASTA a to you you save this object which has everything you need for inference

0:20:18.420,0:20:20.850
It's got all the you know information about

0:20:22.420,0:20:28.739
Normalization about any kind of transformation steps about what the vocab is so it can display everything correctly

0:20:30.040,0:20:33.359
Right. So now we want to

0:20:34.930,0:20:37.049
Deploy this as an app

0:20:38.290,0:20:43.590
now if you've done some web programming before then all you need to know is that this

0:20:44.020,0:20:46.530
line of code and this line of code

0:20:46.630,0:20:51.359
so this is the line of codes you would call once when your application starts up and

0:20:51.580,0:20:53.580
Then this is the line of code you would call

0:20:53.710,0:20:57.419
Every time you want to do an inference, and there's also a batch version of it

0:20:57.420,0:21:00.359
Which you can look up if you're interested, this is just a Roo one at a time

0:21:03.520,0:21:04.880
So there's nothing special

0:21:04.880,0:21:08.680
If you're already a web programmer or have access to a web programmer

0:21:08.930,0:21:13.570
these that you don't you just have to stick these two lines of code somewhere and the three things you get back whether

0:21:14.270,0:21:17.290
The the human readable string if you're doing categorization

0:21:18.110,0:21:23.469
The index of that which in this case is one is grizzly and the probability of each plus

0:21:24.920,0:21:30.729
One of the things we really wanted to do in this course though is not assume that everybody is a web developer

0:21:31.880,0:21:38.080
most data scientists aren't but gee wouldn't it be great if all data scientists could at least like prototype an

0:21:38.210,0:21:40.510
application to show off the thing they're working on and

0:21:41.930,0:21:43.930
so we've

0:21:43.980,0:21:48.719
Trying to kind of curate an approach which none of its stuff. We've built. It's really as curated

0:21:49.690,0:21:56.400
Which shows how you can create a GUI and create a complete application in Jupiter notebook

0:21:57.160,0:21:59.160
so the

0:21:59.470,0:22:00.490
Key

0:22:00.490,0:22:07.559
Pieces of technology we use to do this our ipython widgets, which is always called a PI widgets and voila. I

0:22:08.169,0:22:14.939
pi widgets, which we import by default as widgets, and that's also what they use in their own documentation as

0:22:15.970,0:22:19.199
GUI widgets for example a file upload button

0:22:20.290,0:22:21.820
so if I create

0:22:21.820,0:22:25.350
this file upload button and then display it I

0:22:25.900,0:22:30.540
See and we saw this in the last lesson as well or maybe as lesson one an actual clickable button

0:22:32.020,0:22:34.020
so I can go ahead and

0:22:35.650,0:22:37.650
Click it

0:22:37.720,0:22:43.689
OK you've selected one thing. So how do I use that? Well these

0:22:48.470,0:22:55.089
While these widgets have all kinds of methods and properties and the upload button has a data property

0:22:55.940,0:22:59.559
Which is an array containing all of the images you uploaded

0:23:00.470,0:23:07.270
So you can pass that to Pio image create and so doc create is kind of the standard

0:23:10.000,0:23:13.800
Factory method we use in fast AI to create items

0:23:14.710,0:23:19.229
And Pol image create is smart enough to be able to create an item from all kinds of different things

0:23:19.330,0:23:24.569
And one of the things that can create it from is a binary blob which is what a file upload contains

0:23:25.950,0:23:27.950
so then we can display it and

0:23:28.330,0:23:30.120
There's our teddy, right?

0:23:30.120,0:23:37.739
So you can see how you know cells of Jupiter notebook can refer to other cells that were created that were kind of

0:23:38.200,0:23:39.310
have

0:23:39.310,0:23:41.310
GUI created data in them

0:23:42.530,0:23:44.930
Let's hide that teddy away for a moment and

0:23:46.110,0:23:52.160
the next thing to know about is that there's a kind of widget called output and an output widget is

0:23:53.760,0:23:55.760
It's basically something that

0:23:56.580,0:24:01.099
You can fill in later, right? So if I delete actually

0:24:02.040,0:24:04.609
This part here. So I've now got an output

0:24:05.520,0:24:07.520
widget

0:24:07.930,0:24:09.930
Access to this way around

0:24:12.509,0:24:13.359
And

0:24:13.359,0:24:17.968
You can't see the output widget, even though I said, please display it because nothing is output

0:24:17.969,0:24:21.719
So then in the next cell I can say with that output

0:24:22.239,0:24:23.409
householder

0:24:23.409,0:24:28.799
Display a thumbnail of the image and you'll see that the the display will not appear here

0:24:30.050,0:24:35.389
It appears back here, right? Because that's how that's where the placeholder was

0:24:36.840,0:24:40.280
So let's run that again to clear out that placeholder

0:24:41.940,0:24:46.759
So we can create another kind of placeholder which is a label their labels kind of a

0:24:47.490,0:24:54.410
Something where you can put text in it. They can give it a value like I don't know. Please choose an

0:24:55.170,0:24:56.850
image

0:24:56.850,0:24:59.959
Okay, so we've now got a label containing please choose an image

0:25:00.630,0:25:03.140
Let's create another button to do your classification

0:25:04.870,0:25:09.069
Now this is not a file upload button it's just a general button so this button doesn't do anything

0:25:10.430,0:25:12.759
all right, it doesn't do anything until we

0:25:13.310,0:25:20.440
Attach an event handler to it an event handler is a callback. We'll be learning all about callbacks in this course

0:25:21.770,0:25:27.400
if you've ever done any GUI programming before or even web programming you'll be familiar with the idea that you

0:25:27.800,0:25:35.139
Write a function, which is the thing you want to be called when the button is clicked on and then somehow you tell your framework

0:25:35.960,0:25:37.960
That this is the on click event

0:25:38.150,0:25:40.719
So here I go. Here's my button run. I

0:25:41.240,0:25:43.160
Say the on click event

0:25:43.160,0:25:45.160
the button run is

0:25:45.230,0:25:51.610
We call this code and this code is going to do all the stuff. We just saw and I create an image from the upload

0:25:52.220,0:25:54.970
It's going to clear the output. Let's play the image

0:25:55.850,0:25:58.390
call predict and then replace the

0:25:59.060,0:26:01.060
label with a prediction

0:26:02.750,0:26:07.330
There it all is now so that hasn't done anything but I can now go back to this classify button

0:26:07.330,0:26:09.819
Which now has an event handler attached to it. So watch this

0:26:10.550,0:26:12.530
quick

0:26:12.530,0:26:14.629
Pump and look that's been filled in

0:26:16.010,0:26:22.999
Filled in right in case you missed it. Let's run this again to clear everything out. Okay, everything's gone

0:26:27.330,0:26:30.769
This is please choose an image, there's nothing here I click classify

0:26:32.340,0:26:33.780
Well

0:26:33.780,0:26:38.090
Pop-up, right? So it's kind of amazing how our

0:26:39.030,0:26:41.540
Notebook has suddenly turned into this

0:26:42.210,0:26:47.239
interactive prototyping playground building applications and so once all this works

0:26:48.300,0:26:51.019
We can dump it all together. And so

0:26:54.510,0:26:57.439
The easiest way to dump things together is to create a V box

0:26:57.440,0:26:59.130
So V box is a vertical box

0:26:59.130,0:27:01.849
And it's just it's just something that you put widgets in

0:27:01.850,0:27:02.870
and so in this case

0:27:02.870,0:27:06.409
We're going to put the following widgets rhiness have a label that says select your beer

0:27:06.570,0:27:10.789
then an upload button a run button and output placeholder and a

0:27:11.340,0:27:13.140
label for predictions

0:27:13.140,0:27:15.679
But let's run these again just to clear everything out. So

0:27:16.590,0:27:18.590
That we're not cheating

0:27:20.060,0:27:26.210
And let's create our V box so as you can see it's just got all the

0:27:27.789,0:27:29.789
All the pieces

0:27:29.950,0:27:31.950
right

0:27:33.800,0:27:35.800
We've got whatever

0:27:37.660,0:27:40.899
I accidentally ran the thing that displayed the bear. Let's get rid of that

0:27:45.600,0:27:52.060
Okay, so there it is so now I can click upload my bear

0:27:54.880,0:27:56.880
Okay, and then I can click classify

0:27:57.730,0:28:02.459
right and notice I've this is exactly that this is this is like the same buttons as

0:28:03.340,0:28:10.169
These buttons they're like two places with we're viewing the same button, which is kind of a wild idea. So if I click classify

0:28:10.780,0:28:12.780
it's going to change this label and

0:28:14.350,0:28:17.880
This label because they're actually both references to the same label look

0:28:20.280,0:28:22.080
There we go

0:28:22.080,0:28:23.700
so

0:28:23.700,0:28:28.640
This is our app. Right? And so this is actually how I built that

0:28:29.340,0:28:31.610
that image planar GUI is

0:28:32.519,0:28:37.759
Just using these exact things and I built that image cleaner GUI

0:28:38.669,0:28:44.028
Cell-by-cell in a notebook just like this and so you get this kind of interactive

0:28:44.610,0:28:46.200
experimental framework

0:28:46.200,0:28:47.309
for building a GUI

0:28:47.309,0:28:54.018
so if you're a data scientist who's never done GUI stuff before this is a great time to get started because now you can

0:28:54.210,0:28:56.210
You can make actual

0:28:56.370,0:28:57.419
programs

0:28:57.419,0:28:59.419
now, of course an actual program

0:28:59.760,0:29:07.609
Running inside a notebook is kind of cool. But what we really want is this program to run in a place anybody can run it

0:29:08.850,0:29:10.850
That's where voila comes in Oh

0:29:11.100,0:29:16.819
Voila and needs to be installed so you can just run these lines

0:29:17.460,0:29:19.460
Or install it

0:29:21.330,0:29:23.330
It's listed in the prose

0:29:23.340,0:29:28.429
and one voila does is it takes a notebook and

0:29:29.610,0:29:32.479
Doesn't display anything except for the markdown

0:29:33.750,0:29:37.489
the ipython widgets and the outputs

0:29:38.280,0:29:44.509
Right, so well the code cells disappear and it doesn't give the person looking at that page the ability to run their own code

0:29:44.510,0:29:46.320
they can only

0:29:46.320,0:29:48.320
Interact with the widgets, right?

0:29:48.600,0:29:50.600
So what I did

0:29:50.970,0:29:57.470
was a copied and pasted that code from the notebook into a separate notebook, which only has

0:29:59.690,0:30:02.419
Those lines of code, right so

0:30:07.049,0:30:09.409
So this is just the same lines of code that we saw before

0:30:12.650,0:30:15.050
And so this is a notebook it's just a normal notebook

0:30:17.400,0:30:21.469
And then I installed voila and then when you do that if you

0:30:22.440,0:30:25.999
Navigate to this notebook but you replace

0:30:30.430,0:30:34.319
Notebooks up here with voila

0:30:35.970,0:30:38.459
It actually displays not the notebook but

0:30:40.320,0:30:45.500
Just as I said the markdown and the widgets so here I've got

0:30:47.250,0:30:51.689
Bear classifier and I can click upload. Let's do a grizzly bear this time

0:30:56.460,0:31:00.199
And this is a slightly different version I actually made this so there's no classify button

0:31:00.200,0:31:02.179
I thought it would be a bit more fancy to make it

0:31:02.179,0:31:05.839
So when you click upload it just runs everything but as you can see there it all is

0:31:06.420,0:31:08.420
Right. It's all working. So

0:31:09.540,0:31:11.540
This is the world's

0:31:11.730,0:31:13.170
simplest

0:31:13.170,0:31:16.549
Prototype, but it's it's a proof-of-concept right so you can add

0:31:17.250,0:31:18.750
widgets with

0:31:18.750,0:31:24.799
dropdowns and sliders and charts and you know everything that you can have in a

0:31:25.049,0:31:30.289
You know an angular app or a react app or whatever. And in fact, there's there's even

0:31:31.260,0:31:36.770
Stuff which lets you use, for example, the whole view j/s framework if you know that it's a very popular

0:31:37.799,0:31:41.059
JavaScript framework the whole view jes framework, you can actually use it in

0:31:42.299,0:31:44.299
widgets and voila

0:31:45.000,0:31:47.000
so now we want to get it so that this

0:31:47.910,0:31:49.530
this app

0:31:49.530,0:31:51.330
Can be run by

0:31:51.330,0:31:53.220
Someone out there in the world

0:31:53.220,0:31:58.010
So the voila documentation shows a few ways to do that, but perhaps the easiest one

0:31:58.530,0:32:01.669
Is to use a system called binder

0:32:04.500,0:32:07.050
So binder is at mine, but my binder org

0:32:08.290,0:32:13.389
And all you do is you paste in your github repository name here, right? And this is all in the book

0:32:15.510,0:32:17.510
So you

0:32:18.050,0:32:21.739
Could have repo name you change where it says

0:32:23.190,0:32:25.460
Pile we change that to URL

0:32:28.060,0:32:33.509
You can see and then you put in the path which we were just experimenting with

0:32:34.870,0:32:36.870
right

0:32:37.860,0:32:43.229
Pop that here and then you say launch and what that does is it then gives you a URL

0:32:44.740,0:32:46.580
So then this URL

0:32:46.580,0:32:48.580
You can pass on

0:32:48.770,0:32:50.240
to people

0:32:50.240,0:32:52.240
and this is actually your

0:32:53.000,0:32:57.729
interactive running application so binders free and so this is an you know,

0:32:57.730,0:33:03.849
Anybody can now use this to take their voila app and make it a publicly available web

0:33:04.429,0:33:06.429
application

0:33:06.830,0:33:11.650
So try it as it mentions here the first time you do this binder takes about five minutes

0:33:12.320,0:33:14.030
To build your site. Um

0:33:14.030,0:33:20.469
Because it actually uses something called docker to deploy the whole fast AI framework and Python and blah blah blah

0:33:21.350,0:33:23.350
But once you've done that

0:33:23.450,0:33:27.790
That virtual machine will keep running for you know, as long as people are using it. It'll keep running for a while

0:33:32.150,0:33:37.940
That virtual machine will keep running for a while as long as people are using it and you know, it's it's

0:33:38.580,0:33:40.500
reasonably fast

0:33:40.500,0:33:42.500
So a few things to note here

0:33:43.050,0:33:48.169
Being a free service. You won't be surprised to hear. This is not using a GPU is using a CPU

0:33:49.140,0:33:51.770
And so that might be surprising

0:33:52.530,0:33:55.519
But we're deploying to something which runs on a CPU

0:33:59.830,0:34:05.699
What do you think about it though, this makes much more sense to deploy to a CPU than a GPU

0:34:07.570,0:34:09.570
The

0:34:10.220,0:34:12.220
Just a moment

0:34:13.800,0:34:16.979
Um, the thing that's happening here is that I am

0:34:17.950,0:34:23.909
Passing along that let's go back to my app in my app. I'm passing along a single image at a time

0:34:25.000,0:34:27.120
So when I pass along that single image

0:34:27.120,0:34:30.659
I don't have a huge amount of parallel or work or a GPU to do

0:34:30.850,0:34:34.649
This is actually something that a CPU is going to be doing more efficiently

0:34:36.130,0:34:39.899
So we found that for folks coming through this course

0:34:41.020,0:34:44.159
The vast majority of the time they wanted to deploy

0:34:45.100,0:34:49.019
Inference on a CPU not a GPU because they're normally this doing one

0:34:49.840,0:34:51.840
item at a time

0:34:52.240,0:34:55.800
It's way cheaper and easier to deploy to a CPU

0:34:56.560,0:34:59.610
And the reason for that is that you can just use any

0:34:59.980,0:35:06.300
Hosting service you like because just remember this is just a this is just a program at this point, right?

0:35:07.870,0:35:14.189
And you can use all the usuals horizontal scaling vertical scaling, you know, you can use Heroku you can use AWS

0:35:14.890,0:35:17.189
You can use inexpensive instances

0:35:19.060,0:35:21.060
Super cheap and super easy

0:35:21.700,0:35:25.230
Having said that there are times you might need to deploy to a GPU

0:35:26.590,0:35:33.840
For example, maybe you're processing videos and so like a single video on on a CPU to process

0:35:33.840,0:35:35.840
It might take all day

0:35:36.040,0:35:37.750
or

0:35:37.750,0:35:42.149
You might be so successful that you have a thousand requests per second in

0:35:42.610,0:35:44.320
Which case you could like take?

0:35:44.320,0:35:50.789
128 at a time batch them together and put the whole batch on the GPU and get the results back and pass them back around

0:35:52.260,0:35:54.260
you gotta be careful of that right because

0:35:55.490,0:36:02.719
If your requests aren't coming fast enough your user has to wait for a whole batch of people to be ready to to be processed

0:36:04.410,0:36:10.399
But you know conceptually as long as your site is popular enough that could work

0:36:12.950,0:36:16.839
The other thing to talk about is you might want to deploy to a mobile phone

0:36:17.780,0:36:19.460
and

0:36:19.460,0:36:21.380
the point in to a mobile phone

0:36:21.380,0:36:23.380
Our recommendation is wherever possible

0:36:23.810,0:36:30.579
do that by actually deploying to a server and then have a mobile phone talk to the server over a network and

0:36:30.770,0:36:32.750
Because if you do that

0:36:32.750,0:36:39.579
Again, you can just use a normal pie torch program on a normal server and normal Network calls. It makes life super easy

0:36:40.790,0:36:44.229
When you try to run a PI torch app on a phone

0:36:44.780,0:36:49.780
You are suddenly now not an environment. We're not in an environment where like pi torch will run natively

0:36:49.780,0:36:54.550
and so you'll have to like convert your program into some other form and

0:36:55.069,0:36:56.599
There are other forms

0:36:56.599,0:37:02.169
And the the main form that you convert it to is something called Oh N and X which is specifically designed for

0:37:03.530,0:37:08.769
Kind of super high speed the high performance, you know

0:37:10.339,0:37:15.999
Approach that can run on both servers or on mobile phones and it does not require the whole

0:37:17.030,0:37:19.329
Python and pi torch kind of

0:37:20.119,0:37:22.119
runtime in place

0:37:22.550,0:37:25.899
but it's it's much more complex and

0:37:27.020,0:37:33.159
Not using it's harder to debug it. It's harder to set it up, but it's harder to maintain it. So

0:37:33.980,0:37:37.149
if possible keep things simple and

0:37:37.819,0:37:43.509
If you're lucky enough that you're so successful that you need to scale it up to GPUs or and stuff like that

0:37:44.270,0:37:51.759
then great, you know, hopefully you've got the the finances at that point to justify, you know spending money on a I

0:37:52.310,0:37:55.629
Want an X expert or serving expert or whatever?

0:37:56.450,0:37:58.040
And there are various

0:37:58.040,0:38:02.649
Systems you can use to like go in an X runtime and a wsh maker where you can kind of say

0:38:02.650,0:38:09.609
Here's my o in an X and or when it all serve it for you or whatever pi torch also has a mobile framework

0:38:10.010,0:38:12.010
same idea

0:38:13.660,0:38:14.980
So

0:38:14.980,0:38:20.850
All right, so you've got I mean it's kind of funny. We're talking about two different kinds of deployment here one is deploying like a

0:38:21.550,0:38:28.019
Hobby application, you know that you're prototyping showing off to your friends explaining to your colleagues how something might work

0:38:28.210,0:38:34.199
you know a little interactive analysis, and that's one thing or but maybe you're actually prototyping something that you're

0:38:35.020,0:38:37.020
Want to turn into a real product?

0:38:37.270,0:38:40.229
or an actual real part of your company's

0:38:41.110,0:38:42.370
operations

0:38:42.370,0:38:44.370
When you're deploying

0:38:45.520,0:38:50.280
You know something in in real life there's all kinds of things you got to be careful of

0:38:53.319,0:38:56.768
Sampling to be careful of is let's say you did exactly what we just did

0:38:57.319,0:39:01.149
Which actually this is your homework is to create your own

0:39:01.789,0:39:06.278
application and I want you to create your own image search application you can use

0:39:06.859,0:39:11.078
My exact set of widgets and whatever if you want to but better still

0:39:11.209,0:39:15.999
Go to the I pi widgets website and see what other widgets they have and try and come up with something cool

0:39:17.569,0:39:24.399
Try and comment, you know try and show off as best as you can and show us on the forum now, let's say you decided

0:39:25.039,0:39:27.019
that

0:39:27.019,0:39:29.049
You want to create an app that would help

0:39:29.509,0:39:34.419
The users of your app decide if they have healthy skin or unhealthy skin

0:39:34.459,0:39:41.019
So if you did the exact thing we just did rather than searching for grizzly bear and teddy bear and so forth on bing

0:39:41.599,0:39:46.659
You would search for healthy skin and unhealthy skin and so here's what happens, right?

0:39:46.969,0:39:49.629
if I and remember in our version

0:39:49.630,0:39:55.599
We never actually looked at being we just used the Bing API the Image Search API, but behind the scenes

0:39:55.599,0:40:01.869
It's just using the website. And so if I click healthy if I type healthy skin and say search

0:40:03.530,0:40:06.949
I actually discover that the definition of healthy skin is

0:40:08.700,0:40:10.700
Young white women

0:40:11.640,0:40:13.070
touching their face leveling

0:40:13.070,0:40:19.820
Lee, so that's what your your healthy skin classifier would learn to detect

0:40:20.580,0:40:22.580
right, and so

0:40:23.070,0:40:28.879
This is so this is a great example from Deborah G. And you should check out her paper actionable auditing

0:40:30.300,0:40:35.449
for lots of cool insights about model bias, but I mean here's here's like a

0:40:36.540,0:40:38.749
fascinating example of how if you weren't looking

0:40:39.390,0:40:41.390
at your data carefully

0:40:41.820,0:40:43.820
You you end up

0:40:43.830,0:40:47.809
With something that doesn't at all actually solve the problem you want to solve?

0:40:53.100,0:40:55.100
This is tricky right because

0:40:56.330,0:41:03.019
The data that you train your algorithm on if you're building like a new product that didn't exist before by definition

0:41:03.020,0:41:07.939
You don't have examples of the kind of data that's going to be used in real life, right?

0:41:07.940,0:41:14.780
So you kind of try to find some from somewhere and if there and if you do that throw it through like a Google search

0:41:15.450,0:41:17.540
Pretty likely you're not going to end up with

0:41:18.300,0:41:22.160
A set of data that actually reflects the kind of mix you would see in real life

0:41:25.599,0:41:27.599
So

0:41:29.450,0:41:33.919
You know the main thing here is to say be careful right and and in particular for your test set

0:41:33.920,0:41:35.990
You know that final set that you check on

0:41:36.839,0:41:39.289
really try hard to gather data that

0:41:39.810,0:41:45.019
reflects the real world so that Gus, you know, for example for the healthy skin example

0:41:45.150,0:41:51.500
You might go and actually talk to a dermatologist and try and find like ten examples of healthy and unhealthy skin or something

0:41:52.410,0:41:54.920
And that would be your kind of gold standard test

0:41:56.420,0:41:58.420
Um

0:41:58.790,0:42:03.849
There's all kinds of issues you have to think about in deployment I can't cover all of them

0:42:04.099,0:42:10.119
I can tell you that this O'Reilly book called building machine learning powered applications

0:42:10.820,0:42:13.570
Is is a great resource?

0:42:14.599,0:42:18.219
And this is one of the reasons we don't go into detail about

0:42:19.609,0:42:23.889
AP to a B testing and when should we refresh our data and we

0:42:24.320,0:42:28.539
monitor things and so forth is because that books already been written so we don't want to

0:42:29.180,0:42:31.180
Rewrite it

0:42:33.550,0:42:37.989
I do want to mention a particular area that I care a lot about though

0:42:40.140,0:42:42.060
Which is

0:42:42.060,0:42:43.860
Let's take this example

0:42:43.860,0:42:49.370
Let's say you're rolling out this bear detection system and it's going to be attached to video cameras around a campsite

0:42:49.680,0:42:57.200
It's going to warn campers of incoming bears. So if we used to model that was trained with that data that we just looked at

0:42:58.140,0:43:00.140
You know, those are all

0:43:00.330,0:43:04.580
Very nicely taken pictures of pretty perfect bears, right?

0:43:05.940,0:43:07.470
There's really no relationship

0:43:07.470,0:43:11.240
To the kinds of pictures. You're actually going to have to be dealing with in your in your

0:43:11.820,0:43:18.499
Campsite bear detector, which has it's going to have video and not images. It's going to be nighttime. There's going to be probably low resolution

0:43:19.110,0:43:21.110
security cameras

0:43:21.420,0:43:27.409
You need to make sure that the performance of the system is fast enough to tell you about it before the bear kills you

0:43:29.010,0:43:34.249
You know, there will be bears that are partially obscured by bushes or in lots of shadow or whatever

0:43:34.380,0:43:38.059
None of which are the kinds of things you would see normally in like internet pictures

0:43:39.420,0:43:45.620
So what we call this we call this out of domain data out of domain data refers to a situation where?

0:43:46.140,0:43:50.840
The data that you are trying to do inference on is in some way different

0:43:51.330,0:43:54.709
To the kind of data that you trained with

0:43:56.549,0:44:02.758
This is actually um, there's no perfect way to answer this question and when we look at

0:44:05.140,0:44:07.559
Really helpful ways to to

0:44:08.650,0:44:14.879
minimize how much this happens for example, it turns out that having a diverse team is a great way to

0:44:15.910,0:44:20.759
Kind of avoid being surprised by the kinds of data that people end up coming up with

0:44:22.359,0:44:26.338
But really is just something you've got to be super thoughtful about

0:44:28.690,0:44:30.810
Very similar to that is something called

0:44:31.030,0:44:38.249
The main shift and the main shift is where maybe you start out with all of your data is in domain data, but over time

0:44:38.770,0:44:40.770
The kinds of data that you're seeing

0:44:41.290,0:44:43.739
changes and so over time maybe

0:44:44.680,0:44:48.000
raccoons start invading your campsite and you

0:44:48.610,0:44:51.569
Weren't training on recurrence before it was just a bear detector

0:44:51.570,0:44:57.149
And so that's court domain shift and that's another thing that you have to be very careful of great choice or question

0:44:57.970,0:45:00.300
No, I was just gonna add to that in saying that

0:45:01.000,0:45:06.570
All data is biased so there's not kind of a, you know, a form of de bias data

0:45:07.600,0:45:12.059
Perfectly representative in all cases data and that a lot of the proposals around

0:45:12.250,0:45:17.790
Addressing this have kind of been converging to this idea and that you see in papers like Tim net get bruised

0:45:18.220,0:45:22.800
data sheets for datasets of just writing down a lot of the

0:45:23.710,0:45:30.000
Details about your data set and how it was gathered and in which situations it's appropriate to use and how it was maintained

0:45:30.000,0:45:34.500
And so there that's not that you've totally eliminated bias

0:45:34.500,0:45:40.050
but that you're just very aware of the attributes of your data set so that you won't be blindsided by them later and

0:45:40.450,0:45:47.790
there have been kind of several proposals in that school of thought which I which I really like around this idea of just kind of

0:45:48.850,0:45:51.959
Understanding how your data was gathered and what its limitations are

0:45:53.920,0:45:55.920
Thanks, Rachel

0:45:56.320,0:46:03.719
So a key problem here is that you can't know the entire behavior of your neural network

0:46:05.290,0:46:10.439
With normal programming you typed in the if statements and the loops and whatever

0:46:10.440,0:46:12.510
So in theory, you know, what the hell it does

0:46:12.580,0:46:17.429
Although it still sometimes surprising in this case you you didn't tell it anything. You just gave it

0:46:18.010,0:46:21.600
Examples alone from and hope that it learned something useful

0:46:21.760,0:46:25.979
There are hundreds of millions of parameters in all of these neural networks

0:46:25.980,0:46:31.320
And so there's no way you can understand how they all combine with each other to create complex behavior

0:46:31.630,0:46:35.820
so really like there's a natural compromise here is that we're trying to

0:46:38.099,0:46:41.479
Sophisticated behavior so stuff like like recognizing

0:46:42.450,0:46:43.799
pictures

0:46:43.799,0:46:45.799
Sophisticated enough behavior. We can't describe it

0:46:46.440,0:46:52.879
And so the natural downside is you can't expect the process that the thing is using to do that to be describable

0:46:53.280,0:46:55.280
View for you to be able to understand it. So

0:46:56.549,0:47:00.799
Our recommendation for kind of dealing with these issues is a very careful

0:47:01.650,0:47:05.839
Deployment strategy which I've summarized in this little graph this little chart here

0:47:07.200,0:47:08.880
the idea would be

0:47:08.880,0:47:10.319
first of all

0:47:10.319,0:47:16.609
Whatever it is that you're going to use the model for start out by doing it manually. So have a park ranger

0:47:17.339,0:47:19.339
watching for bears

0:47:19.740,0:47:24.349
Have the model running next to them and each time the park ranger sees a bear

0:47:24.480,0:47:29.839
They can check the morale and see like did it see into a pick it up? So the models not doing anything

0:47:30.210,0:47:35.089
There's just a person who's like running it and seeing would it have made sensible choices?

0:47:36.240,0:47:40.879
And once you're confident that it makes sense that what it's doing seems reasonable in

0:47:41.460,0:47:45.649
You know as being as close to the real-life situation as possible

0:47:47.599,0:47:52.159
Then deploy it in a time and geography limited way

0:47:52.160,0:47:57.379
so pick like one campsite not the entirety of California and do it for

0:47:57.900,0:48:00.019
you know one day and

0:48:00.720,0:48:08.299
Have somebody watching its super carefully, right? So now the basic bear detection is being done by the Baudette bear detector

0:48:08.299,0:48:13.399
But there's still somebody watching it pretty closely and it's only happening in one campsite for one day

0:48:13.400,0:48:15.440
And so then as you say like, okay

0:48:16.410,0:48:18.410
we haven't

0:48:18.720,0:48:20.720
Right our company yet

0:48:20.980,0:48:25.590
Campsites for a week and then let's do you know the entirety of Marin for a month and

0:48:26.200,0:48:29.189
so forth, so this is actually what we did when I

0:48:29.770,0:48:31.300
used to

0:48:31.300,0:48:33.359
Be at this company called optimal decisions

0:48:34.480,0:48:38.310
optimal decisions was a company that I found it to do insurance pricing and

0:48:38.619,0:48:46.409
If you if you change insurance prices by, you know, a percent or two in the wrong direction in the wrong way

0:48:47.140,0:48:53.340
You can basically destroy the whole company. Um, this has happened many times, you know insurers are companies

0:48:53.980,0:48:57.810
That set prices that's basically the product that they provide

0:48:58.359,0:49:04.979
So when we deployed new prices for optimal decisions, we always did it by like saying like, okay

0:49:04.980,0:49:08.070
we're going to do it for like five minutes or

0:49:08.590,0:49:12.779
Everybody whose name ends with a D, you know, so we kind of try to find some

0:49:13.900,0:49:17.010
Group, which hopefully would be fairly, you know

0:49:17.349,0:49:18.520
It would all be different

0:49:18.520,0:49:23.550
but not too many of them and would gradually scale it up and you've got to make sure that when you're doing this that you

0:49:23.550,0:49:25.550
have a lot of

0:49:25.670,0:49:28.749
Really good reporting systems in place that you can recognize

0:49:29.930,0:49:33.909
Are your customers yelling at you? Are your computers burning up?

0:49:35.210,0:49:37.210
you know are your

0:49:38.900,0:49:46.119
Are your computers burning up are your costs spiraling out of control and so forth so it really requires

0:49:47.030,0:49:49.030
Great

0:49:49.130,0:49:51.130
Reporting systems

0:49:52.130,0:50:00.130
This fast AI have methods built-in that provide for incremental learning ie improving the model slowly over time with a single data point each time

0:50:01.520,0:50:03.520
Yeah, that's a great question. So

0:50:04.190,0:50:07.029
this is a little bit different which is this is really about

0:50:08.000,0:50:14.890
Dealing with domain shift and similar issues by continuing to train your model as you do inference. And so the good news is

0:50:15.740,0:50:17.800
You don't need anything special for that

0:50:18.770,0:50:21.729
It's basically just a transfer learning problem. So

0:50:22.310,0:50:27.279
You can do this in many different ways. Probably the easiest is just to say like okay each night

0:50:28.640,0:50:32.019
probably the easiest is just to say ok each night you

0:50:33.110,0:50:34.670
Know at midnight

0:50:34.670,0:50:36.130
We're going to set off a task

0:50:36.130,0:50:43.029
Which grabs all of the previous day's transactions as many batches and trains another epoch

0:50:43.970,0:50:45.530
and

0:50:45.530,0:50:50.290
So yeah, that that actually works fine. You can basically think of this as a

0:50:51.140,0:50:58.119
Fine tuning approach where you're pre trained model is yesterday's model and you're fine-tuning data is today's data

0:50:59.840,0:51:03.159
So as you roll out your model

0:51:04.580,0:51:11.409
One thing to be thinking about super carefully is that it might change the behavior of the system that it's a part of

0:51:11.930,0:51:18.130
And this can create something called a feedback loop and feedback. Loops are one of the most challenging things for

0:51:19.430,0:51:22.840
for real world model deployment particularly of machine learning models

0:51:24.290,0:51:26.090
because they can take a

0:51:26.090,0:51:28.090
very minor issue and

0:51:28.460,0:51:30.460
Explode it into a really

0:51:31.130,0:51:32.630
big issue

0:51:32.630,0:51:35.140
so for example, think about a

0:51:36.050,0:51:38.050
predictive policing algorithm

0:51:38.480,0:51:41.140
It's an algorithm that was trained to recognize

0:51:43.400,0:51:48.010
You know basically trained on data that says whereabouts or arrests being made

0:51:48.860,0:51:54.249
And then as you train that algorithm based on where arrests are being made

0:51:55.940,0:52:02.890
Then you put in place a system that sends police officers to places that the model says

0:52:03.200,0:52:09.520
Are likely to have crime which in this case? Where were were there? Where were arrests?

0:52:10.800,0:52:12.800
Well, then more police go to that place

0:52:13.960,0:52:19.260
Find more crime because the more police that are there the more they'll see they arrest more people

0:52:20.020,0:52:23.880
Causing you know, and then if you do this incremental learning like we're just talking about that

0:52:23.880,0:52:28.589
It's going to say oh there's actually even more crime here. And so tomorrow it sends even more police

0:52:29.410,0:52:36.149
And so in that situation you end up like the predictive policing algorithm ends up kind of sending all of your police

0:52:36.730,0:52:38.560
or one street block

0:52:38.560,0:52:44.640
Because at that point all of the arrests are happening there because that's the only place you have policemen and I should say police officers

0:52:46.030,0:52:48.209
so there's actually a paper about

0:52:49.300,0:52:57.029
This issue called to protect and serve and in to protect and serve the author's right this really nice phrase

0:52:57.430,0:53:02.880
Predictive policing is aptly named it is predicting policing not predicting

0:53:03.490,0:53:05.490
crime so

0:53:05.770,0:53:07.770
if the initial model was

0:53:08.910,0:53:13.969
Perfect, whatever the hell that even means but like it's somehow sent police to exactly

0:53:14.729,0:53:20.989
The best places to find crime based on the probability of crimes actually being in place

0:53:23.150,0:53:25.150
I guess there's no problem, right?

0:53:26.670,0:53:29.059
But as soon as there's any amount of

0:53:29.760,0:53:32.719
Bias, right. So for example in the US

0:53:33.690,0:53:35.690
There's a lot more arrests

0:53:36.870,0:53:43.880
Of black people than of white people even for crimes where black people and white people are known to do than the same amount

0:53:45.100,0:53:47.100
So in the presence of this bias

0:53:47.270,0:53:49.270
or any kind of bias

0:53:49.880,0:53:57.190
You're kind of like setting off this domino chain of feedback loops where that bias will be

0:53:57.830,0:53:59.750
exploded

0:53:59.750,0:54:01.750
over time

0:54:02.360,0:54:03.590
So

0:54:03.590,0:54:08.350
You know one thing I like to think about is to think like well what would happen if this?

0:54:09.410,0:54:12.729
If this model was just really really really good

0:54:13.920,0:54:15.920
They were like who would be impacted?

0:54:16.020,0:54:23.430
You know, what would this extreme result look like how would you know what was really happening this incredibly predictive algorithm. That was like

0:54:24.010,0:54:30.119
Changing the behavior of yours if you're police officers or whatever, you know, what would that look like? What would actually happen?

0:54:32.230,0:54:36.000
And then like think about like, okay what could go wrong

0:54:36.000,0:54:40.289
And then what kind of rollout plan what kind of monitoring systems what kind of oversight?

0:54:41.050,0:54:48.840
Could provide the circuit breaker because that's what we really need here right is we need like nothing's going to be perfect. You can't

0:54:49.600,0:54:51.690
Be sure that there's no feedback. Loops

0:54:52.330,0:54:59.010
but what you can do is try to be sure that you see when the behavior of your system is behaving in a way that's

0:54:59.560,0:55:01.560
Not what you want

0:55:01.750,0:55:03.809
Did you have anything to add to that Rachel I?

0:55:06.010,0:55:10.229
Would add to that is that you're at risk of potentially having a feedback loop

0:55:10.600,0:55:17.279
Anytime that your model is kind of controlling what your next round of data looks like and I think that's true for pretty much all

0:55:17.410,0:55:19.410
products and that can be a

0:55:20.200,0:55:23.399
hard jump from people people coming from kind of a science background

0:55:23.470,0:55:28.139
Where you may be thinking of data as I have just observed some sort of experiment

0:55:28.480,0:55:30.480
Where is kind of whenever you're you know?

0:55:30.480,0:55:32.480
Building something that interacts with the real world

0:55:32.590,0:55:38.279
You are now also controlling what your future data looks like based on kind of behavior of your algorithm

0:55:38.410,0:55:40.410
For the current current round of data

0:55:41.380,0:55:43.380
right, so

0:55:43.720,0:55:45.670
So given that

0:55:45.670,0:55:47.819
You probably can't avoid feedback. Loops

0:55:48.850,0:55:52.589
the you know, the the thing you need to then really invest in is

0:55:53.110,0:55:56.700
the human in the loop, and so a lot of people like to focus on

0:55:57.340,0:56:03.329
Automating things which I find weird, you know, if you can decrease the amount of human involvement by like 90 percent

0:56:03.760,0:56:09.299
you've got almost all of the economic upside of automating it completely but you still have the room to put

0:56:09.460,0:56:12.389
Human circuit breakers in place. You need these appeals processes

0:56:12.400,0:56:19.440
You need the monitoring you need, you know humans involved to kind of go. Hey, that's that's weird

0:56:19.440,0:56:21.440
I don't think that's what we want

0:56:22.000,0:56:23.630
Okay

0:56:23.630,0:56:30.040
Yes, Rachel and just one more note about that those humans though. Do need to be integrated well with

0:56:30.680,0:56:36.909
Kind of product and engineering and so one issue that comes up is that in many companies? I think that

0:56:37.430,0:56:42.520
Ends up kind of being underneath trust and safety handles a lot of sort of issues with how things can go wrong

0:56:42.650,0:56:45.010
Or how your platform can be abused?

0:56:45.380,0:56:49.210
and often trust and safety is pretty siloed away from

0:56:49.400,0:56:55.240
Product and edge which actually kind of has the the control over, you know these decisions that really end up influencing them

0:56:55.240,0:56:56.900
and so that they the

0:56:56.900,0:57:02.170
Engineers probably considered them to be pretty pretty annoying a lot of the time how they get in the way and get in the way

0:57:02.170,0:57:07.300
Of them getting software out the door. Yeah, but like the kind of the more integration you can have between those

0:57:07.300,0:57:10.840
I think it's helpful for the kind of the people building the product to see

0:57:11.060,0:57:15.219
What is going wrong and what can go wrong if the engineers are actually on top of that?

0:57:15.220,0:57:20.470
They're actually seeing these these things happening that it's not some kind of abstract problem anymore

0:57:21.750,0:57:24.629
So, you know at this point now that we've got to the end of chapter 2

0:57:26.560,0:57:31.169
You actually know a lot more than most people about

0:57:32.020,0:57:39.749
about deep learning and actually about some pretty important foundations of machine learning more generally and if data products more generally

0:57:40.570,0:57:42.570
So there's a great time to think about

0:57:43.000,0:57:45.000
writing

0:57:45.640,0:57:47.640
So

0:57:48.540,0:57:50.460
Sometimes we have

0:57:50.460,0:57:56.869
Formatted text that doesn't quite format correctly interpret a notebook by the way, it only formats correctly in in the book book

0:57:56.869,0:58:00.108
So that's what it means when you see this kind of pre formatted text

0:58:03.450,0:58:05.450
So

0:58:05.760,0:58:08.399
The the idea here is to think about

0:58:10.090,0:58:16.619
Starting writing at this point before you go too much further Rachel

0:58:18.460,0:58:20.970
There's a question, okay, let's hit the question

0:58:21.910,0:58:28.800
Question is I am I assume there are fast day. I type ways of keeping a nightly updated transfer learning setup

0:58:29.080,0:58:35.340
Well, could there be one of the fasting for notebooks have an example of the nightly transfer learning training?

0:58:36.400,0:58:41.369
Like the previous person asks, I would be interested in knowing how to do that. Most effectively with fast AI

0:58:42.100,0:58:46.739
Sure, so I guess my view is there's nothing faster you guys specific about that at all?

0:58:47.290,0:58:53.159
So I actually suggest you read a manuals book that book. I showed you to understand the kind of the ideas

0:58:54.130,0:58:58.500
And if people are interested in this I can also point you with some academic research about this as well

0:58:58.500,0:59:00.869
And there's not as much as that there should be

0:59:01.450,0:59:03.750
But there is some there is some good work in this area

0:59:06.640,0:59:08.640
Okay, so

0:59:09.280,0:59:13.620
the reason we mentioned writing at this point in our journey is because

0:59:15.569,0:59:20.159
You know things are going to start to get more and more heavy more and more complicated and

0:59:20.619,0:59:25.439
A really good way to make sure that you're on top of it is to try to write down what you've learned

0:59:28.640,0:59:34.819
Sharing the right part of the screen before but this is what I was describing in terms of the pre-formatted text, which doesn't look correct

0:59:37.110,0:59:39.110
So

0:59:39.660,0:59:41.660
When so

0:59:42.780,0:59:48.470
Rachel actually has this great article that you should check out which is why you should blog and

0:59:49.170,0:59:50.550
I

0:59:50.550,0:59:54.140
Will say it's sort of her saying cuz I have it in front of me and she doesn't

0:59:54.840,0:59:56.960
weird as it is so rachel says

0:59:58.080,1:00:02.120
That the top advice she would give her younger self is to start blogging sooner

1:00:02.370,1:00:07.549
So rachel has a math PhD in this kind of idea of like blogging was not exactly something

1:00:07.550,1:00:10.850
I think they had a lot of in the ph.d program

1:00:11.790,1:00:15.170
But actually it's like it's a really great way of

1:00:16.320,1:00:22.400
Finding jobs. In fact, most of my students who have got the best jobs our students that have

1:00:23.280,1:00:25.280
good blog posts

1:00:25.530,1:00:27.590
The thing I really love is that it helps you learn

1:00:28.230,1:00:31.879
By by writing down. It's kind of synthesizes your ideas

1:00:32.820,1:00:34.820
and

1:00:36.030,1:00:39.620
Yeah, you know, there's lots of reasons to blog so there's actually

1:00:40.680,1:00:43.279
Something really cool. I want to show you. Yeah

1:00:44.250,1:00:49.220
As also just gonna note I have a second post called advice for better blog post

1:00:49.530,1:00:53.600
That's a little bit more advanced which I'll post a link to as well

1:00:53.970,1:00:54.840
and that

1:00:54.840,1:00:56.280
talks about some common pitfalls

1:00:56.280,1:01:02.150
that I've seen in many in many blog posts and kind of the importance of putting putting the time in to do it well and

1:01:02.250,1:01:05.960
And some things to think about so I'll share that post as well. Thanks, Rachel

1:01:06.210,1:01:12.889
um, so one reason that sometimes people don't blog is because it's kind of annoying to figure out how to

1:01:14.250,1:01:17.300
particularly because I think the thing that a lot of you will want to blog about is

1:01:18.180,1:01:20.569
Cool stuff that you're building and Jupiter notebooks. So

1:01:21.690,1:01:29.690
We've actually teamed up with a guy called Hamel sane and and with github to create this

1:01:30.330,1:01:32.070
free product

1:01:32.070,1:01:38.749
As usual with faster ie no ads, no anything called fast pages where you can actually blog

1:01:39.420,1:01:41.420
with Jupiter notebooks

1:01:42.210,1:01:43.270
So

1:01:43.270,1:01:46.199
You can go to fuss pages and see for yourself how to do it

1:01:46.200,1:01:50.639
But the basic idea is that like you literally click one button

1:01:52.500,1:01:55.649
Sets up a plug for you and then you dump your

1:01:56.590,1:01:57.790
notebooks

1:01:57.790,1:02:02.310
Into a folder called underscore notebooks and they get turned into

1:02:03.160,1:02:09.240
blog posts it's it's basically like magic and Hamill's done this amazing job of this and so

1:02:11.260,1:02:14.100
This means that you can create blog posts where you've got

1:02:14.680,1:02:21.840
Charts and tables and images, you know where they're all actually the output of you put a notebook

1:02:22.390,1:02:24.390
along with all the the markdown

1:02:24.970,1:02:27.720
formatted text headings and so forth and

1:02:28.330,1:02:36.029
Hyperlinks and the whole thing. So this is a great way to start writing about what you're learning about here

1:02:38.410,1:02:44.129
Something that Rachel and I both feel strongly about when it comes to blogging is this which is

1:02:47.150,1:02:54.319
Don't try to think about the absolute most advanced thing, you know and try to write a blog post that would impress

1:02:54.990,1:02:56.370
geoff hinton

1:02:56.370,1:02:58.789
Right because most people are not geoff hinton

1:02:58.980,1:03:02.959
so like a you probably won't do a good job because you're trying to like

1:03:03.420,1:03:06.680
log for somebody who's more got more expertise than you and

1:03:07.290,1:03:08.670
be

1:03:08.670,1:03:11.270
You've got a small audience now, right?

1:03:11.300,1:03:17.810
Actually, there's far more people that are not very familiar with deep learning than people who are so try to think, you know

1:03:17.810,1:03:19.810
And and you really understand what it's like

1:03:20.340,1:03:24.559
What it was like six months ago to be you because you were there six months ago

1:03:24.560,1:03:30.350
So try and write something which the six months ago version of you would have been like super

1:03:30.660,1:03:35.809
Interesting full of little tidbits. You would have loved you know that you would that would have delighted you

1:03:36.630,1:03:39.289
that six months ago version of you

1:03:40.680,1:03:48.349
Okay. So once again don't move on until you've had a go at the questionnaire to make sure that you

1:03:50.100,1:03:53.660
You know understand the key things we think that you need to understand

1:03:54.300,1:04:01.519
And yeah have a think about these further research questions as well because they might help you to engage more closely with material

1:04:02.460,1:04:05.000
So let's have a break and we'll come back in

1:04:05.910,1:04:07.910
five minutes time

1:04:10.530,1:04:12.530
では、再開しましょう。

1:04:13.589,1:04:15.589
ここからが、

1:04:16.240,1:04:19.990
このコースの中で面白いパートです。というのも、

1:04:20.840,1:04:25.989
今まではずっと

1:04:27.329,1:04:32.879
私たちが機械学習でやろうとしていること、

1:04:32.890,1:04:35.699
機械学習を機能させる上で必要なピースや知識

1:04:37.260,1:04:44.790
について、ほぼ数学は使わずごくわずかのコードで説明してきました。

1:04:47.130,1:04:50.849
初めにこういった説明を行なったのは、

1:04:51.790,1:04:56.009
機械学習やそれに関する問題を理解したい人たちもターゲットにしているからです。

1:04:57.460,1:04:59.460
中には機械学習にでてくる

1:05:00.010,1:05:06.060
数式やコードに深入りすることなく理解したい人もいるでしょう。

1:05:07.330,1:05:09.330
もし今から話すことに

1:05:09.610,1:05:11.520
興味がなければ

1:05:11.520,1:05:18.270
倫理について話す次回のレッスンに進んだ方が良いかもしれません。次回は

1:05:19.570,1:05:22.080
あまり技術的ではないものになります。

1:05:25.460,1:05:27.880
今から見ていくのは

1:05:29.500,1:05:31.500
非常に単純な問題ですが

1:05:32.530,1:05:34.060


1:05:34.060,1:05:37.289
ほんの数年前までは困難と思われていたものです。

1:05:38.050,1:05:41.039
それは手書き数字認識です。

1:05:42.400,1:05:44.400
そして、私たちはこれから

1:05:44.510,1:05:46.039
スクラッチで解いていきます。

1:05:46.039,1:05:48.879
そのために色々な解法を見ていきます。

1:05:50.059,1:05:52.749
では、今からデータセットを見ます。

1:05:53.510,1:06:00.789
MNISTというデータセットですが、機械学習に触れたことがあれば使ったことがあるでしょう。

1:06:01.520,1:06:05.859
これは手書き数字の機械学習データセットでYann Lecunとその同僚が

1:06:06.589,1:06:10.899
作成し、彼らの提案手法を検証するのに使いました。

1:06:10.900,1:06:14.349
その方法はおそらく最初の非常に実用的で有用な計算機システムで、

1:06:14.779,1:06:20.679
さらにスケールするものであり、LeNetと呼ばれました。そして実際に

1:06:21.380,1:06:25.809
アメリカ合衆国で使われる小切手の1割を処理するのに使われました。

1:06:29.900,1:06:36.279
さて、新しいモデルを作るときに大事なのは非常に単純なものから始め、

1:06:36.559,1:06:38.559
徐々に複雑にしていくことです。

1:06:39.589,1:06:45.038
MNIST sampleというMNISTより簡単なものを用意してあります。3と7のみが含まれるデータセットです。

1:06:45.739,1:06:50.139
今回はこのMNIST sampleから始めましょう。

1:06:50.319,1:06:53.409
3と7は見た目がかなり違うので単純な問題です。

1:06:53.569,1:06:57.399
もしこの問題ができなければ手書き数字認識はできないと思います。

1:06:59.859,1:07:01.630
さて、

1:07:01.630,1:07:06.039
第一ステップはuntar_dataです。untar_dataはfastaiの

1:07:07.819,1:07:09.819
関数でURLを引数にとり、

1:07:11.480,1:07:17.379
ダウンロード済みか確認し、そうでなければダウンロード、その次に解凍済みか確認し、

1:07:17.380,1:07:22.089
もしまだなら解凍し、データセットのパスを返します。

1:07:22.609,1:07:24.609
ここに

1:07:27.200,1:07:34.210
URLs.MNIST_SAMPLEとありますね、tabを押すと自動補完がききます。

1:07:37.140,1:07:42.930
これは場所を表していて、どこにあるかはさほど重要ではありません。そして

1:07:45.460,1:07:51.580
私はすでにダウンロード・解凍済みなので非常にスムーズです。

1:07:52.190,1:07:54.280
そしてこのpathは

1:07:55.520,1:08:03.280
データがどこにあるかを示していて、今は”.”ですがこれはPath.BASE_PATHを

1:08:03.530,1:08:04.910
pathに設定することで

1:08:04.910,1:08:06.910
私が作業するパスの

1:08:07.790,1:08:11.169
開始地点を変えているからです。そして、

1:08:11.170,1:08:16.299
path.lsはそのパスにあるファイルを列挙します。そして、

1:08:17.180,1:08:22.209
列挙されたパスは解凍した場所からの相対パスなので非常に便利です。

1:08:22.880,1:08:24.910


1:08:28.500,1:08:30.500


1:08:30.759,1:08:34.589
さて、pathは、、、

1:08:35.979,1:08:41.639
pathの型はなんでしょう。実はPathlibのPathオブジェクトです。

1:08:44.229,1:08:50.819
Pathlibは標準ライブラリで大変素晴らしいのですが、lsは実装されていません。

1:08:52.059,1:08:56.458
非常に便利ですが、本当に使いたいものがなかったので、

1:08:56.459,1:08:59.429
実際にlsメソッドを追加しました。

1:09:00.009,1:09:02.009


1:09:05.639,1:09:08.059
もし、実装が気になったら、

1:09:08.759,1:09:11.209
すでに伝えてありますが、いくつか確認する方法があります。

1:09:11.210,1:09:15.290
?を付け加えれば、どこで実装されているかわかります。

1:09:15.290,1:09:22.849
fast coreにありますね。fast coreはfastaiの基本的なものが実装されていますが、

1:09:23.819,1:09:25.650
とくにPyTorchや

1:09:25.650,1:09:28.009
pandasなどの大規模なライブラリに依存していないものが含まれます。

1:09:29.940,1:09:34.549
実際に何をしているか知りたければ

1:09:34.549,1:09:36.549
?をもう1つ加えると

1:09:36.989,1:09:38.989


1:09:39.000,1:09:45.990
ソースコードが確認できますし、忘れないで欲しいのは、

1:09:47.720,1:09:49.720
doc関数です。

1:09:51.179,1:09:57.929
doc関数は実際のドキュメントへのリンクを表示し、そこにジャンプすれば

1:09:59.199,1:10:03.029
例やチュートリアルなども確認できます。

1:10:06.750,1:10:07.980


1:10:07.980,1:10:14.180
新しいデータセットを使う時はls関数で何が入っているか確認することをお勧めします。

1:10:14.990,1:10:20.240
そして、trainとvalidフォルダーがあります。非常に一般的なつくりです。

1:10:20.580,1:10:24.799
trainフォルダーをを見てみましょう。

1:10:25.320,1:10:28.700
7と3という名前のフォルダがありますね。

1:10:29.040,1:10:33.560
この構成は熊のデータセットとそっくりですね。

1:10:33.560,1:10:38.629
画像をそのラベルに対応するフォルダにダウンロードしています。

1:10:39.450,1:10:41.450
また、このラベルによる分類の前に

1:10:42.060,1:10:48.410
まず学習データかバリデーションかという分類が行われています。

1:10:49.170,1:10:53.960
画像のデータセットではこのフォルダ構成が一般的です。

1:10:57.290,1:10:59.290
ではどんな画像があるか見るために

1:10:59.700,1:11:03.859
threesというリストを用意して

1:11:04.410,1:11:09.349
3の学習データファイルを列挙し、並び替えます。

1:11:09.960,1:11:13.730
7についても同じことをし、3のデータを見てみましょう。

1:11:14.340,1:11:19.130
さて、threesから1つ選び、

1:11:20.790,1:11:28.009
ファイルを開いて描画してみましょう。3の画像ですね、実際にはなんでしょう？

1:11:31.000,1:11:34.089
im3の型は

1:11:35.570,1:11:42.399
PILで、これはPythonの画像ライブラリで、最も一般的なものです。

1:11:43.550,1:11:45.579
そしてPNGですね。

1:11:46.490,1:11:48.490
一般的ですね。

1:11:49.190,1:11:51.790
Jupyter Notebookは

1:11:53.780,1:11:55.340
様々なものを

1:11:55.340,1:11:59.980
描画する方法を知っていて、自分で型を作った場合にはPILにその描画方法を教えられます。

1:12:00.010,1:12:04.959
PILは一般的な型の描画方法を知っているので、このような画像を出力します。

1:12:05.990,1:12:11.019
しかし、今はこの画像が数字でどう表されるかを見ます。

1:12:11.660,1:12:16.599
画像を数字で扱う簡単な方法は、arrayに変換することです。

1:12:16.880,1:12:20.950
The array is part of numpy which is the most popular
arrayはnumpyの要素で、numpyは広く使われている

1:12:21.470,1:12:22.580
配列

1:12:22.580,1:12:24.350
プログラミングライブラリです。

1:12:24.350,1:12:27.100
もし、

1:12:28.670,1:12:29.750
PILの

1:12:29.750,1:12:31.750
image object to array
画像オブジェクトをarrayに渡すと

1:12:32.000,1:12:35.589
画像が多数の数値に変換されます。

1:12:35.590,1:12:40.810
実は画像もともと数字なのです。ディスクに保存された大量の数値です。

1:12:41.000,1:12:48.129
マジックのようなものがあり、Jupyterが描画できるだけなのですが、

1:12:48.770,1:12:50.720
arrayがPILオブジェクトをnumpy.arrayに変えていると表現しました。

1:12:50.720,1:12:56.050
numpy.arrayに変えると先ほどのように描画されなくなります。

1:12:56.240,1:12:59.530
so once I do this we can then index into that array and
一度numpy.arrayにすれば、要素へのアクセスが可能になり、

1:13:00.050,1:13:02.949
4から9行目の全要素を取得したり、

1:13:03.080,1:13:10.390
また、4から9列目の全要素を取得することもできます。ここにいくつかの数値がありますが、

1:13:11.000,1:13:12.890
これらは

1:13:12.890,1:13:14.090
8ビットの整数値で、

1:13:14.090,1:13:21.970
0から255を取り得るものです。計算機上の全ての画像は大量の数字であり、

1:13:22.520,1:13:24.350
だからこそ、それを使って

1:13:24.350,1:13:26.350
計算することができるのです。

1:13:26.880,1:13:31.909
要素のアクセス等は、arrayではなくtensorでもできます。tensorは

1:13:32.699,1:13:37.158
numpy.arrayのPyTorch版と言えるものです。

1:13:37.889,1:13:41.479
ですから、コードは上とほぼ同じ見た目をしています。

1:13:41.699,1:13:47.959
arrayをtensorに書き換えただけで全く同じことをしています。

1:13:47.960,1:13:53.899
PyTorchのtensorとnumpyのarrayがほぼ同じように動作することが

1:13:54.900,1:13:56.900
わかりますね。

1:13:57.210,1:14:02.330
一部例外はありますが、大事なことはPyTorchのtensorは

1:14:03.449,1:14:05.569
GPU上でも動くことです。

1:14:05.940,1:14:07.320


1:14:07.320,1:14:12.049
この講義と本では、

1:14:12.449,1:14:17.299
numpy.arrayではなく、PyTorchのtensorを使うようにしています。

1:14:17.520,1:14:23.209
というのも、numpy.arrayとGPU計算のメリットを使うことができる上に、

1:14:23.639,1:14:26.539
numpyにはない機能も多く取り揃えているからです。

1:14:27.990,1:14:29.990
Pythonを書いた経験がある

1:14:31.690,1:14:33.690
多くの人は常に

1:14:33.850,1:14:39.870
みなさんがPyTorchのTensorを使いたいと思うようにNumPyに飛びつきますが、

1:14:40.570,1:14:46.860
それはtensorやarrayを使うようにすることで多くのことが

1:14:46.860,1:14:48.860
簡単に、そして高速に行えるからです。

1:14:50.280,1:14:52.280
さて

1:14:52.449,1:14:58.379
先ほどの3の画像をtensorにしましょう。

1:14:58.380,1:15:02.699
im3_tがim3のtensorです。im3_tの一部を取り出し

1:15:03.280,1:15:09.210
pandas.DataFrameにしましょう。理由は

1:15:09.210,1:15:15.779
background gradientが非常に便利だからです。

1:15:16.000,1:15:21.329
3の画像の上の方が描画されていて、0が白、

1:15:22.000,1:15:27.779
255に近い数字が黒、中間の値が灰色です。

1:15:28.630,1:15:32.909
この描画で、

1:15:34.119,1:15:38.939
画像、数値の集合がスクリーンでどう描画されるかわかりますね。

1:15:40.679,1:15:48.538
実際の画像のごく一部を見せていますが、MNISTの画像は28x28、つまり768ピクセルです。

1:15:49.150,1:15:50.559


1:15:50.559,1:15:57.479
非常に小さいですね。例えば私の携帯電話が何メガピクセルか知りませんが何百万ピクセルです。

1:15:57.480,1:15:59.909
シンプルで小さいものから始めるのは大事です。

1:16:01.499,1:16:02.650


1:16:02.650,1:16:10.529
モデルを作るのが目標ですが、モデルはデータから学習した何かしらの計算プログラムで、

1:16:11.889,1:16:16.589
3と7を認識できるものです。3検知器と捉えても良いでしょう、なぜなら

1:16:16.590,1:16:18.809
3じゃなければ7と言えるのです。

1:16:20.110,1:16:24.089
ではここでビデオを一時停止して、

1:16:25.179,1:16:26.440
あなたならどうするかを考えてみてください。

1:16:26.440,1:16:30.089
How would you like you don't need to know anything about neural networks, or?
ニューラルネットワークについて知る必要なくするにはどうするでしょうか？

1:16:30.519,1:16:34.679
あるいは常識を使って3検出器を作るには

1:16:35.289,1:16:37.059
どうしますか？

1:16:37.059,1:16:40.919
必要であれば紙とペンを用意してください。

1:16:41.710,1:16:45.539
私の1つ目のアイデアは

1:16:47.079,1:16:49.079
データセットの3の画像

1:16:49.389,1:16:51.389
を全て取り出し、

1:16:51.880,1:16:53.880
各ピクセルの

1:16:54.039,1:16:56.248
平均値を求める

1:16:57.800,1:17:02.120
というものです。

1:17:02.120,1:17:04.189
つまり28x28の

1:17:05.970,1:17:07.170
画像で

1:17:07.170,1:17:11.510
各ピクセルは全部の3画像の平均ですから、理想的な

1:17:11.790,1:17:14.839
3になっています。7についても同じことを行い、

1:17:15.450,1:17:20.569
バリデーションセットに含まれる画像に対して、

1:17:21.270,1:17:27.979
この画像は理想的な3と7のどちらに似ているかに基づいて分類するのです。

1:17:28.980,1:17:33.140
ここではピクセル類似度法とでも呼びましょう。

1:17:33.600,1:17:39.109
これがベースラインです。ベースラインは非常に簡潔なモデルで

1:17:39.110,1:17:43.100
プログラムも簡単に書けるものであるべきです。

1:17:43.100,1:17:46.729
この方法は平均算出を行うだけですから簡単ですし、

1:17:47.790,1:17:52.490
ランダムよりは良くなるでしょう。

1:17:53.280,1:17:55.370
経験豊富な人でもし得る

1:17:55.950,1:18:03.859
大きな誤りの1つはベースラインを作らないというものです。

1:18:04.620,1:18:06.620
彼らは

1:18:09.239,1:18:12.539
ベイズ予測器やニューラルネットワークを作り

1:18:12.540,1:18:18.180
「Jeremy、素晴らしいモデルができました。」と言うのですが、私が「どうして素晴らしいと
わかるのですか？」と問うと、

1:18:18.180,1:18:21.389
「正確度が80%です」と言いますが、私は

1:18:21.700,1:18:25.529
「常に平均を予測に用いるモデルでどうなるか確認しましょう。おや、

1:18:26.110,1:18:28.110
85%ですね」と言えば、

1:18:29.170,1:18:30.340
当然、

1:18:30.340,1:18:34.860
彼らは大変落ち込むのです。なので、必ず、まともなベースラインから始め、

1:18:35.380,1:18:37.830
徐々に大きいものを作るようにしましょう。

1:18:39.040,1:18:41.040
私たちは、

1:18:41.050,1:18:43.050
ピクセルの平均値を計算する必要があります。

1:18:43.870,1:18:45.100

1:18:45.100,1:18:48.359
そのためにPythonのトリックをいくつか紹介します。

1:18:49.150,1:18:52.140
まず必要なのは3と7の画像の

1:18:52.750,1:18:56.430
リストです。

1:18:56.950,1:18:58.950
すでにsevensはありますが

1:19:00.650,1:19:03.230
要素はファイル名でした。

1:19:05.040,1:19:07.729
それぞれに対して、

1:19:07.800,1:19:15.020
Image.openでPILオブジェクトを取得し、tensorに変換しています。

1:19:15.270,1:19:18.199
これはリスト内包と呼ばれるものです。

1:19:18.360,1:19:23.179
これはPythonの中で最も強力かつ便利なものです。

1:19:23.640,1:19:29.299
C#のlinkの下位互換とも言えますし、

1:19:30.659,1:19:35.929
JavaScriptにおける関数型プログラミングのアイデアに似たものでもあります。

1:19:36.270,1:19:39.890
基本的には、この集合の各要素、

1:19:40.409,1:19:44.989
ここではoと呼ばれますが、それがこの関数に渡されます。

1:19:45.480,1:19:50.480
この関数は画像を開いてtensorに変換します。各要素に対応する関数の返り値がリストに格納されます。

1:19:50.480,1:19:52.480
ですから、このリストには

1:19:53.040,1:19:54.540
tensorとしての7の全画像が含まれます。

1:19:54.540,1:19:56.540


1:19:58.630,1:20:02.889
Silvyanと私はリストと辞書の内包を毎日使っています。

1:20:03.409,1:20:07.299
もしまだ慣れていなければ、少し時間をかけて使えるようにすべきです。

1:20:08.690,1:20:16.419
3をあらわすtensorのリストがあるので1つ取り出して

1:20:17.960,1:20:19.960
表示してみましょう。

1:20:20.040,1:20:23.779
tensorであって、PIL Imageオブジェクトではないので

1:20:24.719,1:20:26.719
Jupyterは描画できません。

1:20:28.230,1:20:30.230
ですからここでは

1:20:30.330,1:20:37.640
show_imageコマンドを使います。これはfastaiが提供するtensor描画コマンドです。

1:20:39.770,1:20:44.299
3の平均画像を求める必要があります。

1:20:45.060,1:20:47.060
平均を計算するためにまず、

1:20:47.130,1:20:51.230
tensorのリストをtensorにします。これはリストではなく、

1:20:52.110,1:20:54.140
tensorです。

1:20:55.080,1:20:56.880
今、

1:20:56.880,1:20:59.120
three_tensors[1]

1:21:02.830,1:21:04.490
の形（shape）は

1:21:04.490,1:21:05.630


1:21:05.630,1:21:13.600
(28, 28)です。行の数と列の数です。しかし、three_tensors自体は

1:21:17.609,1:21:19.079
リストです。

1:21:19.079,1:21:22.819
このままだと平均の計算は簡単ではありません。

1:21:22.919,1:21:28.819
そこで、私たちができることと言うと、28x28の画像を積み重ねて

1:21:29.820,1:21:35.149
画像からなる3次元の立方体にすることで、これもtensorです。

1:21:35.149,1:21:41.809
tensorは軸もしくは次元をいくらでも持てます。

1:21:42.570,1:21:45.649
torch.stackはtensorのリストを

1:21:46.379,1:21:48.559
tensorにし、今ここにあるように

1:21:49.109,1:21:51.169
stacked_threesのshapeは

1:21:51.719,1:21:54.378
(6131, 28, 28)です。

1:21:54.959,1:21:58.398
So it's kind of like a cube of height 6 1 31
これは直方体のようなもので、高さが6131、

1:21:59.010,1:22:00.840


1:22:00.840,1:22:02.840
底面が28x28になっています。

1:22:06.510,1:22:09.590
もう1つやりたいことは、平均を計算するために

1:22:10.170,1:22:12.120
このtensorを

1:22:12.120,1:22:13.739
浮動小数点に変換することです。

1:22:13.739,1:22:17.119
なぜなら、整数の丸め込みを避けたいからです。

1:22:18.000,1:22:22.100
もう1つ知っておくべき標準的なことは、

1:22:22.920,1:22:29.239
コンピュータビジョンで浮動小数点を扱う時は値が0から1であるということです。

1:22:29.699,1:22:34.039
なので、ピクセルの最大値である255で割っています。

1:22:34.560,1:22:37.759
ここまでが多くの画像をPyTorchで

1:22:38.610,1:22:41.960
表現するときの非常に標準的な作法です。

1:22:44.849,1:22:51.779
この3つはaxes（軸）と呼ばれ、左から第1軸、第2軸、第3軸です。

1:22:53.380,1:23:00.119
また、軸が3つあるのでランクが3のtensorとも言います。

1:23:01.150,1:23:04.230
これはランク2のtensorだったのです。

1:23:04.869,1:23:06.869
軸が2つなので。

1:23:08.090,1:23:15.279
tensorのランクはshapeの長さでわかります。

1:23:18.940,1:23:20.940
また、

1:23:21.180,1:23:24.300
私は軸（axes）と表現していますが、

1:23:25.090,1:23:27.150
次元と言うこともできます。

1:23:27.930,1:23:34.499
NumPyはaxes、PyTorchはdimを使っていると思います。ランクはまた、

1:23:36.169,1:23:38.169
次元の数でもあるので、ndimで取得できます。

1:23:40.140,1:23:47.209
ランクはtensorの軸あるいは次元の数であることと、

1:23:47.520,1:23:51.080
shapeはtensorの各軸のサイズであることを

1:23:52.820,1:23:54.820
しっかり覚えてください。

1:23:57.380,1:24:04.210
もう、stack_threes.mean()が使えます。stack_threes.mean()は

1:24:08.270,1:24:14.739
全てのピクセルの平均値を返しますが、

1:24:15.110,1:24:17.110
mean(0)とすれば

1:24:17.420,1:24:25.390
この軸に関する平均を計算します。つまり画像の平均です。

1:24:28.880,1:24:32.040
これは28x28です。なぜなら

1:24:32.890,1:24:36.390
6131の軸に関してreductionを行ったからです。

1:24:36.910,1:24:44.459
この軸に関してとった平均は描画することができるので、これが理想的な3、

1:24:46.600,1:24:48.959
こちらが同様にして得られた理想的な7です。

1:24:49.630,1:24:52.170
では、3の画像を1枚持ってきましょう。

1:24:52.780,1:24:56.759
1度描画したものと同じ画像です。

1:24:57.370,1:25:01.109
今から、この画像が理想的に3に近いのか、

1:25:01.360,1:25:07.860
もしくは7に近いのかを計算し、より似ている方をこの画像のラベルと予測します。

1:25:10.900,1:25:15.299
各ピクセルに関して

1:25:16.420,1:25:19.020
画像と理想的なものの差を

1:25:19.020,1:25:23.999
例えば、0、0、1、1、と言ったように、計算して平均をとることはできません。

1:25:24.070,1:25:29.100
その理由は、正の値も負の値もあるのでキャンセルされ、

1:25:29.950,1:25:34.049
0になり得るからです。各ピクセルの差は正の必要があります。

1:25:35.170,1:25:40.649
2つの方法があります。絶対値をとる、つまり

1:25:41.380,1:25:43.380
負の符号を無視し、

1:25:43.750,1:25:46.620
平均を計算する方法です。

1:25:47.440,1:25:51.660
平均絶対誤差やL1ノルムと呼ばれる方法です。

1:25:52.719,1:25:58.169
もう1つは二乗した誤差の

1:25:58.989,1:26:04.979
平均を求め、二乗根を計算する方法で

1:26:05.410,1:26:08.819
二乗平均平方根誤差やL2ノルムと呼ばれます。

1:26:10.930,1:26:14.610
So, let's have a look let's take a three
さて、3の画像を1つとり、

1:26:16.309,1:26:21.799
3の平均を引き、絶対値をとってから平均を計算したものを

1:26:22.800,1:26:24.659
dist_3_absとし、

1:26:24.659,1:26:28.009
すると、

1:26:28.739,1:26:34.788
その値は0.1です。これが平均絶対誤差、L1ノルムです。

1:26:35.369,1:26:39.918
もしL1を知らなければ、不思議なものに感じるかもしれませんが

1:26:40.649,1:26:44.088
必要な数学の用語や式というのはここにあるように

1:26:45.589,1:26:47.589
ごくわずかのコードで表せます。

1:26:48.770,1:26:51.560
ほら、数学的な要素に

1:26:52.080,1:26:54.890
うろたえているよりもコードを

1:26:54.890,1:27:00.079
見る方がどんなことをしているかわかりやすく、これを見て勉強したり

1:27:00.870,1:27:02.870
どう検索するか学べば良いのです。

1:27:03.060,1:27:09.289
こっちは二乗平均平方根誤差です。二乗してから平均をとり、平方根を計算しています。

1:27:11.100,1:27:16.160
これと同じことを理想的な7に対しても行います。

1:27:16.710,1:27:23.029
a3からmean3までの距離は絶対値だと0.1で

1:27:24.030,1:27:28.580
mean7までの距離は0.15です。

1:27:29.670,1:27:33.770
よって、a3はmean3の方が近いので

1:27:33.770,1:27:36.020
私たちはこのa3は

1:27:36.720,1:27:40.549
平均絶対誤差に基づいて3と推測するのです。

1:27:41.310,1:27:45.260
平均二乗誤差についても同様です。つまり、この値とこの値を比較して、

1:27:46.560,1:27:53.089
mean7との誤差が大きいので、3と推測します。

1:27:53.490,1:27:55.490
これは

1:27:56.350,1:28:02.169
機械学習あるいはデータドリブンなモデルのようなもので、3と7を認識しようとしています。

1:28:02.810,1:28:04.810
良いベースラインです。

1:28:05.510,1:28:09.099
妥当なベースラインです。ランダムより良いでしょう。

1:28:10.400,1:28:15.040
実は平均絶対誤差をこうして書き出す必要はありません。

1:28:16.310,1:28:21.550
l1_lossを使えば良いのです。l1_lossは全く同じことをします。

1:28:23.780,1:28:25.989
また、平均二乗誤差も書き出す必要はありません。

1:28:26.630,1:28:31.690
単にmse_lossを使えば良いのですが、デフォルトでは平方根を求めないので、追加しないといけません。

1:28:31.760,1:28:33.760
そして、このように

1:28:34.490,1:28:36.490
同じ数字です。

1:28:38.340,1:28:39.520


1:28:39.520,1:28:44.729
あまり先に進む前に、arrayやtensorの操作に慣れておくのは

1:28:45.460,1:28:49.469
非常に重要です。tensorとarrayはよく似ています。

1:28:50.020,1:28:55.080
リストのリストから始めましょう。行列のようなものです。

1:28:56.640,1:28:58.640
arrayにも

1:28:59.300,1:29:01.300
tensorにも変換できます。

1:29:02.300,1:29:04.300
表示もできます。

1:29:04.870,1:29:06.870
ほとんど同じですね。

1:29:07.090,1:29:09.090
1行だけアクセスしたり、

1:29:10.710,1:29:16.649
1列だけアクセスもできます。コロン（:）は

1:29:18.820,1:29:24.239
全ての行を意味します。なぜなら始めに書いたからです。もし2番目がコロンなら

1:29:24.910,1:29:27.569
全ての列を意味します。

1:29:30.430,1:29:34.530
この場合は取り除いても同じです。

1:29:36.970,1:29:38.970
最後のコロンは取り除くことが

1:29:39.380,1:29:43.210
できます。というのもそれが示唆されていますから。

1:29:43.210,1:29:49.509
こうする必要はありませんが、私自身はあえて書くこともあります。そうした方が、

1:29:50.030,1:29:52.030
どう対応していて

1:29:52.130,1:29:54.130
どうずれているかわかりやすいからです。

1:29:55.300,1:30:02.500
組み合わせることもできます。1行目の1列目から3列目までと行った感じで使えます。

1:30:03.800,1:30:05.800


1:30:07.200,1:30:15.200
足し算や型の確認もできます。この型はPythonの型とは異なります。

1:30:16.470,1:30:18.740
Right. So type is a function
Pythonのtypeは関数で

1:30:20.570,1:30:26.179
この場合の型はtensorですが、もしtensorの型が知りたい時はメソッドで、これはlongです。

1:30:28.650,1:30:31.969
floatを掛け合わせれば、float型になります。

1:30:31.980,1:30:35.750
もしこれまでにNumPyやPyTorchを使ったことがあまりなければ、

1:30:36.930,1:30:40.730
今が良い機会です。

1:30:42.079,1:30:48.139
いろんなことを試し、動かないと思うものも試してエラーメッセージをよく読んでください。

1:30:50.900,1:30:52.550


1:30:52.550,1:30:54.550
さて、今度はどれぐらい

1:30:55.460,1:30:57.730
このモデルが機能するかチェックしましょう。

1:30:58.400,1:31:02.619
私たちのモデルは受け取った画像を平均と

1:31:03.350,1:31:05.350
比べるものです。

1:31:07.840,1:31:09.409


1:31:09.409,1:31:11.409


1:31:12.230,1:31:17.080
すでに議論しましたが、学習データでだけでなく、

1:31:17.080,1:31:20.859
バリデーションセットでの性能を見るべきです。

1:31:21.409,1:31:27.039
validディレクトリにデータが入っています。さて、先に進む前に

1:31:27.040,1:31:29.709
バリデーションデータを用意しましょう。

1:31:30.590,1:31:31.969
3lsで取得できる

1:31:31.969,1:31:37.149
ファイルを開いて、tensorにして、stackして、浮動小数点にして、

1:31:37.790,1:31:39.770
255で割ります。

1:31:39.770,1:31:41.750
Okay

1:31:41.750,1:31:47.739
7についても同じです。必要な手順を数行にまとめました。

1:31:49.219,1:31:49.920
私は

1:31:49.920,1:31:53.119
ほぼいつもshapeをプリントするようにしています。

1:31:54.059,1:31:58.489
というのももしshapeが期待されたものでなければ変なことが起きているとわかるからです。

1:32:01.110,1:32:07.400
アイデアはis_threeという画像が3だと思ったらTrueを返す関数を定義することです。

1:32:09.239,1:32:12.558
実装するためには、

1:32:13.860,1:32:21.589
今見ている数字が理想的な3と7のどちらに近いかテストすることです。まずは

1:32:22.949,1:32:24.949


1:32:27.000,1:32:31.410
2つの画像の差の絶対値の平均を返すものを定義しましょう。

1:32:33.689,1:32:36.989
この関数はmnist_distanceとし、

1:32:37.659,1:32:40.558
2つの画像の差を計算し、

1:32:41.769,1:32:46.259
その絶対値をとり、平均を計算します。そしてこの関数にはすでに計算した平均画像をわたします。

1:32:46.260,1:32:50.010
今回は、平均を

1:32:50.590,1:32:52.590


1:32:54.960,1:33:02.279
後ろから2番目と3番目の軸で計算します。

1:33:03.850,1:33:10.799
つまり、x軸とy軸に関しての平均です。そして、これは、

1:33:11.290,1:33:16.979
a3とmean3の距離を返します。

1:33:17.380,1:33:19.589
そしてこの値は先ほど計算した値と

1:33:20.320,1:33:22.320
同じ0.114です。

1:33:24.500,1:33:30.580
さて、この計算をバリデーションセットの全画像に対して行います。メトリクスを計算するためです。

1:33:30.590,1:33:34.329
メトリクスとは、私たちのモデルがどれぐらい良いあるいは

1:33:35.420,1:33:39.309
ズレているかの指標です。mnist_distanceを

1:33:40.130,1:33:45.159
a3だけでなく、バリデーションセットの全データと

1:33:47.200,1:33:49.200
mean3に対して適用します。

1:33:49.910,1:33:55.910
これはすごいですね。普通のプログラミングで

1:33:56.670,1:34:03.710
行列あるいはランク3のtensorが入力でどちらでも動くものはありません。

1:34:04.890,1:34:09.079
ここでは1つの数字を返すのではなく、何が起きているのでしょう？

1:34:11.180,1:34:13.180


1:34:13.620,1:34:15.620
返り値は1010個の数字ですね。

1:34:15.660,1:34:17.970
これはブロードキャスティングのおかげです。

1:34:19.030,1:34:20.680
ブロードキャスティングは

1:34:20.680,1:34:25.680
とても特別な魔法のようなトリックで、

1:34:26.290,1:34:31.919
Pythonをとてもとても高速な言語にするものです。もしブロードキャスティングを

1:34:33.520,1:34:40.590
GPUのtensorに行うと、Pythonで書かれているのにGPUを使って計算されます。

1:34:42.490,1:34:44.490
このa - bを見てください。

1:34:45.850,1:34:47.850
- bを

1:34:48.050,1:34:53.949
valid_3_tensに行います。valid_3_tensは

1:34:56.220,1:35:01.229
約1000枚の画像で、mean3は

1:35:04.200,1:35:08.099
1枚の理想的な画像です。

1:35:10.180,1:35:12.180
このshapeのtensor - 

1:35:13.000,1:35:14.680
このshapeのtensorは

1:35:14.680,1:35:15.760


1:35:15.760,1:35:20.130
ブロードキャスティングはこのshapeとこのshapeが一致しない時に

1:35:20.440,1:35:26.609
一致しているかのように対応する要素から引き算を行います。しかし、実際にshapeが

1:35:27.160,1:35:31.800
一致しているわけではないのに1010個のmean3があるかのように

1:35:32.410,1:35:34.410
振舞います。

1:35:34.420,1:35:40.409
つまり、各画像データからmean3を引きます。

1:35:42.970,1:35:45.659
ブロードキャスティングの例を見ていきましょう。

1:35:47.230,1:35:50.489
理解するには要素毎の演算を知る必要が

1:35:51.010,1:35:52.420
あります。

1:35:52.420,1:35:58.049
要素毎の演算とは、このようなものです。ここにランク1で要素数3のtensorが

1:35:58.480,1:36:03.029
2つあります。shapeが全く同じです。

1:36:03.040,1:36:03.840


1:36:03.840,1:36:10.679
1, 2, 3と2, 1, 1の要素和は2, 3, 4となります。単純に

1:36:11.140,1:36:15.810
対応する要素を足し合わせるだけです。

1:36:19.110,1:36:20.940
では

1:36:20.940,1:36:23.060
shapeが異なる

1:36:25.440,1:36:27.440
場合はというと、

1:36:28.890,1:36:31.970
基本的にこの数字を

1:36:32.700,1:36:38.329r
1010書いコピーし、valid_3_tensから1010個のmean3のコピーの

1:36:38.700,1:36:42.649
引き算を行います。

1:36:43.560,1:36:45.560


1:36:47.100,1:36:51.209
実際にはmean3を1010回もコピーすることなく、

1:36:51.210,1:36:52.300
そのように振舞うだけです。

1:36:52.300,1:36:57.749
実際には何回も何回もループしているかのように振舞い、

1:36:57.750,1:37:01.050
こういった演算はCやCUDAで実装されます。

1:37:03.610,1:37:07.989
さて、少し戻って絶対値を見ましょう。

1:37:09.950,1:37:14.950
さて、absolute valueの関数をshapeが(1010, 28, 28)のtensorに適用すると

1:37:17.219,1:37:19.219
何が起きるのでしょうか？

1:37:21.260,1:37:26.110
各要素にabsが適用されますね。

1:37:26.750,1:37:28.040


1:37:28.040,1:37:32.019
最後にmean呼びますが、

1:37:33.140,1:37:37.479
-1は最後の軸、-2は最後から2番目の軸に対して作用します。

1:37:37.690,1:37:41.289
ですのでmean((-1, -2))は最後の2つの軸の平均をとります。

1:37:41.290,1:37:47.560
ですので最初の軸に関して返します。なので最終結果は1010個は

1:37:48.410,1:37:50.650
1010個の画像と理想画像の

1:37:51.380,1:37:53.230
差を表していて、今欲しいものです。

1:37:53.230,1:37:59.680


1:38:00.530,1:38:02.530


1:38:03.820,1:38:09.690
さて、この関数を使えばis_three関数も作れます。まず、

1:38:10.510,1:38:14.400
問題の数字画像を受け取り、それと理想的な3画像との距離を求め、

1:38:14.830,1:38:19.350
理想的な7の画像との距離より小さければ、

1:38:20.050,1:38:26.759
3、yesと予測するのです。

1:38:27.699,1:38:32.339
そして、それをfloatに変換、つまりyesなら1を返します。

1:38:35.230,1:38:37.699
これをバリデーションセット全体に行います。

1:38:39.179,1:38:42.469
Set right. So this is so cool. We basically get rid of loops
イケてますね。私たちは基本的にloopなしで、

1:38:43.260,1:38:49.670
In in in in this kind of programming you should have very few very very few. Loops. Loops make things
プログラムしました。loopはプログラムの

1:38:50.580,1:38:52.469
much harder to read
可読性を損ねますし、

1:38:52.469,1:38:53.940
さらに

1:38:53.940,1:38:58.580
GPUの有効活用を妨げプログラムを何十万倍も遅くします。

1:38:59.969,1:39:02.389
is_threeをvalid_three_tensに

1:39:03.390,1:39:07.129
適用し、floatに変換し、平均を取れば、

1:39:07.320,1:39:14.179
3の正確度になりますし、7の正確度は1 - 3の正確度です。

1:39:15.000,1:39:18.589
そして3の正確度は91%強で、

1:39:18.690,1:39:24.679
7に関しては98%、それらの平均は95%です。

1:39:25.230,1:39:27.350
ここで私たちは

1:39:28.140,1:39:32.449
95%の精度を誇る3と7を認識するモデルを作りました。

1:39:33.510,1:39:35.510
このように

1:39:36.090,1:39:38.239
簡単な計算だけでこのモデルができるというのは

1:39:39.570,1:39:44.659
驚きでしょうが、これが良いベースラインというものです。

1:39:47.440,1:39:49.440
さて、問題は

1:39:51.150,1:39:57.889
これを改善する方法が自明ではないことです。問題はこの方法がアーサー・サミュエルの言う

1:39:59.130,1:40:01.190
機械学習とは

1:40:01.860,1:40:07.130
Machine learning. This is not something where there's a function which has some parameters
異なることです。彼の表現ではパラメータを受け取る関数があり、

1:40:07.950,1:40:09.870
私たちが、

1:40:09.870,1:40:14.750
適合性の指標に基づいて評価し、その値に基づき繰り返しパラメータを改善するのです。

1:40:15.000,1:40:17.029
ですが、今作った方法は1ステップで、

1:40:18.030,1:40:20.030
十分でした。

1:40:21.360,1:40:27.380
今から取り組む方法では、重みの割り当てを評価する方法を用意し、

1:40:27.510,1:40:33.500
私はパラメータの割り当てと言いますが、

1:40:33.690,1:40:36.199
パフォーマンスを最大化するような重み割り当てを自動で行います。

1:40:36.870,1:40:42.140
この方法に取り組みたいのですが、何せ、第一章、初回レッスンからこの方法を知っているのですから、

1:40:42.170,1:40:45.049
しかし、そうするには、

1:40:45.930,1:40:47.640
マジックボックスのようなもの、

1:40:47.640,1:40:53.690
機械学習があり、ニューラルネットを使います。

1:40:54.510,1:40:56.510
理論的にはニューラルネットは

1:40:57.630,1:40:59.940
良い重みの組み合わせが見つかればどんな問題も解けます。

1:41:00.940,1:41:04.830
そして、重みを改善する方法が必要です。

1:41:05.650,1:41:07.650


1:41:08.110,1:41:10.110
では、

1:41:11.250,1:41:13.250
パラメータをとる関数を考えましょう。

1:41:13.840,1:41:21.090
理想的な画像を見つけたりある画像がその理想的なものからどれぐら離れているかを見たり、

1:41:26.920,1:41:33.839
ある画像が理想的なものとどれくらい違うかを計算する代わりに

1:41:34.210,1:41:36.210
できることは、各ピクセルに

1:41:36.910,1:41:38.080
対応する重みを用意し、

1:41:38.080,1:41:41.760
3の画像のピクセルが値を持つような

1:41:42.100,1:41:47.850
場所により重みを割り当てると言ったものです。

1:41:47.860,1:41:52.650
そうすれば、もしそのようなピクセルに値があったときに

1:41:53.170,1:41:57.390
よりスコアを与えることができ、それ以外の場所には

1:41:57.880,1:42:05.069
低いスコアを与えることで、最終的に何らかの確率が計算できる関数になりますね。

1:42:05.920,1:42:07.920
ここでは画像が8ピクセルとして、

1:42:07.990,1:42:12.359
そのピクセルと

1:42:13.330,1:42:19.919
何かしらの重みと掛けてから足し合わせますを計算します。

1:42:21.160,1:42:22.750


1:42:22.750,1:42:24.750
今見ている画像の

1:42:26.540,1:42:28.540
大きい重みが多ければ多いほど

1:42:29.130,1:42:35.960
確率は高くなります。今予測したい画像をXとします。

1:42:36.900,1:42:39.770
Xをベクトルで表します。

1:42:39.770,1:42:44.450
ただ全ての行をつなぎ合わせ、1つの長い行にするだけです。

1:42:45.750,1:42:46.830


1:42:46.830,1:42:52.910
今から取り組む方法では重みWから始めます。Wはベクトルで

1:42:52.910,1:42:59.329
ランク1のtensorです。ベクトルWの初期値は、

1:43:00.420,1:43:01.770
乱数に

1:43:01.770,1:43:08.629
すると良いでしょう。

1:43:10.050,1:43:11.670


1:43:11.670,1:43:15.830
そして、数字が3に見えるか7に見えるかを

1:43:16.890,1:43:18.720
この簡単な

1:43:18.720,1:43:20.100
関数で

1:43:20.100,1:43:21.570
予測します。

1:43:21.570,1:43:26.060
それから、このモデルがどれくらい正確かを

1:43:26.670,1:43:30.260
どの程度正しく予測できているかという感じで計算します。

1:43:31.350,1:43:33.350
これが損失です。

1:43:34.559,1:43:37.829
そして大事なステップは、勾配の計算です。

1:43:37.829,1:43:42.478
勾配は各重みをほんの少し動かした時に

1:43:43.449,1:43:49.438
損失が大きくなるか小さくなるかを尺測るもので、

1:43:49.439,1:43:51.479
全ての重みに対して計算します。

1:43:51.669,1:43:56.309
そうすると、全ての重みに対して、それを大きくするか小さくするかを決められます。

1:43:57.800,1:44:05.270
これを勾配と言います。勾配が得られたら、stepです。これは全ての重みを

1:44:05.790,1:44:07.790
更新することで、

1:44:09.070,1:44:11.349
勾配に基づいて小さくしたり大きくしたりします。

1:44:11.349,1:44:15.219


1:44:15.219,1:44:17.219


1:44:17.750,1:44:22.239
更新されるとほんの少し改善されて、ステップ2に戻ります。

1:44:23.119,1:44:25.869
再び式に基づいて予測を計算し、

1:44:27.770,1:44:29.550
勾配を計算し

1:44:29.550,1:44:31.230
重みを更新します。

1:44:31.230,1:44:32.060
この繰り返しです。

1:44:32.060,1:44:37.700
これが基本的なフローチャートで、待ちくたびれるか、損失が十分改善されたら

1:44:37.860,1:44:39.860
訓練を止めます。

1:44:40.800,1:44:48.260
So these seven steps 1 2 3 4 5 6 7
7つのステップですね。

1:44:49.920,1:44:50.800


1:44:50.800,1:44:51.899


1:44:51.899,1:44:56.239
この7つのステップ、深層学習モデルの訓練の鍵となるのは確率的勾配降下法です。

1:44:56.689,1:45:00.499
いまのは、勾配降下法で、確率的勾配降下法はあとで見ます。

1:45:01.829,1:45:03.749
これらの7つのステップはそれぞれ

1:45:03.749,1:45:08.749
どう実行するかの選択肢が多々ありますね？

1:45:08.749,1:45:11.179
これらのうち、多くのものはここでは置いておきます。

1:45:11.550,1:45:17.209
例えばランダム初期化や実際に勾配を計算する方法や勾配に基づいてどう更新するか、そして

1:45:17.209,1:45:19.459
どうやって訓練を止めるかを決める方法などです。

1:45:20.129,1:45:24.889
このコースではこれらのステップについて勉強しますが、

1:45:25.679,1:45:28.038
これあはパート1みたいなもので、

1:45:29.550,1:45:35.449
もう1つの大きなパートはニューラルネットワークがどういった関数であるかというものです。

1:45:35.449,1:45:37.998
どうやって訓練して、訓練しているものは何かといった感じです。

1:45:39.179,1:45:41.929
さて、パラメータを乱数で初期化し

1:45:42.419,1:45:45.259
損失関数となる関数が必要です。

1:45:45.539,1:45:50.088
損失関数はモデルが良ければ小さい値を返します。

1:45:51.719,1:45:56.058
何らかの方法で重みを増やすか減らすか決めます。

1:45:58.780,1:46:03.309
そして、いつ訓練を止めるか、つまり、いつ十分なエポック数学習したと言うかを決める必要があります。

1:46:06.780,1:46:08.550
So, let's like
さて、

1:46:08.550,1:46:14.179
もっとシンプルに行きましょう。MNISTも使いません。まずはxの二乗を計算する関数で始めます。

1:46:14.730,1:46:20.839
fastaiはplot_functionという関数があり、これは与えられた関数

1:46:25.610,1:46:27.610
fを描画します。

1:46:27.809,1:46:34.619
この図が損失関数ですが、今から

1:46:35.139,1:46:36.489
この底を見つけようとします。

1:46:36.489,1:46:37.139
さて、

1:46:37.139,1:46:41.279
今からするのは損失関数を最小にするxの値を見つけることで、

1:46:41.469,1:46:46.259
7つのステップは初期化するところから始まりますので、

1:46:47.859,1:46:49.719
1つ値を決める必要があります。

1:46:49.719,1:46:55.469
ここでは-1.5から始めます。

1:46:56.769,1:47:04.349
次に調べるべきはxを少し大きくしたら、損失関数の値は

1:47:04.349,1:47:07.049
良くなる、つまり小さくなるか、悪くなるかです。

1:47:09.270,1:47:15.450
これは非常に簡単でxを少しずらしてどうなるか確認すれば十分です。

1:47:15.450,1:47:19.109
そして、この情報はその地点における傾きがわかれば

1:47:19.960,1:47:23.760
得られます。

1:47:24.250,1:47:28.529


1:47:30.489,1:47:38.158
傾きの方向に重みを変更すれば損失は良くなります。

1:47:38.650,1:47:43.739
これがこの地点における傾きでこれが新しいxの値です。

1:47:44.349,1:47:46.949
これを何度も繰り返せば

1:47:47.860,1:47:49.860
この曲線の底にたどり着きます。

1:47:52.989,1:48:00.718
これはニュートンが考えたものでニュートン法といいます。

1:48:02.560,1:48:04.709
ですので私たちが行う必要があるのは

1:48:06.100,1:48:08.100
傾きの計算です。

1:48:09.250,1:48:12.959
微積分が必要という悪い知らせですが、

1:48:14.320,1:48:19.230
というのも私は微積分が嫌いですから。

1:48:20.170,1:48:22.170
良い知らせは

1:48:23.380,1:48:27.060
すでに導関数の求め方の勉強に時間を費やしているかもしれませんが、

1:48:27.940,1:48:34.859
計算機が高速で計算してくれるということです。

1:48:35.710,1:48:39.149
計算機はあなたが勉強した方法とそれ以外にも賢いトリックを

1:48:39.550,1:48:43.170
使って勾配計算を高速化しています。

1:48:43.750,1:48:51.299
高校数学を覚えているか知りませんが、x二乗の導関数は2xです。

1:48:53.320,1:48:57.000
これは先ほど言及したトリックの1つで

1:48:58.150,1:49:01.109
PyTorchは

1:49:01.900,1:49:06.509
導関数から勾配を計算するエンジンを積んでいます。

1:49:07.360,1:49:09.360
さて、これを使うために

1:49:10.050,1:49:12.050
tensorを使います。

1:49:12.250,1:49:14.250


1:49:14.440,1:49:17.489
そして、今回はこのtensorを更新するために

1:49:18.520,1:49:25.469
requires_grad_メソッドを呼びます。このメソッドはPyTorchに、tensor xtを使って

1:49:25.780,1:49:27.610
計算するときは

1:49:27.610,1:49:31.889
どんな計算をしたか覚えておき、あとで導関数を使えるようにしろと伝えます。

1:49:33.740,1:49:35.740
You see the underscore at the end and
末尾のアンダースコア（_）は

1:49:36.890,1:49:43.539
PyTorchではin-placeであることを示します。

1:49:44.180,1:49:47.200
このrequires_grad_は

1:49:47.870,1:49:52.870
私たちがxtの勾配を必要としていることをPyTorchに伝えます。

1:49:52.940,1:49:56.800
それはつまり、xtに対して行う計算全ての履歴を保存することになります。

1:49:57.050,1:49:59.169
こうすると導関数をあとで計算できます。

1:50:02.969,1:50:06.198
さて、要素が3のtensorを作りました。

1:50:07.230,1:50:13.459
関数fを適用します。fはただ二乗するもので、3の二乗は9ですね。

1:50:14.429,1:50:16.040
しかし結果はただの9ではなく

1:50:16.040,1:50:22.759
9と勾配を計算する関数で、二乗が適用されたことを示します。

1:50:23.280,1:50:25.400
ここまでくると

1:50:26.849,1:50:28.730
backwardを呼べて、

1:50:28.730,1:50:30.730
backwardは

1:50:32.150,1:50:36.109
あとで勉強しますが基本的には導関数と

1:50:37.350,1:50:42.870
requires_grad_を呼んだ、xtの値に基づいて

1:50:43.510,1:50:45.510
その勾配を求めます。

1:50:46.240,1:50:48.840
xの二乗の導関数は2xですね、

1:50:50.719,1:50:52.719
今回xは3だったので、

1:50:53.540,1:50:55.110
勾配は6ですね。

1:50:55.110,1:50:57.110


1:50:57.420,1:51:04.940
導関数を求める必要はありません。ただbackwardと.gradを呼べば勾配が得られます。

1:51:05.670,1:51:10.129
PyTorchで微分するのはこんなに簡単なのです。

1:51:11.910,1:51:17.030
ですから微積分について知っておくべきはどのように導関数を求めるかではなく

1:51:17.670,1:51:20.960
何を意味するかで、それは

1:51:21.720,1:51:23.670
ある点における

1:51:23.670,1:51:25.670
傾きです。

1:51:27.479,1:51:29.249
少し面白いことをしてみましょう。

1:51:29.249,1:51:32.699
3だけではなく、ランク1のtensor、

1:51:33.460,1:51:35.410
ベクトルを用意し

1:51:35.410,1:51:37.410
(3, 4, 10)で初期化し

1:51:37.780,1:51:39.760
sum()を

1:51:39.760,1:51:42.959
関数fに加えましょう。

1:51:43.630,1:51:46.200
そして、f(xt)を計算すると

1:51:48.199,1:51:50.598
125になります。

1:51:51.860,1:51:59.150
backward()を呼ぶと、勾配は(2x, 2x, 2x)です。

1:52:00.500,1:52:02.500
つまり私たちは

1:52:03.660,1:52:08.569
ベクトル微積分ができるのです。私たちはここで

1:52:09.390,1:52:10.920
ベクトルの

1:52:10.920,1:52:15.649
各要素の勾配を全く同じコードで求めました。

1:52:18.750,1:52:23.279
これが微積分について知っておくべき全てです。

1:52:24.940,1:52:29.279
もしこの傾きという考えに馴染みがなければ、

1:52:29.800,1:52:32.190
Khan Academyをお勧めします。

1:52:32.230,1:52:37.919
入門的なコースがありますし、あなたたちは実際に微分を手で求める部分は

1:52:38.770,1:52:40.770
飛ばして良いのです。

1:52:41.830,1:52:48.220
さて、もう勾配、つまり関数の傾きが計算できる、つまり、関数への入力を

1:52:48.800,1:52:50.800
少し変えたら

1:52:51.350,1:52:53.350
その関数の出力がどう変わるかわかります。

1:52:53.870,1:52:55.990
Correspondingly, that's what a slope is
これが傾きの意味です。

1:52:56.510,1:53:04.389
もし勾配が得られたら、そこにある全てのパラメータを

1:53:04.390,1:53:10.839
どう更新したら損失がどれくらい変わるかわかります。よってパラメータをどう変えるべきかわかります。

1:53:12.080,1:53:17.289
私たちがすべきは、重みwの各要素から

1:53:18.140,1:53:21.579
何か小さい係数を掛け合わせた

1:53:22.610,1:53:24.320
勾配を

1:53:24.320,1:53:29.169
引くことです。この小さい係数はだいたい

1:53:29.630,1:53:32.740
0.001から1ぐらいで学習率と呼ばれます。

1:53:33.500,1:53:37.570
そしてこれこそが勾配降下法の

1:53:38.540,1:53:40.540
肝です。

1:53:40.820,1:53:43.719
もし学習率が小さすぎると

1:53:44.269,1:53:47.739
傾きの方向にほんの少しだけ移動し、

1:53:47.899,1:53:52.239
それを繰り返します。この調子だといつまで経っても、ゴール、つまり損失関数の

1:53:52.849,1:53:54.439
底に着きません。

1:53:54.439,1:53:56.439
逆に学習率が大きすぎると、

1:53:57.409,1:53:59.409
遠くに行きすぎるので

1:54:00.289,1:54:02.889
それを繰り返してたとしても、先ほど同様に終わらないでしょうし、

1:54:05.429,1:54:11.129
この場合では、ここから始まるので、むしろ悪化します。

1:54:13.780,1:54:16.659
また、ここからこれぐらいの学習率で始めると

1:54:17.300,1:54:20.920
毎回悪化します。ただ長い時間をかけて行ったり来たりします。

1:54:21.739,1:54:23.690
ですから、

1:54:23.690,1:54:30.250
妥当な学習率を選択するというのは問題を解く上でも、現実的な時間で問題を解く

1:54:30.590,1:54:33.279
上でも非常に重要です。

1:54:33.469,1:54:37.808
ですからこのコースで学習率の選び方も教えます。


1:54:41.780,1:54:43.070
では

1:54:43.070,1:54:47.139
この方法を試しましょう。勾配降下法も試しましょう。

1:54:48.010,1:54:53.380
確率的勾配降下法と言いましたが厳密には間違いです。この問題を解くには勾配降下法を使います。

1:54:54.650,1:55:00.039
今から扱う問題のイメージは、こんな感じです。あなたはジェットコースターを見ているとします。

1:55:00.650,1:55:05.949
てっぺんから反対側のてっぺんに向かって進むとき

1:55:06.499,1:55:10.629
始めは徐々にスピードを上げていきますが、

1:55:11.059,1:55:14.859
上りでは徐々にスピードを失っていきます。

1:55:15.260,1:55:17.590
頂上についたらまた下りはじめ、スピードを付けていきます。

1:55:17.599,1:55:22.808
もしスピードメーターやストップウォッチのようなもので

1:55:23.059,1:55:25.599
等間隔で

1:55:26.329,1:55:32.109
測定したらこのようなものが得られますね。

1:55:32.110,1:55:36.099
And so the way I did this was I just grabbed a range just grabs
この関数の作り方は、まずarange関数で

1:55:36.679,1:55:43.748
The numbers from naught up to but not including 20, right? So these are the time periods at which I'm taking my speed measurement and
0から20までの整数を取得し、これが時間ですね、

1:55:44.599,1:55:46.599
Then I've just got some
それから、

1:55:47.479,1:55:52.929
時刻から9.5を引いた後に二乗し0.75倍したものに定数項1と

1:55:52.929,1:55:56.438
乱数の三倍を足しています。

1:55:57.530,1:55:59.300


1:55:59.300,1:56:06.759

1:56:07.070,1:56:10.449
その結果、少し凸凹の二次関数が得られました。

1:56:10.639,1:56:14.768
でこぼこのおかげで少し現実的になっています。なぜならスピードメータによる

1:56:15.289,1:56:17.469
計測は不完全ですから。

1:56:20.659,1:56:22.659
では、次は

1:56:22.789,1:56:27.728
どんな時間でも何かしら推測する関数を用意します。ジェットコースターの速度はなんでしょう。

1:56:28.519,1:56:30.519
いつも、

1:56:30.769,1:56:33.849
どんな関数が存在するか予測することから始まります。

1:56:33.849,1:56:40.899
We guess that it's a function a times x squared plus B times time plus C
私たちは、その関数はtの二乗＋B t + Cのようなものと考えました。

1:56:40.969,1:56:43.419
You might remember from school is quite a quadratic
これは二次関数の一般的な形ですね。

1:56:44.090,1:56:47.799
So let's create a function, right? And so
では、関数を作りましょう。

1:56:49.010,1:56:54.070
Let's create it using kind of the Alpha Samuels technique the machine learning technique. This function is going to take two things
アーサー・サミュエルの機械学習のテクニックを使って関数を作りましょう。この関数は

1:56:54.409,1:56:56.409
It's going to take an input
入力、ここでは時間

1:56:56.599,1:56:58.599
そして、

1:56:58.760,1:57:00.760
いくつかのパラメータ、

1:57:01.850,1:57:05.149
a, b, cを受け取ります。

1:57:05.670,1:57:12.410
Pythonではリストなどからこのように要素を取り出せます。

1:57:16.100,1:57:18.890
ここでは、どんな関数に対しても、私たちは

1:57:19.920,1:57:22.790
a, b, cを見つけることで二次関数を適合させようとしています。

1:57:23.880,1:57:27.680
アーサー・サミュエルにならえば、

1:57:27.990,1:57:35.030
次にするべきは、関数の予測がどの程度優れているかを測る損失関数を

1:57:36.000,1:57:38.000
決めることです。

1:57:38.460,1:57:41.960
このとき、目標は実際の値で、

1:57:42.750,1:57:44.750
ここでは、

1:57:46.320,1:57:52.939
平均二乗誤差を使います。

1:57:54.530,1:57:57.310
準備ができたので7つのステップを実行します。

1:57:57.679,1:58:03.549
できる限り良いa, b, cのを見つけるたいのですが、

1:58:03.800,1:58:07.509
まずa, b, cを初期化する必要があります。

1:58:07.880,1:58:13.599
これがPyTorchで乱数を取得する方法です。ここからパラメータを調整していきます。

1:58:13.599,1:58:15.969
ですのでPyTorchに勾配を計算するよう伝えなければなりません。

1:58:19.950,1:58:26.490
そして、この初期値をあとで確認するために保存しておきます。そして、関数fを使って予測値を計算します。

1:58:27.370,1:58:29.370
fはこれです。

1:58:31.650,1:58:35.000
それから、その時点での予測値がどの程度かを可視化する

1:58:35.520,1:58:37.760
関数も作ります。

1:58:38.010,1:58:44.539
この関数は予測を赤、正解を青でプロットします。

1:58:44.700,1:58:46.700
ボロボロですね。

1:58:48.520,1:58:50.520
そして損失を

1:58:51.670,1:58:53.670
この関数で求めます。

1:58:54.050,1:59:01.160
パラメータを更新するために、backwardメソッドを呼び、gradを取得する2ステップで勾配を計算します。

1:59:01.710,1:59:03.710
この結果はパラメータが

1:59:04.620,1:59:06.859
負の勾配を持っているということです。

1:59:09.660,1:59:15.829
学習率を10の-5乗とし、この勾配それぞれに学習率をかけて

1:59:18.139,1:59:19.019

1:59:19.019,1:59:25.699
重みを更新、つまり、現時点での重み - 学習率 x 勾配

1:59:26.519,1:59:28.519
を実行します。

1:59:28.980,1:59:31.020
ここではdata attributeを使っていますが

1:59:32.020,1:59:36.330
これは、PyTorchにおいて、dataに対する計算は

1:59:36.640,1:59:38.640


1:59:38.980,1:59:44.399
勾配を計算しなくなるからです。重み更新に関する勾配は不要です。

1:59:44.860,1:59:51.810
勾配が必要なのは

1:59:52.989,1:59:57.479
関数fだけです。ですから、重みの更新においては、data attributeを

1:59:58.300,2:00:00.300
使います。

2:00:00.610,2:00:02.350
重み更新後は

2:00:02.350,2:00:04.350
使用済みの勾配を削除し、

2:00:04.989,2:00:08.309
損失が良くなったか見てみましょう。最初は

2:00:10.840,2:00:12.760
25800でしたが、

2:00:12.760,2:00:19.679
今は5400です。プロットも-300に向かって加工する曲線から

2:00:22.030,2:00:24.030
だいぶまともになりました。

2:00:25.129,2:00:30.769
このプロセスをもう少し繰り返すので、関連する数行のコードを1つのセルにまとめました。

2:00:31.409,2:00:35.118
予測、損失を計算して、backward、重み更新、勾配削除という感じです。

2:00:35.969,2:00:38.388
そして、毎回損失の値を出力するようにして、

2:00:39.329,2:00:42.889
10回繰り返すと毎回改善されていますね。

2:00:46.030,2:00:50.640
そして、改善の様子が可視化されています。

2:00:52.230,2:00:59.000
イケてますね。アーサー・サミュエルの技術を使って、それは

2:01:00.840,2:01:03.560
良いパラメータを見つけるためのものですが、

2:01:04.170,2:01:10.520
損失関数による結果のフィードバックを使って継続的に改善していくのです。

2:01:11.999,2:01:14.339
非常に重要なステップです。

2:01:15.579,2:01:23.429
これが勾配降下法というもので、みなさんはぜひ、何回も復習して、

2:01:24.070,2:01:28.289
何が起きているかをしっかり理解してください。もし馴染めなくても

2:01:28.289,2:01:32.998
もしこれが初めてなら仕方ありません。

2:01:34.840,2:01:39.779
このnotebookのどのセルからあやふやになってしまったかを洗い出し、

2:01:40.389,2:01:45.748
しっかり考えてみてください。

2:01:45.749,2:01:50.339
1行1行何が起きているか良くみて、何回か実験したり、本を読んで

2:01:51.340,2:01:53.320
あなたが詰まった

2:01:53.320,2:01:56.039
セルを理解してから次に進みましょう。

2:01:58.380,2:02:00.920
So let's now apply this to em mist
ではこれをMNISTに使いましょう。

2:02:02.770,2:02:04.770


2:02:06.050,2:02:08.050
MNISTでは

2:02:09.310,2:02:13.620
ほとんど同じで、追加ですべきことはほとんどありません。

2:02:14.590,2:02:16.150
必要なのは

2:02:16.150,2:02:18.150
損失関数と

2:02:21.190,2:02:27.280
メトリクスでこれは誤差率です。

2:02:27.320,2:02:31.689
ここでも、メトリクスが良くなるように取り組むのですが、

2:02:32.780,2:02:35.709
深刻な問題は

2:02:36.470,2:02:39.130
勾配を計算して、

2:02:40.400,2:02:46.239
パラメータをどう更新するかはっきりさせることです。勾配は傾きで

2:02:47.030,2:02:50.169
関数の出力の変化 / 入力の変化で定義されます。つまり、

2:02:51.050,2:02:57.519
(y_new - y_old) / (x_new - x_old)です

2:02:58.490,2:03:06.369
実際に勾配が定義されるのはx_newがx_oldに非常に近いときです。

2:03:07.650,2:03:09.650
では、

2:03:09.940,2:03:17.129
もし、パラメータをごくわずか変化させたとしても、正確度は全く変わらないでしょう。

2:03:17.800,2:03:19.800
というのも

2:03:19.929,2:03:25.439
3と予測されていたものが7に変わったりその逆は起きないからです。

2:03:25.659,2:03:28.049
そもそもパラメータの変化は微小なのですから。

2:03:29.320,2:03:34.949
ですから、実際に多くの場所で勾配は0になり得るのです。

2:03:35.679,2:03:39.149
そして、このことは

2:03:39.790,2:03:46.709
学習率x勾配=0となり、パラメータを全く変化させないことを意味します。

2:03:48.429,2:03:50.429
これが

2:03:51.250,2:03:53.020
損失関数と

2:03:53.020,2:03:57.149
メトリクスが必ずしも一致しない理由です。

2:03:58.150,2:04:00.540
もしメトリクスの勾配が0なら

2:04:01.300,2:04:05.009
損失としては使えません。

2:04:07.680,2:04:09.680
ですからメトリクス以外で、

2:04:10.920,2:04:12.920
とはいっても正確度のようなものが必要で

2:04:14.530,2:04:19.620
それは正確度が良くなればその損失関数も

2:04:20.140,2:04:22.950
改善されると同時に、

2:04:23.770,2:04:25.770
勾配が0にならないようなものです。

2:04:27.670,2:04:29.670
ではこんな関数を考えましょう。

2:04:32.800,2:04:35.610
3枚の画像があるとします。

2:04:37.779,2:04:39.779
えー、

2:04:41.110,2:04:45.060
おそらくこのタイミングで今日のレッスンは止めた方が良さそうです。

2:04:45.060,2:04:49.680
勾配降下法の説明をしました。

2:04:51.780,2:04:55.219
単純な損失関数でどう実行するか学びました。

2:04:55.680,2:04:59.720
ですので、今日はもうMNISTの損失関数について考えたり、

2:05:00.690,2:05:02.400
説明しない方が良さそうです。

2:05:02.400,2:05:06.560
来週までの宿題も沢山あります。

2:05:06.560,2:05:09.410
1つはwebアプリを作成すること、そして

2:05:09.810,2:05:15.080
勾配降下法を復習することです。

2:05:15.660,2:05:17.660
ですから今日のところは

2:05:18.930,2:05:26.510
ここまでとしておきましょう。Rachel、何か質問は出ていますか？

2:05:28.170,2:05:35.390
わかりました。ではみなさん、今日もありがとうございました。最後の数分間についてはごめんなさい。

2:05:36.240,2:05:43.309
webアプリケーション作成を楽しんでください。

2:05:44.250,2:05:48.439
何か素晴らしいものを作ってくれることを期待しています。

2:05:49.350,2:05:53.870
過去には、16人のいとこを見分けるモデルを作った

2:05:54.270,2:05:57.530
生徒もいました。

2:05:57.960,2:06:03.200
婚約者のために作ったそうです。

2:06:04.590,2:06:11.120
どんなものでも作ることができますが、ぜひ誰かに見せて、そして

2:06:12.780,2:06:18.259
ipywidgetのドキュメントを確認したりしながら何か作ってみてください。

2:06:19.200,2:06:21.530
ではさようなら、また来週。
