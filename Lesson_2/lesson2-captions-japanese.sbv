0:00:00.520,0:00:04.020
それでは皆さん、こんにちは。そして、

0:00:04.690,0:00:07.319
コーダのための実践的ディープラーニングへお帰りなさい。今回はレッスン2です。

0:00:08.260,0:00:10.000
そして、

0:00:10.000,0:00:12.599
前回のレッスンでは

0:00:13.570,0:00:19.500
最初のモデルのトレーニングを開始しました。実際にトレーニングがどのようなものかは考えずに

0:00:19.500,0:00:22.439
より高いレベルでどうなっているかを見ていました。

0:00:23.109,0:00:24.519
そして、

0:00:24.519,0:00:26.519
私たちは

0:00:26.560,0:00:28.240
機械学習とは

0:00:28.240,0:00:30.510
何であるか、そしてどのように機能するかを学びました。

0:00:31.390,0:00:33.390
さらに

0:00:34.180,0:00:35.860
私たちは

0:00:35.860,0:00:43.260
機械学習がどう動くかに基づいて考えると、そもそも機械学習にはできることの制限があることを認識しました。

0:00:43.719,0:00:46.259
そして、そういった制限についても話しました。

0:00:46.260,0:00:50.820
さらに、機械学習モデルを訓練した後に、

0:00:51.309,0:00:56.249
通常のプログラムのように振る舞うプログラムができあがることについても話しました：入力、中間にあるもの（モデル）、そして

0:00:56.829,0:00:58.449
出力です。

0:00:58.449,0:01:00.449
さて、今日は

0:01:00.850,0:01:02.850
この話を終わらせてから

0:01:03.280,0:01:05.820
実際に訓練したモデルを

0:01:06.400,0:01:09.119
本番環境にのせる方法とそうする上での問題点について話します。

0:01:10.000,0:01:12.000
そして

0:01:12.939,0:01:14.939
2冊の本について再度説明したいです。

0:01:15.369,0:01:19.438
失礼、実際にはノートブックですね。

0:01:20.590,0:01:23.100
一つは、fast bookで

0:01:24.009,0:01:29.249
オライリー本の執筆で実際に使ったノートブックのレポジトリで、

0:01:30.220,0:01:32.939
実際に

0:01:33.460,0:01:35.939
私が伝えることとプラスアルファを動かすことができます。

0:01:36.430,0:01:43.319
そして、もう一つはこのコースのレポジトリで、レッスンで扱うものと同じノートブックですが、

0:01:43.320,0:01:46.680
あなた方の理解のために説明文などは消してあります。

0:01:47.140,0:01:52.439
ですので、それらのノートブックは授業を聞きながら実行したり、自分で色々試したりできます。

0:01:52.780,0:01:58.949
そして、ビデオと本を行ったり来たりすることも、どちらか片方を先に終わらせてからもう片方を進めることもできます。

0:01:59.530,0:02:04.320
それから、このノートブックを見て、

0:02:04.320,0:02:09.239
セクションの内容を思い出して、コードを実行して、何が起きるかを見て、コードを少し変えるとどうなるかを確認するといった使い方をしてください。

0:02:11.830,0:02:13.830
さて、私たちが

0:02:16.780,0:02:19.860
見ていたこの行ではデータセットを

0:02:20.800,0:02:22.800
作るために

0:02:23.080,0:02:26.790
おそらく最も重要であろうラベルの付け方を教えたり

0:02:27.370,0:02:31.230
私たちはラベル付けの重要性についても話しましたね

0:02:31.230,0:02:35.250
そして、今回は、犬と猫のデータセットを使っています。

0:02:35.290,0:02:39.059
このデータセットではファイル名の頭文字が大文字か小文字かでラベルが決まっています。

0:02:39.970,0:02:43.139
これは、このデータセットがそう作られているからです。

0:02:44.320,0:02:50.699
そして、特に、このvalid_pct=0.2というものを確認しました。

0:02:50.700,0:02:55.679
これは、バリデーションセットを作るもので、バリデーションセットについては今後詳しく話したいと思っています。

0:02:56.740,0:03:00.540
まず最初に指摘しておきたいのは、この特定のラベリング関数は

0:03:04.330,0:03:07.320
真か偽のどちらかを返すということです。

0:03:09.610,0:03:15.179
このデータセットには、後ほど見るように、37種類の猫と犬の実際の品種も

0:03:15.910,0:03:20.429
このデータセットには、後ほど見るように、37種類の猫と犬の実際の品種も含まれており、ファイル名から取得できます。

0:03:21.910,0:03:29.249
これら2つのケースでは、カテゴリを予測します。それらは、「猫なのか犬なのか？」、

0:03:30.190,0:03:34.739
「ジャーマンシェパードなのかビーグルなのかラグドールなのか？」といったものです。

0:03:35.440,0:03:42.389
カテゴリーを予測しようとしているとき、つまりラベルがカテゴリーであるとき、それを分類モデルと呼びます。

0:03:43.750,0:03:45.519
一方で、

0:03:45.519,0:03:50.879
動物の年齢や身長、

0:03:51.640,0:03:52.959
あるいは、

0:03:52.959,0:03:58.469
そういったものを予測しようとするとき、対象は13.2や26.5といった連続値です。

0:03:59.110,0:04:05.729
数字を予測しようとするときはいつでも、そのラベルは回帰と呼ばれる数字です。

0:04:05.730,0:04:07.860
これらが主に用いられる2種類のモデルで、

0:04:08.410,0:04:13.919
分類と回帰と呼ばれるものです。これは非常に重要な専門用語なのでしっかり覚えてください。回帰モデルは、

0:04:14.769,0:04:19.379
温度や場所などの1つ以上の数値量を予測しようとします。

0:04:20.400,0:04:27.229
これは少し紛らわしいですね。時々、回帰という言葉は

0:04:27.810,0:04:31.310
線形回帰と呼ばれる特定のモデルをさすことがあります。

0:04:33.180,0:04:39.139
しかし、線形回帰は回帰ではないので、大変紛らわしいです。

0:04:39.419,0:04:43.189
線形回帰は特定の種類の回帰に過ぎないことに注意してください。

0:04:44.580,0:04:48.590
回帰について話し始めると、線形回帰ではないのに多くの人は線形回帰のことを話していると思い込むでしょう。

0:04:50.790,0:04:57.589
さて、私はこのvalid_percent 0.2について話したいと思います。先ほど説明したように、

0:04:58.470,0:05:04.850
先ほど説明したように、valid_percentはデータの20パーセントを別のバケツに入れておき、

0:05:05.220,0:05:07.220
モデルを訓練するときには

0:05:07.650,0:05:10.190
そのデータを使いません。

0:05:10.770,0:05:17.780
そのデータは、モデルがどれだけ正確であるかを示すためだけに使用されます。

0:05:20.010,0:05:22.010
ですから、もしあなたがあまりにも長い間、

0:05:23.070,0:05:27.229
あるいは十分なデータを持たずに、あるいはパラメータが多すぎるモデルを使って

0:05:27.599,0:05:33.889
トレーニングした場合、しばらくするとモデルの精度は実際に悪くなります。これをオーバーフィットと呼びます。

0:05:34.349,0:05:38.419
そこで、オーバーフィットしていないことを確認するために検証セット

0:05:38.940,0:05:40.940
を使用します。

0:05:42.000,0:05:45.019
次に見たコードの行はこの行で、

0:05:45.750,0:05:51.500
Learnerと呼ばれるものを作成しました。Learnerについては今後深く学ぶ予定ですが、基本的には

0:05:51.780,0:05:53.780
データセットと

0:05:54.990,0:05:56.130
あなたの

0:05:56.130,0:05:59.630
アーキテクチャ、つまり最適化する数学的な関数を持ちます。

0:06:00.630,0:06:07.699
つまり、learnerとは関数がデータのラベルに最も適合するような

0:06:07.949,0:06:11.779
パラメータを見つけ出すものです。

0:06:12.449,0:06:14.689
詳しく説明しましたが、要するに、

0:06:15.240,0:06:19.760
このresnet34という関数がアーキテクチャの名前で、

0:06:19.979,0:06:23.449
このアーキテクチャは、コンピュータビジョンに適している

0:06:24.030,0:06:24.930
ことが知られています。

0:06:24.930,0:06:30.829
本当の名前はResNetで34は層の数を表していて、この数字が大きくなると、

0:06:31.080,0:06:38.330
より多くのパラメータが学習に使われるのでよりメモリを消費し、さらに過学習しやすくなりますが、

0:06:39.990,0:06:41.990
より複雑なモデルを作れます。

0:06:42.480,0:06:46.759
しかし、今はmetrics=error_rateに注目しましょう。

0:06:47.580,0:06:54.199
ここでは、バリデーション時に使いたい関数を列挙し、

0:06:54.330,0:06:56.330
それらの結果は毎エポック後に

0:06:56.430,0:06:58.430
プリントされます。

0:06:58.770,0:07:00.120
エポックとは、

0:07:00.120,0:07:04.730
データセットの全ての画像を見ることを意味します。

0:07:05.670,0:07:12.259
つまり、データセットを1周するたびに、モデルに関する情報がプリントされ、

0:07:12.450,0:07:17.300
最も重要なことですが、これらのメトリクスの結果もプリントされます。

0:07:17.550,0:07:23.240
error_rateはメトリクスの1つで、バリデーションセットのうち，何%の画像が

0:07:23.520,0:07:26.570
誤って分類されたかをプリントします。

0:07:28.920,0:07:34.820
つまり、バリデーションセットを使って予測の質を計算しているのです。

0:07:35.370,0:07:40.370
1 - error_rateで計算される正確度も一般的なメトリクスです。

0:07:41.190,0:07:45.410
先週のレッスンで大変重要なことを話しました。アーサー・サミュエルは

0:07:46.680,0:07:53.329
機械学習における重要な損失という考えを持っていました。モデルの性能がどれくらい良いかを把握するためには

0:07:54.300,0:08:01.759
何らかの方法が必要で、パラメータを変更したときに、どのパラメータのセットが性能を良くするか悪くするかを

0:08:02.880,0:08:04.880
把握することができます。

0:08:05.190,0:08:07.669
パフォーマンスの基準は損失ですが、

0:08:08.190,0:08:09.900
必ずしも

0:08:09.900,0:08:13.489
メトリクスと同じとは限りません。

0:08:14.670,0:08:19.850
その理由は少し微妙で、今後のレッスンで数学を掘り下げていくと

0:08:19.850,0:08:21.850
詳細が見えてきますが 、

0:08:22.560,0:08:26.869
基本的には関数が必要で、

0:08:27.390,0:08:33.470
パラメータを少しだけ上げたり下げたりして、 損失が少し良くなったか悪くなったか

0:08:33.470,0:08:39.739
を見ることができる損失関数が必要です。

0:08:39.990,0:08:43.370
予測が犬から猫に変わるほどパラメータを変化させるわけではない

0:08:43.920,0:08:49.499
ので精度やエラーレートでは不十分なのです。

0:08:49.500,0:08:53.609
予測が同じならエラーレートも同じはずです。

0:08:54.400,0:08:59.249
損失とメトリックは密接に関連していますが、メトリックはあなたが気にしているもので、

0:08:59.980,0:09:07.110
損失はパフォーマンスの測定値としてコンピュータがパラメータをどのように更新するかを決定するために使用しているものです。

0:09:08.920,0:09:10.920
損失はパフォーマンスの測定値として

0:09:11.860,0:09:17.490
コンピュータがパラメータをどのように更新するかを決定するために使用しているものです。

0:09:17.860,0:09:21.210
FastAIは常に検証セットを使用してメトリクスを出力します。

0:09:22.480,0:09:29.970
オーバーフィッティングは重要で、学習しているデータだけでなく、

0:09:30.640,0:09:37.949
学習アルゴリズムが見たことのないデータに適合するモデルをどうやって見つけるかということです。

0:09:41.170,0:09:42.760
つまり

0:09:42.760,0:09:43.960
過学習は

0:09:43.960,0:09:45.520
モデルが

0:09:45.520,0:09:47.520
不正行為が

0:09:47.890,0:09:51.670
している結果とも言えます。

0:09:51.670,0:09:56.969
モデルは、「これと同じ写真を見たことがある、それは猫の写真だ」と言うことでごまかすことができます。

0:09:57.400,0:10:00.719
つまり、一般的に猫がどのように見えるかを学習していないかもしれませんが

0:10:00.720,0:10:01.360
、画像1〜4と8が猫で、

0:10:01.360,0:10:07.050
画像2〜3と5が犬であることを覚えているだけで

0:10:07.450,0:10:12.989
猫がどういうものかという概念は学習していないのです。これが、絶対に避けたいタイプのズルです。

0:10:12.990,0:10:14.990
つまり、モデルが特定のデータセットを

0:10:15.250,0:10:17.250
丸暗記するのは避けたいのです。

0:10:17.980,0:10:19.980
なので、バリデーションデータを作るのです。

0:10:20.530,0:10:25.559
画面に表示されている文章は本からコピーしてきました。

0:10:26.950,0:10:29.009
検証データを分割して、

0:10:30.010,0:10:35.729
モデルが学習中にそれを見ないようにすれば、完全にデータに汚染されないので、ごまかすことはできません。

0:10:36.790,0:10:38.849
そうではありません。ごまかすことはできます。

0:10:39.460,0:10:45.599
ごまかす方法としては、モデルをフィットさせて結果と検証セットを見て、

0:10:46.120,0:10:48.719
何かを少し変更して別のモデルをフィットさせて検証セットを見て、

0:10:48.720,0:10:52.200
何かを少し変更して、検証セットが一番良さそうなものが見つかるまで

0:10:53.050,0:10:55.770
100回くらい繰り返してみることができます。

0:10:56.350,0:10:58.710
そうするとバリデーションセットに適合しているかもしれませんね。

0:10:59.230,0:11:04.779
ですから、もしこれを本当に厳密に行いたいのであれば、テストセットと呼ばれる3番目のデータを用意しておくべきです。

0:11:05.330,0:11:11.470
訓練にもメトリクス計算にも使わないテストデータを作るのです。

0:11:12.320,0:11:15.249
これは実際には、プロジェクト全体が終了するまで見ることはありません。

0:11:15.920,0:11:19.149
これは、Kaggleのようなコンペテイションプラットフォームで使われているものです。

0:11:20.060,0:11:23.380
Kaggleでは、コンペテイション後、

0:11:24.200,0:11:26.560
見たことのないデータセットに対して

0:11:27.260,0:11:32.410
パフォーマンスが測定されます。
　
0:11:32.990,0:11:34.990
これは本当に有益なアプローチで、

0:11:35.390,0:11:42.230
自分でモデリングをしていなくても、実際にそうするのは素晴らしいアイデアです。
　
0:11:42.230,0:11:44.529
もしあなたがベンダーを見ていて、

0:11:44.530,0:11:51.550
今日はIBMかGoogleかMicrosoftにしようと決めようとしていて、彼らのモデルがどれだけ素晴らしいかを見せてくれているなら、

0:11:52.820,0:11:56.379
あなたがすべきことは、「OK、あなたはモデルを作成して、

0:11:56.780,0:12:02.019
私は私のデータの10％を保持して、あなたには全く見せないようにします。

0:12:02.450,0:12:11.320
あなたたちが作成したモデルをあなたたちが使えなかったテストデータで評価します。

0:12:12.470,0:12:14.210
さて、検証セットとテストセットを

0:12:14.210,0:12:16.840
引き出すのはちょっと微妙ですが、

0:12:17.690,0:12:22.149
これは簡単な小さなデータセットの例で、

0:12:23.000,0:12:28.419
これはレイチェルが書いた、効果的な検証セットの作成についての素晴らしいブログもってきました。

0:12:29.390,0:12:35.170
基本的には、ある種の季節性をもつデータセットであることがわかります。

0:12:35.750,0:12:38.529
さて、「Ok, FastAI, valid_percent of 0.2で

0:12:39.230,0:12:43.570
data loaderを作りたい」と言うと、次のようになります。

0:12:44.420,0:12:51.190
ランダムにいくつかのドットを間引いていますね？

0:12:51.380,0:12:53.210
これは良くありません。

0:12:53.210,0:12:58.449
ドットが他のドットの真ん中にあるので、ズルをすることができます。

0:12:58.940,0:13:00.670
こんなことは実世界では起きませんよね？

0:13:00.670,0:13:05.110
実際に何が起こるかというと、これは日付ごとの売上高ですが、

0:13:05.110,0:13:08.620
来週の売上高を予測したいと思います。対象は

0:13:09.200,0:13:12.539
14日前、18日前、29日前の売上ではありません。

0:13:13.089,0:13:18.178
ここで効果的な検証セットを作成するために実際に必要なのは、ランダムに行うのではなく、

0:13:19.179,0:13:20.649
最後の部分を

0:13:20.649,0:13:22.149
切り落とすことです。

0:13:22.149,0:13:29.368
これは全てのKaggleコンテストで起こることで、例えば、時間が関係していて、

0:13:29.369,0:13:34.979
予測しなければならないのは、最後に与えられたデータポイントの２週間後くらいのことで、

0:13:35.889,0:13:38.459
あなた達のテストセットでもこうすべきです。

0:13:38.920,0:13:42.569
繰り返しになりますが、ベンダーを抱えていて、

0:13:42.569,0:13:48.269
あなた方のモデリングが完了したら、私たちが提供したデータセットの1週間後の

0:13:48.269,0:13:50.789
データセットでモデルを評価します。

0:13:51.339,0:13:55.018
あなた達は再学習などはできません。なぜならこれが実世界で起きることだからです。

0:13:56.619,0:14:00.119
質問があります。過学習は訓練誤差が

0:14:00.639,0:14:07.048
バリデーション誤差より小さくなることだと聞いたことがあります。この経験則はあなたの説明と同等ですか？

0:14:07.569,0:14:09.420
良い質問ですね。

0:14:09.420,0:14:14.429
おそらく、質問は、訓練誤差と検証誤差の比較に関してですね。

0:14:15.189,0:14:17.519
fastaiでは訓練誤差をプリントせず、

0:14:18.040,0:14:24.449
エポックの終わりに、トレーニングセットとバリデーションセットに対する損失関数の値を

0:14:24.449,0:14:26.789
プリントします。

0:14:28.329,0:14:32.428
十分長く訓練を続けた場合、

0:14:33.160,0:14:36.449
訓練誤差も検証誤差も小さくなるでしょう。

0:14:37.480,0:14:39.480
なぜなら、定義上、

0:14:40.989,0:14:45.449
損失関数は、損失関数が低いほど良いモデルであるように定義されているからです。

0:14:46.329,0:14:48.329
過学習し始めたら

0:14:48.369,0:14:55.949
パラメータは改善されているので訓練誤差は減少し続けますが、

0:14:57.790,0:15:00.360
検証誤差が増加し始めます。

0:15:01.149,0:15:06.928
なぜなら、モデルがトレーニングセットの特定のデータに適合し始めているからです。そうすれば訓練誤差は小さくなりますから。

0:15:06.929,0:15:10.319
しかし検証誤差に関しては当てはまりません。ですので検証誤差は悪くなります。

0:15:11.470,0:15:13.329
とはいえ、

0:15:13.329,0:15:14.769
このことは必ずしも

0:15:14.769,0:15:20.128
過学習、もしくは悪い意味での過学習しているとは言い切れません。

0:15:20.379,0:15:23.639
実際に、検証誤差は増え始めているが、

0:15:24.279,0:15:30.118
検証正確度あるいは誤差率などのメトリクスは良くなっていることもありうるのですから。

0:15:31.269,0:15:33.220
過学習を数式的に

0:15:33.220,0:15:37.290
表せすには損失関数について学ぶ必要があるのでここでは行いません。

0:15:37.290,0:15:43.379
検証誤差ではなく、メトリクスの値が悪化していないか見るのが

0:15:44.110,0:15:48.389
大事と認識しておいてください。

0:15:49.749,0:15:51.749
大変素晴らしい質問でした。

0:15:55.689,0:16:03.178
次に学ぶべき重要なことは、転移学習と呼ばれるものです。

0:16:03.699,0:16:05.699
なぜlearn.fitなんでしょう？

0:16:06.220,0:16:08.459
fine tuningは転移学習で行うものです。

0:16:08.980,0:16:16.559
転移学習では、異なるタスクで訓練された学習済みモデルを活用します。

0:16:16.809,0:16:23.969
専門用語の説明にさらに専門用語が必要ですね。学習済みモデルとは何でしょう？

0:16:23.970,0:16:26.850
先ほど、今使っているアーキテクチャはresnet34とお伝えしました。

0:16:27.819,0:16:32.279
resnet34を持ってくる時、それはただの数式で、

0:16:32.619,0:16:37.169
大量のパラメータが使われていて、私たちが機械学習で調整しようとします。

0:16:40.420,0:16:46.649
ImageNetという1000クラス合計130万枚の画像データセットがあります。

0:16:47.949,0:16:52.618
キノコや動物、飛行機やハンマーなどが含まれます。

0:16:54.730,0:16:59.189
かつて、ImageNetのコンペテイションが毎年開催されていて、研究者達はより

0:16:59.529,0:17:03.448
より良い分類器を作ろうと努力していました。

0:17:04.240,0:17:05.889
そこで作られたモデル

0:17:05.889,0:17:12.359
のパラメータはインターネットで公開されていて、今では誰もが使えます。

0:17:12.610,0:17:17.130
つまり、それらをダウンロードする時、アーキテクチャではなく学習済みモデルが手に入ります。

0:17:17.230,0:17:20.730
そのモデルは写真に写っている1000種類の物体を

0:17:21.880,0:17:24.510
識別できます。

0:17:25.779,0:17:31.169
これは、たまたまその1000クラスを正確に認識するものが必要な場合を除いては、あまり有用ではないでしょう。

0:17:32.260,0:17:34.260
しかし、実際には、

0:17:36.370,0:17:42.209
その重みから始めて、新しいデータセットでさらに数エポック訓練すれば、

0:17:43.000,0:17:46.949
事前に訓練されたモデルから始めなかった場合よりも

0:17:47.230,0:17:53.610
はるかに正確なモデルができあがります。なぜかはすぐに確認します。

0:17:54.610,0:17:58.829
この移動学習のアイデアは、直感的に理解できますよね？

0:18:00.429,0:18:04.649
ImageNetにはすでに猫と犬が登録されていて、

0:18:04.650,0:18:06.779
これは猫でこれは犬だと言うことができますが、

0:18:06.779,0:18:10.889
ImageNetには登録されていない多くの犬種を認識するようなことをしたいと思います。

0:18:11.529,0:18:18.719
猫と犬、飛行機とハンマーを認識するためには、

0:18:19.720,0:18:26.339
金属はどんな形をしているのか、毛皮はどんな形をしているのか、などを理解する必要があります。ですから、

0:18:26.340,0:18:31.770
この犬種は耳が尖っている、これは金属だから犬のはずがないといったことがわかります。

0:18:32.529,0:18:37.709
これらの概念はすべて、事前に訓練されたモデルによって暗黙的に学習されます。

0:18:38.470,0:18:42.839
ですから、事前に訓練されたモデルから始めれば、これらすべての特徴をゼロから

0:18:43.630,0:18:47.849
学習する必要はありません。

0:18:48.370,0:18:55.679
少ないデータと計算力でより良いモデルを獲得できるということは非常に重要ですから

0:18:56.080,0:19:01.500
FastAIライブラリとこのコースは転移学習にフォーカスしています。

0:19:03.820,0:19:10.590
質問です。誤差率とメトリクスの違いを説明してください。

0:19:14.559,0:19:16.559
わかりました。

0:19:19.029,0:19:21.029
誤差率は

0:19:21.460,0:19:33.220
メトリクスの1つです。ラベルの候補はたくさんあります。例えば、犬と猫の年齢などです。

0:19:33.220,0:19:34.510
この場合、

0:19:34.510,0:19:39.569
メトリクスは、予測と実際の年齢のズレでしょう。

0:19:41.590,0:19:48.209
これがメトリクスになるでしょうが、一方で犬と猫の識別を行う場合、

0:19:48.700,0:19:50.669
メトリクスは

0:19:50.669,0:19:52.669
誤分類の割合になるでしょう。

0:19:53.230,0:20:00.809
今説明したものが誤差率です。誤りは1つのメトリクスです。それは、

0:20:01.359,0:20:05.879
モデルがどの程度できるかを測り、私たちが一番気にするものです。

0:20:06.039,0:20:13.019
ですから、メトリクスとはfastaiが提供しているものを使うか自分で定義してください。

0:20:15.820,0:20:17.769
損失は

0:20:17.769,0:20:22.049
前回のレッスンで説明しましたが、簡単におさらいしましょう。

0:20:22.059,0:20:24.059
もし覚えてなかったら前回のレッスンを確認してください。

0:20:24.970,0:20:29.939
アーサー・サミュエルは、機械学習モデルにはパフォーマンスの指標が必要で、

0:20:31.269,0:20:38.638
それは私たちがパラメータを調整した時にパフォーマンスがどう変化したか確認できるものとしています。

0:20:39.609,0:20:41.609
先ほど申し上げましたが、

0:20:42.519,0:20:44.519
中には

0:20:44.710,0:20:50.999
パラメータが変わっても全く変わらないメトリクスもありますが、 それはメトリクスとしては不適切です。

0:20:51.609,0:20:56.789
なぜなら、パラメータを調整してより良いパフォーマンスのものを見つけるのが目的ですから。

0:20:56.789,0:20:59.309
よく異なる関数を使います。

0:20:59.309,0:21:01.309
それは損失関数というもので、

0:21:01.389,0:21:07.139
パフォーマンスの指標で、アルゴリズムがより良いパラメータを見つけるのに使う関数です。

0:21:07.509,0:21:13.229
損失関数はメトリクスに似たもので、

0:21:13.869,0:21:20.159
どんな微小なパラメータの変化をも検知する必要があります。

0:21:20.159,0:21:21.159
ですので、

0:21:21.159,0:21:22.779
損失関数がどうなっているかを

0:21:22.779,0:21:27.659
知るためには数学を勉強しなければならないので、次回以降のレッスンで教えます。

0:21:31.450,0:21:33.450
素晴らしい質問をありがとう。

0:21:35.499,0:21:41.579
fine tuningは転移学習のテクニックで、

0:21:42.519,0:21:45.508
スライドじゃなく、写真を見せている時に、

0:21:51.350,0:21:56.600
fine tuningは転移学習のテクニックで、これは、重み、これは厳密には不正確で

0:21:56.600,0:22:02.809
パラメータと言うべきですが、事前学習済みモデルのパラメータが追加の数エポックの学習で更新します。

0:22:03.030,0:22:05.689
この時は事前学習とは違うタスクのデータセットを使います。

0:22:05.690,0:22:17.990
今回は事前学習はImageNetで私たちのタスクは犬か猫を認識するものです。

0:22:18.690,0:22:24.650
標準では、fastaiはこの微調整を1エポックのみ行います。

0:22:25.799,0:22:32.779
つまり、データセットの画像を全て見て、事前学習済みモデルを部分的に調整して

0:22:33.390,0:22:36.349
パフォーマンスを改善します。このモデルは

0:22:36.870,0:22:39.409
新たなデータセットで機能するものです。

0:22:40.020,0:22:41.730
その後、

0:22:41.730,0:22:44.900
好きなだけモデル全体を更新しますが、

0:22:45.000,0:22:48.319
これは少し発展的なものです。

0:22:48.320,0:22:52.460
これがどう機能するかは今後のレッスンで説明します。

0:22:53.789,0:22:57.139
さて、転移学習はなぜうまくいくのでしょうか？

0:22:58.049,0:23:04.099
2012年のImageNetコンペティションの優勝者であるZeilerとFurgusの論文を

0:23:05.700,0:23:07.700
チェックしましょう。

0:23:08.340,0:23:09.809
興味深いことに、

0:23:09.809,0:23:16.309
彼らの考えは、モデル内部の可視化に基づいています。可視化はしばしば

0:23:16.470,0:23:19.459
素晴らしい結果を得る上で非常に重要です。

0:23:20.520,0:23:25.489
彼らができたことは、resnet34は34層ありますが、

0:23:26.400,0:23:28.320
彼らは

0:23:28.320,0:23:34.909
7層からなり、当時はそれだけで巨大とされていましたが、ImageNetのチャンピオンモデルであるAlexNetを見ました。

0:23:35.580,0:23:40.580
著者らは、最初の層のパラメータは

0:23:40.950,0:23:46.340
どのようなものかを疑問に思い、可視化する方法を編み出しました。

0:23:46.340,0:23:49.340
最初の層に対応する図は

0:23:50.970,0:23:56.900
沢山あるのですが、ここには9つ載せてあり、

0:23:57.960,0:24:00.620
それぞれどんな見た目かがわかります。

0:24:00.620,0:24:04.960
1つは左上から右下にかけての斜め線を認識しています。

0:24:04.960,0:24:08.039
また別のものは左下から右上への線を見つけます。

0:24:08.320,0:24:12.179
また別のものは、上のオレンジから下の青に向かう勾配を見つけます。

0:24:12.909,0:24:18.389
そして、また別のものは緑色のものに反応します。

0:24:19.030,0:24:22.530
それぞれは、

0:24:24.549,0:24:26.939
フィルターと呼ばれますが、特徴を抽出します。

0:24:28.659,0:24:32.009
彼らが行ったことでもっとも興味深いことは、彼らが9つそれぞれを良く見たことです。

0:24:32.799,0:24:38.999
私たちはこれらの実態を数学的に学ぶ予定です。

0:24:39.730,0:24:41.650
ここでは、

0:24:41.650,0:24:46.169
このことを認識して、これは斜め線が見ている、や、これは勾配を見ているということを確認し、

0:24:46.690,0:24:50.280
ImageNetの画像でもこれらがあることを知っておいてください。

0:24:52.390,0:25:04.559
左上のフィルターにはそのフィルターにマッチする実際の写真の９つのパッチがあります。

0:25:04.559,0:25:11.399
そして、ここには4つの緑のフィルターがあり、緑のフィルターにマッチした写真の一部があります。

0:25:11.950,0:25:18.210
第一層は単純です。ここで注目すべきは、

0:25:18.730,0:25:24.030
グラデーションや色や線のパッチを認識できるものは、imagenetだけでなく

0:25:24.030,0:25:28.169
他の多くのタスクにも使える可能性があるということです。

0:25:29.020,0:25:31.020
こういうことができると

0:25:31.419,0:25:34.079
ImageNet以外のタスクもこなせる可能性があるのです。

0:25:35.380,0:25:37.380
これが第二層で、

0:25:37.390,0:25:41.579
第一層で得た特徴を受け取り、組み合わせて

0:25:42.429,0:25:48.029
エッジだけでなく、角や

0:25:49.299,0:25:57.089
カーブの繰り返す、半円や円を見つけます。例えば、ここには

0:25:58.990,0:26:02.760
第二層以降を正確に可視化するのは

0:26:04.419,0:26:09.359
難しいと思います。

0:26:10.150,0:26:19.840
しかし、第二層のフィルターが写真のどんな部分に発火しているかの例があります。

0:26:20.030,0:26:22.869
そして、ご覧の通り、円のようなものを見つけていて、

0:26:23.390,0:26:30.490
興味深いことにこのぼやけたようなグラデーションは夕日を見つけるのに非常に適しているようです。

0:26:30.950,0:26:38.330
そして、この繰り返しの縦のパターンは、カーテンや小麦畑などを見つけるのに非常に適しています。

0:26:38.330,0:26:44.139
このようにして、レイヤー3をさらに進めると、レイヤー2にあるすべての種類の特徴を組み合わせることができるようになります。

0:26:44.540,0:26:50.920
ここでは12種類の特徴しか見ていませんが、実際には数百個の特徴があるでしょう。

0:26:50.920,0:26:53.320
AlexNetが実際にいくつの特徴があるか覚えていませんが、AlexNetにはたくさんの特徴があります。

0:26:53.750,0:27:00.700
しかし、第二層の要素を組み合わせて第三層に到達することには、

0:27:01.700,0:27:06.189
テキストを見つけることができて、この特徴は画像のテキストを見つけられます。

0:27:07.130,0:27:09.130
これはすでに

0:27:10.130,0:27:13.780
幾何学的な繰り返しを見つけることができます。お分かりのとおり、

0:27:15.710,0:27:18.340
特定のピクセルパターンとのマッチングではありません。

0:27:19.190,0:27:24.249
これは意味的な概念のようなもので，円、四角形、六角形の繰り返しを見つけられます。

0:27:24.920,0:27:28.450
素晴らしいですね。これが計算で、ただのテンプレートマッチング

0:27:29.240,0:27:36.700
ではりません。ニューラルネットワークは計算可能な任意の関数を解けることを覚えておいてください。確かにこういった計算ができます。

0:27:38.960,0:27:41.710
第4層は第3層のフィルタを

0:27:42.290,0:27:51.220
一度にすべて組み合わせることができます。そして第4層では、例えば犬の顔を見つけることができるものができます。

0:27:51.470,0:27:53.470
そして、このように、

0:27:54.410,0:27:59.499
各レイヤーでは、より応用的に洗練された機能が得られるようになっています。

0:27:59.630,0:28:04.360
これがニューラルネットワークを強力たらしめている要因です。

0:28:05.150,0:28:11.200
それはまた、転移学習が非常にうまく機能する理由でもあります。なぜなら、

0:28:11.990,0:28:15.550
もし本を見つけたいとしても、本はImageNetにはないと思いますが、

0:28:15.680,0:28:21.549
学習済みモデルはすでに本を見つけるのに必要なフィルターを獲得しているからです。

0:28:21.560,0:28:24.700
もしかしたら図書館や本棚のカテゴリーはあるかもしれません。

0:28:26.390,0:28:32.660
ですから、転移学習では事前に学習した

0:28:33.150,0:28:38.089
特徴や既存の特徴の組み合わせを使うことができるのです。

0:28:38.310,0:28:45.440
これが、従来のアプローチに比べて、転移学習が高速かつ少データで機能する理由です。

0:28:47.250,0:28:53.119
ここで重要なことは、コンピュータビジョンのためのこれらの技術は写真を認識するのが得意なだけではないということです。

0:28:55.170,0:29:01.430
画像で表現できるものは多くあります。例えば、これらは

0:29:01.980,0:29:08.329
時間の経過とともに周波数を表現して画像化した音です。

0:29:09.120,0:29:13.880
そして、音をこのような画像に変換すれば、

0:29:14.580,0:29:18.380
音検知の最高精度を達成できるのです。

0:29:19.260,0:29:22.489
単に既に見てきたのと同様ResNetと

0:29:23.160,0:29:25.160
learnerを使うことでできるのです。

0:29:25.860,0:29:29.449
9:45ですが、休憩しますか？

0:29:30.720,0:29:32.720
転移学習の非常に良い例は

0:29:33.000,0:29:37.640
、これは1年目のFastAIの生徒がやったことだと思いますが、

0:29:38.880,0:29:45.499
Splunkでの仕事ですが、ユーザのマウスの動きを写真にして、詐欺対策を行いました。

0:29:45.500,0:29:48.530
私の記憶が正しければ、彼らはマウスの動くを画像にして、

0:29:48.740,0:29:55.310
その動きの速さに応じて色分けしました。

0:29:55.830,0:29:59.630
丸は左もしくは右クリックを表します。

0:30:00.570,0:30:05.389
それから、彼が実際にコースのプロジェクトとして行ったことは、

0:30:06.210,0:30:12.560
作成した画像に対して転移学習が使えるかどうかを確認しました。

0:30:12.560,0:30:17.839
レッスン1で詐欺行為防止モデルを作り、それが動くことを見ましたが、

0:30:17.840,0:30:24.620
Splunkは転移学習を活用したプロダクトで特許を取得しています。

0:30:24.620,0:30:30.859
そして、このことについてのブログが公開されており、このアプローチが

0:30:32.190,0:30:37.219
私たちの優秀で創造的な受講生がレッスン1の後に思いついたものに基づいていることも書いてあります。

0:30:39.180,0:30:43.580
もう一つの素晴らしい例は、様々な

0:30:44.880,0:30:46.380
ウイルスを調べて、

0:30:46.380,0:30:51.109
同様に画像に変換したものです。これは論文からの引用ですが、

0:30:51.630,0:30:53.630
本を参照してください。

0:30:54.240,0:30:58.729
彼らは、VB80と呼ばれるウイルスのサンプルを3つと、

0:30:59.070,0:31:05.179
fake rienと呼ばれるウイルスの例をもってきて、画像に変換しました。

0:31:05.850,0:31:06.800
これによって

0:31:06.800,0:31:11.900
彼らは、プログラムシグナルのようなものを画像に変換し、画像認識を行うことで、

0:31:12.300,0:31:16.610
ウイルス検知の最高精度を達成しました。

0:31:20.040,0:31:25.820
本には、これまでに紹介してきた最も重要な単語のリスト

0:31:25.820,0:31:29.270
がその意味と一緒に掲載されています。ここでは読み上げませんが、

0:31:29.270,0:31:35.270
みなさんはチェックしてください、というのもここに載っている単語は今後使いますし、

0:31:35.520,0:31:37.520
意味も含めて把握してください。

0:31:37.710,0:31:43.789
というのも、これから説明するラベル、アーキテクチャ、モデル、パラメータ

0:31:44.130,0:31:50.359
には特定の意味があり、その意味で使われるからです。

0:31:51.990,0:31:58.909
確認ですが、ここまでがアーサー・サミュエルのアプローチに関して、学んだことで、

0:31:59.970,0:32:05.299
彼の用語を私たちの用語に置き換えると、アーキテクチャというものがあり、

0:32:05.970,0:32:12.380
それは、パラメータとデータを入力として受け取ります。

0:32:13.200,0:32:16.669
つまり、アーキテクチャはモデルのパラメータと、

0:32:17.850,0:32:20.480
データを受け取って予測を計算します。

0:32:20.820,0:32:26.990
予測は損失関数によってラベルと比較され、損失関数はパラメータの更新に使われます。

0:32:27.600,0:32:32.449
この処理は損失が小さくなまで何回も繰り返されます。

0:32:34.890,0:32:37.279
ここまでがfast bookの第一章です。

0:32:38.010,0:32:44.059
そして、クイズに答えてみることを強くお勧めします。なぜなら、クイズは、みなさんが

0:32:45.640,0:32:52.020
その章から私たちが理解してほしいことをちゃんと学んだかを確認するためにあり、

0:32:53.380,0:32:57.599
不確かなものについてはその章に説明があるので、

0:32:57.640,0:33:02.640
少し戻って、答えを見つけてください。

0:33:04.390,0:33:10.950
そして、はじめのいくつかの章に関しては発展的なリサーチの節もありますが、非常に単純です。

0:33:11.050,0:33:16.380
それらは、興味深く楽しめるものと思って書きました。ただ本を読むだけでは答えがわからず、

0:33:16.900,0:33:22.410
自分で検索したり、実験しないと答えはでないと思います。

0:33:23.260,0:33:32.980
さらに後の方の章ではこういったリサーチは重たくなってくるので、数日、場合によっては数週間かかるかもしれません。

0:33:32.980,0:33:38.820
はい、それらは、きっと理解の助けになるので必ずトライしてみてください。

0:33:41.200,0:33:47.550
もう一つ、この本を最大限活用する上でのポイントは章を読み終えるごとに、

0:33:47.550,0:33:54.419
少し時間をとって、その章の知識で自分のプロジェクトに取り組むことです。

0:33:55.090,0:33:59.699
つまり、ノートブックの内容を新しいデータで再実行するのです。

0:33:59.700,0:34:04.169
第一章でこれをするのは少々難しいかもしれませんが、

0:34:04.540,0:34:07.440
第二章以降ではできるようになると思います。

0:34:08.920,0:34:18.390
それでは、9:55まで休憩をとりましょう。

0:34:18.970,0:34:25.770
さて、再開しましょう。次に進む前に質問に答えましょう。Rachel、お願いします。

0:34:26.530,0:34:29.130
モデルは再学習した場合、

0:34:29.130,0:34:35.430
事前学習でのデータセットに対するパフォーマンスが悪化するのでしょうか？

0:34:36.340,0:34:38.340
素晴らしい質問ですね。

0:34:39.460,0:34:47.310
質問の内容は、ImageNetで訓練したモデルを犬と猫のデータセットで

0:34:47.890,0:34:54.299
fine tuningすると、犬と猫を認識するのには優れているが、

0:34:56.380,0:34:58.900
ImageNetのデータセットに対してはそれほど優れていないのではないか？ということです。

0:34:58.910,0:35:03.879
確かに、飛行機やハンマーを認識するのはそれほど上手ではないでしょうし、これは

0:35:05.810,0:35:07.810
破滅的忘却と呼ばれるものです。

0:35:07.850,0:35:12.190
考えは、事前に見たデータセットと異なるものを見れば見るほど

0:35:12.260,0:35:16.960
事前に見たものを忘れていくというものです。

0:35:18.860,0:35:22.150
もしこの破滅的忘却を防ぎたければ、つまり、

0:35:22.850,0:35:27.009
新たなタスクと以前のタスクの両方で優れているモデルを作りたければ、

0:35:27.010,0:35:30.700
fine tuningを行う際に、事前のタスクで使ったサンプルも与える必要があります。

0:35:33.800,0:35:38.890
パラメータとハイパーパラメータの違いはなんですか？

0:35:40.070,0:35:46.150
入力として犬の画像を与え、ハイパーパラメータであるバッチサイズやモデルを変えた場合、

0:35:46.280,0:35:48.370
何がパラメータですか？

0:35:49.880,0:35:52.150
パラメータは、

0:35:53.540,0:35:58.240
レッスン1で伝えたように、アーサー・サミュエルによれば、

0:35:59.870,0:36:01.870
それは、

0:36:02.060,0:36:08.769
モデルがすることやアーキテクチャがすることを変えるものです。私たちは、無限に柔軟な関数から始め、

0:36:08.770,0:36:15.740
それこそがニューラルネットワークですが、それはなんでもできるものですが、

0:36:15.740,0:36:21.009
実際にニューラルネットワークができることを調整するのがパラメータです。

0:36:21.010,0:36:27.070
パラメータは関数に渡す数値です。関数に渡す数字は2種類あります。

0:36:27.070,0:36:34.059
1つは入力データ、例えば犬の写真のピクセルを表す数字でもう1つは学習で得られた

0:36:35.720,0:36:37.720
パラメータです。

0:36:38.150,0:36:42.430
ニューラルネットワーク以外の例としては、アーサー・サミュエルが60年代に

0:36:43.070,0:36:49.330
使ったかもしれないチェッカープログラムがあるでしょう。そのパラメータは

0:36:50.600,0:36:52.600
もしあれば、

0:36:53.240,0:36:57.099
ピースをとるか、ボードの端まで進むかの確率を表していたでしょう。

0:36:57.950,0:37:01.599
どちらの選択肢をより多くとるようにするかというものです。

0:37:01.870,0:37:10.410
例えば、一方より他方が2倍、3倍重要であるというものです。

0:37:10.410,0:37:12.000
ニューラルネットワークにおいては

0:37:12.000,0:37:19.069
パラメータはより抽象的なもので、詳しく理解するのは次回か次次回のレッスンになるでしょう。

0:37:19.590,0:37:23.990
ですが、基本的なアイディアは同じで、それは、

0:37:25.020,0:37:28.640
モデルが何か認識する動作を変更する数字であるということです。

0:37:29.550,0:37:35.060
悪性腫瘍であったり、犬か猫、カラー写真か白黒写真を認識するというようなものです。

0:37:36.810,0:37:38.810
一方で、ハイパーパラメータは

0:37:39.420,0:37:43.110
次のようなものに関する選択です。

0:37:43.110,0:37:49.670
例えば、関数を調整する際、どのようなプロセスを経るかといったものです。

0:37:52.020,0:37:57.140
このコースの進度が気になります。本の内容は全てカバーするのでしょうか？

0:37:58.350,0:38:02.420
答えは全ての内容として、何を意味するかに依りますが、本当に全てをカバーするのは無理でしょう。

0:38:07.110,0:38:10.370
実際には7回のレッスンでカバーできるものをカバーします。

0:38:11.790,0:38:18.440
つまり、本全体をカバーすることはできないでしょう。本全体をカバーするには、例年だと、

0:38:19.320,0:38:23.600
追加で2もしくは3つのコースが必要でした。通常はコース2つで本全体ですね。

0:38:24.750,0:38:28.909
ですが、どうなるかはわかりません。というのもこの本は500ページもありますから。

0:38:29.190,0:38:32.569
コース2つというのは、レッスン14回ということですか？

0:38:32.570,0:38:35.870
はい、14か21回で本が終わると思います。

0:38:37.530,0:38:39.740
先週の授業でお伝えした通り、

0:38:39.840,0:38:45.350
授業と独立して読み進めるのも理解の助けにはなると思います。

0:38:45.780,0:38:47.930
そして、コミュニティ、

0:38:49.200,0:38:54.049
つまり、フォーラムに参加して、質問を投稿したり回答することも有用です。

0:38:56.580,0:39:03.620
このコースの第二部では、作成したモデルをどうプロダクションに載せるかについても話します。

0:39:05.280,0:39:09.830
ですので、深層学習の限界や能力について理解することも

0:39:11.100,0:39:13.100
必要になってきます。

0:39:13.290,0:39:16.250
例えば、どんなプロジェクトが本番環境に載せるのに適しているかといったことですね。

0:39:17.100,0:39:20.809
そして、このコースと本の中で言及すべき大事なことは、

0:39:20.940,0:39:23.669
最初の2〜3回もしくは章では、

0:39:24.310,0:39:27.600
コーダだけでなく、全ての人が対象の

0:39:28.150,0:39:37.409
内容、例えば深層学習を動かすのに必要なものも含まれています。

0:39:37.450,0:39:42.329
例えば、それらは、深層学習が現時点で得意とするものです。

0:39:43.870,0:39:46.740
ですから、本に書いてあることをまとめました。

0:39:47.560,0:39:50.250
4つの分野があります。

0:39:51.100,0:39:54.539
この分野はfastaiのapplicationモジュールにあるもので、

0:39:54.850,0:40:02.309
コンピュータビジョン、テキスト，テーブル、そして推薦システムのための協調フィルタリングです。

0:40:02.890,0:40:10.589
質問です。ImageNet以外の事前学習済みモデルで利用可能なものはありますか？

0:40:10.750,0:40:14.520
いつImageNet以外のものを使うべきかというのは良い質問です。

0:40:16.810,0:40:20.730
たくさんの事前学習済みモデルがあります。

0:40:21.370,0:40:26.280
いくつか探し方がありますが、良い探し方は、

0:40:27.370,0:40:29.819
つまり、最初に見るべきは、

0:40:31.540,0:40:33.540
model zooです。

0:40:33.580,0:40:38.430
これは多種多様なモデルがある場所で，

0:40:39.760,0:40:43.289
あなたが探しているもの、特に事前学習済みモデルなら

0:40:44.920,0:40:46.920
見つけられます。

0:40:49.030,0:40:53.609
たくさんありますが、ここには残念なことに、

0:40:55.750,0:41:03.599
それほど多様ではなく、多くはImageNetやそれに類似したもので

0:41:04.240,0:41:06.689
医用画像のものはほとんどありませんね。

0:41:08.980,0:41:14.010
ドメイン固有の事前学習済みモデルを作る機会は多くあると思いますが、

0:41:14.010,0:41:17.549
十分多くの人が転移学習に取り組んでいるようではないのですね。

0:41:20.569,0:41:27.489
さて，4つのアプリケーションがあると話しました、そして、

0:41:28.880,0:41:34.569
深層学習はこれら全てにおいて非常に優れていますが、

0:41:36.529,0:41:43.268
スプレッドシートやデータベースのテーブルにおいては深層学習が最善とは限りません。

0:41:43.549,0:41:47.528
しかし、深層学習は高濃度変数が含まれる場合に有効です。

0:41:47.599,0:41:52.509
高濃度とは、郵便番号やプロダクトIDのように非常に多くのカテゴリ

0:41:53.059,0:41:55.239
をもつ変数のことです。

0:41:56.079,0:41:59.349
深層学習はそれを除けば大変素晴らしく、例えば

0:42:02.779,0:42:07.599
自然言語処理においては、分類や翻訳で良いパフォーマンスを発揮しています。

0:42:08.059,0:42:14.169
しかし、会話は苦手ですし、このことは多くの企業をがっかりさせてきました。

0:42:14.170,0:42:16.359
以前、作ろうとしたこともありますが、

0:42:17.299,0:42:19.509
深層学習は会話において、

0:42:20.329,0:42:22.309
正確な情報を提供するのが苦手なのです。

0:42:22.309,0:42:26.319
でもそれっぽく聞こえるものを返すのは得意です。

0:42:26.390,0:42:29.680
しかし、返答の正確性を正しいことを確認する方法がありません。

0:42:33.559,0:42:37.959
また、推薦システムにおける問題点の一つは

0:42:38.960,0:42:41.019
真相学習は予測に注力していることで、

0:42:42.259,0:42:48.459
予測というのは必ずしも良い推薦をすることを意味しません。すぐにどういうことか確認します。

0:42:49.789,0:42:52.569
深層学習はまた、マルチモーダルも得意です。

0:42:53.269,0:42:55.269
マルチモーダルとは、

0:42:55.970,0:43:02.139
数種類のデータを入力とするものです。例えば、テキストとの列を含むテーブルデータと画像、

0:43:03.650,0:43:05.710
そして、協調フィルタリングのデータ、

0:43:06.349,0:43:09.699
の組み合わせからなるデータなどが深層学習が得意とするものです。

0:43:10.519,0:43:12.519
例えば、

0:43:13.309,0:43:19.569
写真のキャプション生成は深層学習が大変得意としているものですが、

0:43:19.569,0:43:21.289
正確であるというのは不得意です。

0:43:21.289,0:43:26.289
ですから、実際には3羽の鳥が映っている写真に対して2羽の鳥であると言うといったものです。

0:43:27.829,0:43:29.829
そして、

0:43:30.880,0:43:31.930
他にも、

0:43:31.930,0:43:38.550
深層学習でできる想像的なことは沢山ありますし

0:43:39.160,0:43:46.080
Application based approaches for example an approach that we developed for natural language processing called you LM fit

0:43:46.080,0:43:48.080
これらはどれもコースで説明します。

0:43:48.670,0:43:55.200
例えば、タンパク質分析も素晴らしいです。もし、様々なタンパク質を異なる単語ととらえれば、

0:43:56.200,0:44:00.030
それらは列の中である種の状態や意味をもち、

0:44:00.490,0:44:07.409
ULMFitがタンパク質分析に使えることが分かったのです。

0:44:08.350,0:44:13.649
ですので、あなたが作ろうと思ったものに深層学習が使えるかもしれませんし、

0:44:14.290,0:44:17.969
実際に試してみるのも良いでしょう。

0:44:20.800,0:44:26.370
そして、検索してみれば、似たようなことに挑戦した人々を見つけられるかもしれません。

0:44:27.040,0:44:30.060
また、見つからないからうまく行かないと言うことではありません。

0:44:31.780,0:44:38.790
協調フィルタリングの弱点に言及しましたが、それは、推薦と予測は同じではないと言うことです。

0:44:39.310,0:44:41.310
この例はアマゾンで

0:44:41.440,0:44:45.870
よく起きています。私がTerry Pratchettの本を買った後、

0:44:46.210,0:44:50.610
アマゾンは数ヶ月に渡ってTerry Pratchettの本を推薦していましたが、

0:44:50.830,0:45:00.520
それはアマゾンの予測モデルがTerry Patcherの本を買った人はまた買うと言っているからでしょう。

0:45:00.520,0:45:04.530
しかし，推薦というのは購買行動を多少左右するべきでしょう？

0:45:05.200,0:45:07.800
おそらく、ある本が好きだったら、

0:45:07.800,0:45:11.999
私がその著者が好きで、その著者の別の本が好きであることも分かっているでしょう。

0:45:12.000,0:45:15.510
ですから、そういった本は買うでしょう。

0:45:16.450,0:45:19.980
これはアマゾンの例ですがあまり賢くないですね。単に私に

0:45:20.680,0:45:25.919
推薦システムの最適化を行うのではなく協調フィルタリングの予測結果をただ見せているだけなのです。

0:45:26.500,0:45:30.510
最適化された推薦システムというのは、どちらかというと最寄りの書店の

0:45:31.120,0:45:35.399
店員のように振舞うものでしょう。あなたはTerry Pratchettが好きなんですね、

0:45:35.770,0:45:42.840
なら、コメディ、ファンタジー、SFなどから同じようなテイストで聞いたことがないかもしれない本を教えましょう。

0:45:44.200,0:45:49.139
この推薦と予測の違いは大変重要です。

0:45:50.619,0:45:55.079
ですので、モデル解釈とこのような重要な問題について話したいのです。

0:45:56.170,0:46:01.200
ケーススタディとして、今非常に重要なことを取りあげましょう。

0:46:01.530,0:46:03.689
この論文におけるモデルはどちらでしょう？

0:46:03.690,0:46:06.960
このコースで挑戦することの1つは論文の読み方を学ぶことです。

0:46:07.720,0:46:11.730
というわけで、皆さんに読んでいただきたいのがこちらの論文です。

0:46:12.310,0:46:18.179
高温多湿がCOVID-19の感染を減少させるという論文で、これは非常に重要な問題です.

0:46:18.730,0:46:21.419
もしこの論文の主張が本当ならば、

0:46:21.420,0:46:23.420
これは季節性の病気であることを意味し、

0:46:23.530,0:46:29.159
もしこれが季節性の病気であれば、大規模な政策的な意味合いを持つことになります。

0:46:30.880,0:46:36.540
これがどのようにモデル化されたのかを調べて、このモデルをどのように解釈するかを理解しましょう。

0:46:38.590,0:46:40.590
これが

0:46:41.530,0:46:45.659
論文からの重要な図です。

0:46:46.270,0:46:51.119
彼らは中国の100の都市の気温を1つの軸に摂氏でプロットし

0:46:51.490,0:47:00.970
もう1つの軸にはRをプロットしました。 Rは感染性の尺度です。各人がこの病気に感染した場合

0:47:00.970,0:47:02.970
平均で何人を感染させるかを表しています。

0:47:03.790,0:47:09.749
つまり、Rが1以下であれば、この病気は広まりません。

0:47:10.720,0:47:14.010
もしＲが２より高ければ 信じられないほど早く広がります。

0:47:15.369,0:47:20.459
基本的に、Rが高くなると、指数関数的に感染が拡大します。

0:47:21.670,0:47:28.240
このケースでは、ここに最適な線をプロットしています。

0:47:28.240,0:47:30.750
そして、彼らは、

0:47:32.260,0:47:38.699
Rは1.99から0.023かける温度を引いたものであるという公式に基づいて、ある特定の関係があると主張しています。

0:47:39.760,0:47:41.470
ここで

0:47:41.470,0:47:45.780
この図を見ていて私が懸念しているのは、

0:47:47.560,0:47:53.340
これは単なるランダムなものかもしれない、もしかしたら全く関係がないのかもしれない、ということです。

0:47:54.010,0:47:58.709
100の都市をランダムに選ぶと、この程度の関係性を示すことがあるのかもしれません。

0:48:00.160,0:48:08.859
それを確かめる簡単な方法としては、実際にスプレッドシートを使ってみるという方法があります。

0:48:08.859,0:48:16.619
これがスプレッドシートです。 ここで私がやったのは、このデータを見て、平均気温が何度かを推測してみました。

0:48:16.839,0:48:24.029
約5度だと思います。 摂氏の標準偏差は？　たぶん同じように5くらいだと思います。

0:48:24.819,0:48:28.979
そして、Rについても同じことをしました。平均Rは私には

0:48:29.260,0:48:34.020
1.9くらいに見えます。 そして、Rの標準偏差はおそらく0.5くらいだと思います。

0:48:35.589,0:48:40.409
そこで、私はここにジャンプして、

0:48:41.440,0:48:42.819
ランダムな

0:48:42.819,0:48:47.519
正規値、つまり正規分布からのランダムな値を作成しました。

0:48:47.530,0:48:53.849
つまり温度の特定の平均と標準偏差とRの特定の平均と標準偏差の

0:48:54.339,0:48:59.699
ベルカーブです。 これは架空の

0:49:00.549,0:49:02.020
100の都市の

0:49:02.020,0:49:07.889
データセットの中にあるかもしれない都市の例です。摂氏9度、Rが1.1の都市。

0:49:07.890,0:49:13.349
摂氏9度、Rが1.1で、このあたりになります。

0:49:14.950,0:49:18.359
だから、この式を100回

0:49:20.380,0:49:22.380
コピーしました。

0:49:22.420,0:49:25.290
ここに中国にあるかもしれない

0:49:25.960,0:49:31.889
100の都市がありますが、これは気温とRの間に

0:49:32.260,0:49:35.010
関係がないと仮定した、ただのランダムな数値です。

0:49:36.490,0:49:37.690
そして

0:49:37.690,0:49:43.290
だから再計算するたびに（コントロール・イコールを押すと再計算されます）

0:49:44.290,0:49:46.290
ランダムなので、違う数字が出てきます。

0:49:46.839,0:49:49.979
上の方には、

0:49:50.740,0:49:52.740
全温度の平均と

0:49:54.579,0:49:59.339
全Rの平均。全ての温度の

0:50:02.290,0:50:07.290
平均値が変化し、Rも同様に変化します。そこで

0:50:09.040,0:50:12.119
私がしたのはこれらの乱数をここに

0:50:14.530,0:50:16.530
コピーしたことです。

0:50:17.230,0:50:23.490
実際にやってみましょう。100個の乱数をコピーして

0:50:25.960,0:50:27.760
ここと、

0:50:27.760,0:50:33.389
ここと、 ここと、 こことに貼り付けます。これで

0:50:34.839,0:50:40.979
1 2 3 4 5 6 100個の都市のグループが６つできました。

0:50:41.289,0:50:43.559
これでこれ以上

0:50:45.220,0:50:51.359
ランダムに変化しないように固定しておきます。

0:50:57.789,0:51:00.329
さて、これで貼り付けました。

0:51:01.030,0:51:08.489
気温とRの関係が全くないとしたら、100の都市はどのようになるのか、6つの例が出てきました。

0:51:09.579,0:51:13.589
これら6つの例の平均温度とRはここにあります。

0:51:13.630,0:51:19.079
私がした事は、これを見て下さい、最初の例をプロットしました。

0:51:19.630,0:51:22.710
この場合、実際には

0:51:23.680,0:51:25.680
若干、プラスの傾きがあります。

0:51:26.500,0:51:28.500
私は実際に、

0:51:30.549,0:51:32.549
それぞれの傾きを

0:51:33.010,0:51:38.010
Microsoft Excelの傾き関数を使って計算しました。見ての通り、

0:51:39.430,0:51:41.430
この特定のケースでは、 ただランダムであることがわかります。

0:51:42.460,0:51:44.490
5回は

0:51:45.369,0:51:47.818
負の値を示しています。そして、それは彼らの

0:51:48.460,0:51:50.460
0.023よりもさらに負の値を示しています。

0:51:50.559,0:51:55.109
このように、私たちの直感と一致しています。

0:51:55.109,0:51:58.499
つまり、この線の傾きは、完全に

0:51:59.829,0:52:07.079
偶然に起こることが多いということです。 実際の関係を示しているようには見えません。

0:52:07.990,0:52:11.819
もし、この傾きを

0:52:12.490,0:52:18.689
もっと自信を持って示したいのであれば、もっと多くの都市を 調べる必要があります。

0:52:21.549,0:52:27.149
ここに3,000個のランダムに生成された数字があります。この傾きは

0:52:28.930,0:52:35.760
0.00002であるのがわかりますね？これは我々の期待通りほぼ0です。実際にCとRの間には関係がない場合、

0:52:35.760,0:52:37.949
これらはランダムに生成された数字で関係がありません。

0:52:38.740,0:52:44.219
そして、ランダムに生成されたたくさんの都市のデータを見てみると、「ああ、そうだ、傾きはない」と言えるでしょう。

0:52:44.590,0:52:49.379
しかし、今回のように１００個の都市だけを見た場合には、非常に多くの場合、

0:52:51.010,0:52:58.139
全く偶然に関係性があることがわかります。だから、それを測定する必要があります。

0:52:58.690,0:53:01.649
これを測定する一つの方法は、p値と呼ばれるものを使うことです。

0:53:02.590,0:53:05.159
p値、ここではp値がどのように機能するかを説明します。

0:53:05.470,0:53:12.600
まず帰無仮説と呼ばれるものから始めます。帰無仮説とは、基本的には出発点の

0:53:13.270,0:53:16.800
仮定のことです。 例えば我々の出発点の仮定は、

0:53:16.800,0:53:24.179
温度とRの間には何の関係もないというものかもしれません。そして、いくつかのデータを集めて、（レイチェル：Rとは何か説明してくれましたか？ ジェレミー：はい、しました)

0:53:24.390,0:53:26.390
Rはウイルスの透過性です。

0:53:28.180,0:53:35.310
そして、独立変数と従属変数のデータを収集します。 この場合、独立変数とは、

0:53:36.130,0:53:43.290
従属変数を引き起こすと思われるものです。ここでは、独立変数は温度で、従属変数はRです。ここでデータを収集しました。

0:53:43.990,0:53:46.379
この例で収集したデータはこれです。

0:53:46.380,0:53:51.960
そして、何％の割合でこれくらいの関連性を偶然で見ることがあるでしょうか？

0:53:51.960,0:53:55.830
ここでは0.023の傾きです。

0:53:56.260,0:54:00.090
これまで見てきたように、これを行う1つの方法は、いわゆる

0:54:00.190,0:54:07.260
シミュレーションと呼ばれるもので、乱数を生成して、100組の乱数のペアを何回か繰り返して、この関係がどのくらいの頻度で

0:54:07.510,0:54:09.600
見られるかを計測するというものです。

0:54:11.140,0:54:13.830
しかし、実際にそれをする必要はありません。実際には、

0:54:14.710,0:54:22.290
which is what percent of the time would we see that relationship by chance?
この数値を求めるのに使える簡単な方程式があります。ここ言えば、その関係性を偶然見てしまうのは何％なのかです。

0:54:25.150,0:54:27.150
そして

0:54:27.580,0:54:31.110
これは基本的にはこのようになります。ここに「最も可能性の高い観測」がありますが、

0:54:31.780,0:54:37.439
この場合、温度との間に関係がなければ、

0:54:37.590,0:54:40.410
最も可能性の高い傾きはゼロという事。

0:54:41.410,0:54:47.039
偶然、正の傾きが得られることもあれば、

0:54:48.160,0:54:50.219
かなり小さな傾きが得られることもあり、

0:54:51.010,0:54:54.180
また時には大きな負の傾きが得られます。

0:54:54.520,0:54:55.410
このように、

0:54:55.410,0:55:00.569
数字が大きくなるほど、それが正の側であろうと負の側であろうと、その可能性は低くなります。

0:55:00.910,0:55:02.969
私たちの場合、疑問だったのは

0:55:04.390,0:55:10.529
どのくらいの頻度で0.023以下の負の値を得ることができるのか。それは実際にはこの辺のどこかになるでしょう。

0:55:10.930,0:55:14.430
実はこれをウィキペディアからコピーしたのですが、正の数字を探していたので、

0:55:14.560,0:55:18.090
数字の上のこの部分に色をつけています。

0:55:18.370,0:55:25.380
これがp値です。数学は気にしていませんが、この数値、つまりp値を

0:55:25.960,0:55:27.960
データから直接計算するのに使える

0:55:28.780,0:55:32.460
簡単な小さな方程式があります。

0:55:34.360,0:55:37.589
これは、ほとんどすべての

0:55:38.710,0:55:41.879
医学研究の結果がこのような形で示される傾向があり、

0:55:42.850,0:55:47.519
人々はこのp値という考えに注目します。実際に、この特定の研究でも、

0:55:48.220,0:55:51.090
後ほどご紹介するように、p値が報告されています。

0:55:52.120,0:55:57.539
おそらく、多くの人が以前p値を見たことがあるでしょう。それらは様々な分野で出てきます。

0:55:59.110,0:56:01.110
ここからが問題なのですが、

0:56:01.180,0:56:05.039
これはひどいものです。使うべきではありません。

0:56:05.950,0:56:09.119
私だけを信用しないでください。アメリカ統計協会を信じて下さい。

0:56:10.330,0:56:12.870
彼らはp値について6つのことを指摘しています。

0:56:13.570,0:56:19.529
その中には次のようなものがあります。p値は仮説が真である確率を測るものでも、

0:56:20.080,0:56:23.610
あるいはデータがランダムな選択だけで作られた確率を測るものでもない、ということです。

0:56:24.040,0:56:31.110
これは今学んだように、より多くのデータを使用した場合、

0:56:32.020,0:56:37.350
100の都市ではなく3000の都市を無作為にサンプリングした場合、

0:56:38.080,0:56:43.080
得られる値ははるかに小さくなるのです。つまり、p値は関係性の大きさを教えてくれるだけではなく、

0:56:43.090,0:56:48.539
実際にはそれらを組み合わせて、どれだけのデータを収集したかを教えてくれるのです。

0:56:49.060,0:56:53.039
つまり、仮説が真である確率を測定するものではないのです。

0:56:54.430,0:56:59.610
したがって、結論や政策決定は、P値がある閾値を通過したかどうかに基づいて行われるべきではありません。

0:57:02.500,0:57:04.500
P値は結果の重要性を

0:57:04.780,0:57:06.780
測定するものではありません。

0:57:07.150,0:57:10.349
なぜなら、繰り返しになりますが、P値は、あなたが多くのデータを収集したことを教えてくれるだけで、

0:57:10.810,0:57:18.269
結果が実際に実用的なものであることを教えてくれるわけではないからです。それは証拠の良い尺度にはなりません。

0:57:20.500,0:57:27.840
フランク・ハレルという人がいますが、私は彼の本を読みました。本当に大切な学習の一部です。

0:57:27.840,0:57:31.590
彼は生物統計学の教授で、このことについて多くの素晴らしい記事を書いています。

0:57:33.370,0:57:34.810
彼は

0:57:34.810,0:57:39.029
帰無仮説検定とp値が科学に大きな害を与えていると言っています。

0:57:39.700,0:57:44.520
彼は「帰無仮説有意性検定は全く機能しなかった」という別の記事も書いています。

0:57:45.550,0:57:47.230
という事で、

0:57:47.230,0:57:48.730
私はp値が何であるかを示したのは、

0:57:48.730,0:57:56.070
なぜ機能しないのかを知るためであって、それを使えるようにするためではありません。しかし、それらは機械学習の超重要な部分で、

0:57:57.010,0:58:03.570
それはいつも出てきます。「この薬が効くのかどうか」とか、

0:58:04.270,0:58:06.630
「疫学的な関係があるかどうか」などと、

0:58:07.330,0:58:11.580
判断するために度々取り上げられます。

0:58:12.220,0:58:14.220
そしてこの論文にもp値が出てきます。

0:58:14.710,0:58:18.149
この論文では、多重線形回帰の結果が

0:58:19.030,0:58:21.030
示されています。

0:58:21.310,0:58:24.840
彼らは、p値が0.01以下の関係の隣に

0:58:25.480,0:58:29.070
3つの星をつけています。

0:58:30.880,0:58:32.880
さて、

0:58:34.420,0:58:39.240
0.01以下のような小さなp値については、何か役に立つことがあります。

0:58:40.150,0:58:43.890
それは、私たちが見ているものは、おそらく偶然起こったのでないという事です。

0:58:44.440,0:58:46.390
人々がいつも犯している

0:58:46.390,0:58:52.259
最大の統計的ミスは、p値が0.05以下ではないことを見て

0:58:52.660,0:58:55.080
関係が存在しないという誤った結論を

0:58:55.660,0:59:00.120
下してしまうことです

0:59:01.060,0:59:05.399
それは意味不明です。なぜなら、3つのデータポイントしかなかったとすると、

0:59:06.039,0:59:11.999
どの仮説に対してもp値が0.05未満になるような十分なデータはほぼ確実に得られないからです。

0:59:13.299,0:59:19.619
そこで、確認する方法としては、戻って、「もし私が全く逆の帰無仮説を選んだとしたらどうだろうか？」と考えるのです。

0:59:20.140,0:59:24.210
もし私の帰無仮説が、「温度とRの間に関係がある」だったとしたらどうでしょうか？

0:59:24.789,0:59:27.059
その帰無仮説を棄却するのに十分なデータがあるでしょうか？

0:59:28.029,0:59:32.129
答えがノーなら、

0:59:32.950,0:59:34.359
それは

0:59:34.359,0:59:38.338
どの結論を出すのにも十分なデータがないだけですよね？

0:59:38.890,0:59:45.569
この場合、彼らは温度とRの間に関係があると確信するのに

0:59:46.329,0:59:48.329
十分なデータを持っています。

0:59:48.490,0:59:49.779
これは変です。

0:59:49.779,0:59:54.989
なぜならたった先ほど、グラフを見て、エクセルで手早く計算して、これは、

0:59:55.509,0:59:58.019
ランダムかもしれないという結論に至ったからです。

1:00:00.039,1:00:02.039
問題はここにあります。

1:00:02.619,1:00:08.518
このグラフは、一変量関係と呼ばれるものを示しています。一変量関係は、

1:00:08.890,1:00:13.319
1つの独立変数と1つの従属変数の間の関係を示します。それが普通のグラフに表示できるものです。

1:00:14.019,1:00:16.169
しかし、このケースでは、

1:00:16.990,1:00:19.259
多変量モデルを用いて、気温、

1:00:20.259,1:00:21.609
湿度、

1:00:21.609,1:00:23.559
一人当たりGDP、

1:00:23.559,1:00:25.559
人口密度を調べました。

1:00:25.599,1:00:33.179
そして、それらをすべてモデルに入れると、温度と湿度について統計的に有意な結果が得られることになります。

1:00:33.730,1:00:37.079
なぜそうなるのでしょうか？なぜこのようなことが起こるのかというと、

1:00:38.950,1:00:43.169
青い点のこれらのすべての変化は無作為ではないのです。

1:00:43.420,1:00:47.159
異なっているのには理由がありますよね？その理由としては、

1:00:48.069,1:00:51.538
例えば、密度の高い都市ほど透過率が高いでしょう。

1:00:52.150,1:00:57.180
湿度の高い都市ほど透過率は低くなります。

1:00:59.109,1:01:06.689
多変量モデルを使うと結果に自信が持てるようになります。

1:01:09.309,1:01:16.169
しかし、アメリカ統計協会が指摘しているように、p値は、これが実際に重要かどうかを教えてくれるものではありません。

1:01:17.109,1:01:21.119
これが実用的に重要かどうかを教えてくれるのは、グラフの傾きです。

1:01:21.910,1:01:23.940
この場合、

1:01:25.930,1:01:33.719
彼らが出してきた方程式は R = 3.968から0.0383かける温度を引き、

1:01:33.720,1:01:38.130
それから0.0224かける相対湿度を引いたものです。

1:01:38.170,1:01:44.909
これはこの方程式です。これは実用的に重要でしょうか？ ここでまた、手早く

1:01:47.710,1:01:49.710
エクセルに入力してみましょう。

1:01:50.800,1:01:58.680
温度が10℃で湿度が40％の場所があったとします。

1:01:58.680,1:02:00.960
この式が正しいとすると Rは約2.7になります。

1:02:01.840,1:02:05.340
温度が35℃で湿度が80％の場所では

1:02:06.070,1:02:08.070
約0.8になります。

1:02:08.380,1:02:12.630
これは実質的に重要でしょうか？何てことでしょう、そうです。

1:02:13.360,1:02:16.259
異なる気候を持つ２つの異なる都市は、

1:02:16.960,1:02:20.369
もし他のすべての点で同じであって、このモデルが正しければ、

1:02:21.010,1:02:28.290
１つの都市では病気が広がらず（Rが1より小さいので）、１つの都市では大規模な指数関数的爆発が起こるでしょう。

1:02:29.650,1:02:31.000
ですから、

1:02:31.000,1:02:38.400
もしこのモデルが正しければ、これは非常に実用的に重要な結果であることがわかります。

1:02:38.400,1:02:43.799
このように、モデルの実用的な重要性を判断する方法は、p値ではなく、

1:02:44.380,1:02:47.579
実際の結果を見て判断することです。

1:02:48.910,1:02:51.180
ですから、モデルの実用的な重要性を

1:02:52.360,1:02:54.539
どのように考え、

1:02:55.150,1:03:00.420
予測モデルをどのようにして生産に役立つものに変えていけばいいのでしょう。

1:03:01.000,1:03:05.880
私はこのことについて何年も考えてきました。

1:03:06.490,1:03:08.230
そして

1:03:08.230,1:03:11.190
実際に他の素晴らしい人たちと一緒に論文を作成しました。

1:03:13.330,1:03:15.330
「優れたデータ製品の設計」

1:03:17.320,1:03:19.180
これは

1:03:19.180,1:03:21.180
私が設立した

1:03:22.270,1:03:24.840
オプティマル・ディシジョン・グループという会社で

1:03:24.840,1:03:28.920
10年に渡って行ってきた仕事に基づいています。オプティマル・ディシジョンズ・グループは

1:03:29.230,1:03:33.849
保険会社がどのような価格を設定すべきかを把握することに重点を置いていました。

1:03:34.520,1:03:35.960
それまで

1:03:35.960,1:03:41.919
保険会社は、予測モデリングに重点を置いていました。特にアクチュアリーは、

1:03:42.619,1:03:44.619
Spent their time trying to figure out

1:03:46.190,1:03:50.649
車を衝突させる可能性がどの程度あるのか、また衝突した場合の損害はどの程度なのかを把握し、

1:03:51.440,1:03:55.779
それに基づいて保険会社がどのような価格を設定すべきかを考えることに時間を費やしていました。

1:03:56.809,1:04:01.449
この会社の場合は、別のアプローチ、

1:04:01.700,1:04:08.359
つまりここで説明したドライブトレインアプローチというものを使って、

1:04:08.359,1:04:13.749
保険の価格を設定だけではなく他にもいろいろなことに活用してきました。保険の例で言うと、

1:04:14.720,1:04:17.709
保険会社の目的は、いかにして

1:04:18.559,1:04:20.559
5年間の利益を

1:04:21.049,1:04:23.049
最大化するかということです。

1:04:23.539,1:04:28.419
そのために、どのようなインプットをコントロールすることができるでしょか。私はこれをレバーと呼びます。

1:04:29.029,1:04:32.229
この場合、それは設定する価格です。

1:04:32.779,1:04:39.339
そして、データは、レバーを変えることで目的がどう変わるかを知ることのできるデータです。

1:04:39.470,1:04:46.299
例えば、車を衝突させる可能性の高い人たちの価格を上げれば、そういう人たちの数は減り、

1:04:46.299,1:04:52.059
コストは減りますが、同時に収入も減ることになります。

1:04:52.609,1:05:00.369
そこで、収集したデータを介して、目的とレバーを結びつけるために、レバーがどのように目的に影響を与えるかを説明する

1:05:01.160,1:05:03.160
モデルを構築しました。

1:05:03.740,1:05:08.469
このように言うと、当たり前のことのように思えますが、

1:05:09.200,1:05:16.839
私たちが1999年にオプティマル・ディシジョンズの仕事を始めたときには、保険業界では誰もこのようなことをしていませんでした。

1:05:18.020,1:05:23.709
保険業界では誰もが予測モデルを使って 車を衝突させる可能性を推測していました。

1:05:24.500,1:05:31.250
そして価格設定は20％とか何かを追加して設定するなど、非常にナイーブな方法で行われていました。

1:05:31.250,1:05:32.559
私がしたことは、

1:05:32.559,1:05:39.339
この基本的なプロセスを何年にもわたって、多くの企業が予測モデルを行動に移すために、このプロセスをどのように使うかを理解する

1:05:40.010,1:05:42.010
手助けをしてきたことです。

1:05:43.160,1:05:45.160
特定のモデルで

1:05:45.170,1:05:51.300
実際に価値を得るための出発点は、自分が何をしようとしているのかを考えることであり、

1:05:51.300,1:05:53.519
自分がしようとしていることの価値の源泉は何かを知ることです。

1:05:54.190,1:06:00.810
レバーとは、私たちが何を変えることができるのか？何もできないのであれば、予測モデルの意味はないでしょう。

1:06:02.170,1:06:06.270
自分が持っていないデータを見つける方法や、適切なデータ、利用可能なデータを見つけ出し、

1:06:06.460,1:06:09.480
その上でどのようなアプローチでアナリティクスに取り組むかを考えます。

1:06:10.180,1:06:13.750
そして超重要なのは、

1:06:13.750,1:06:18.869
その変更を実際に実行できるかどうかです。そして、環境の変化に合わせて

1:06:18.910,1:06:22.500
実際にどのように変化させていくかということも非常に重要です。

1:06:22.750,1:06:29.489
興味深いことに、これらのことの多くは、学術的な研究があまり行われていない分野です。少しはありますが。

1:06:31.359,1:06:37.289
「メンテナンス」に関する論文の中には、機械学習モデルがまだ大丈夫かどうかをどうやって判断するのか、

1:06:38.109,1:06:43.919
どうやって更新して行ったらいいのか、などがあります。たくさんの引用がありましたが、

1:06:44.650,1:06:49.889
多くの人が数学に集中しているため、あまり頻繁には出てきませんでした。

1:06:50.859,1:06:55.169
そして、「この全体にはどんな制約があるのか」という全体的な質問があります。

1:06:55.270,1:07:01.259
この本の中には、この６つのことを一つ一つ解説した付録がついています。

1:07:01.599,1:07:05.068
そして、例のリストがあります。

1:07:05.770,1:07:09.540
これは、価値について考える方法の一例です。

1:07:11.050,1:07:18.149
また、企業や組織が実際の生産に向けて、効果的な製品にするために、

1:07:19.960,1:07:22.949
これらの異なるパズルの

1:07:24.190,1:07:30.569
すべての部分について考えてみるために使える質問もたくさんあります。質問があります。はい、ちょっと待ってください。

1:07:30.569,1:07:36.959
だから私が言おうとしていたので、この付録をチェックしてみてください。なぜならこの付録は実は元々ブログ記事として登場したもので、

1:07:37.540,1:07:40.409
私がレイチェルと一緒に書いたcovid-19の記事を除けば、

1:07:40.410,1:07:46.260
実は今まで書いたブログ記事の中で最も人気のあるもので、数十万回の閲覧数を誇ります。そしてそれは、

1:07:47.319,1:07:49.180
20年間の苦労して勝ち取った

1:07:49.180,1:07:53.700
実際にどのように機械学習から価値を得るのか、

1:07:54.190,1:07:59.099
そして実際に何を尋ねなければならないのかという洞察のようなものです。ぜひチェックしてみてください。参考になれば幸いです。

1:07:59.930,1:08:01.930
季節性とcovid-19の伝染性の関係について

1:08:02.870,1:08:10.420
人々はどのように考えるべきか、という質問について考えるときには、

1:08:13.130,1:08:16.840
データの中の数字が何なのかだけでなく、

1:08:18.200,1:08:22.510
実際にはどのように見えるのか、という質問を深く掘り下げる必要があります。

1:08:22.510,1:08:27.369
論文の中で、彼らが示しているものの一つは、実際の地図です。

1:08:28.040,1:08:29.840
温度と

1:08:29.840,1:08:32.829
湿度とRの地図です。

1:08:33.650,1:08:37.659
驚くことではありませんが、

1:08:38.330,1:08:40.330
中国の湿度と気温は、

1:08:40.520,1:08:46.419
私たちが自動相関と呼んでいるものです。つまり、地理的に近い場所では、

1:08:46.730,1:08:51.490
気温も湿度も似ています。

1:08:51.530,1:08:53.270
このように、

1:08:53.270,1:08:57.520
彼らが示したp値に疑惑が出てきます。

1:08:58.160,1:09:03.519
なぜなら、これらの都市を100個の全く別の都市とは考えられないからです。

1:09:03.920,1:09:07.420
互いに近接している都市は、おそらく非常に似たような傾向が見られ、

1:09:07.420,1:09:10.180
これらを少数の「都市の集合体」のようなものと

1:09:10.940,1:09:16.370
考えるべきかもしれません。大地域のような。

1:09:16.370,1:09:21.700
このように実際にモデルを検討する際には、何が限界なのかを考える必要があります。

1:09:22.310,1:09:27.700
そして、それが何を意味するのか？それについてどうすればいいのか？

1:09:29.720,1:09:36.340
このようなユーティリティ（実用性）の観点から考える必要があります。

1:09:37.070,1:09:40.299
最初から最後まで、私にできる行動は何か、それによってどんな結果になるのか。

1:09:41.210,1:09:44.500
ただの帰無仮説検定ではありません。このケースでは、

1:09:46.520,1:09:48.760
基本的にここでは4つの主な結果が考えられます。

1:09:49.430,1:09:58.630
一つ目の可能性は「温度とRの間には実際に関係がある」です。

1:09:59.720,1:10:05.050
それはこの右側です。あるいは、温度とRの間には実際には関係がないということです。

1:10:06.350,1:10:09.610
そして、関係があると仮定して行動するかもしれません。

1:10:10.100,1:10:15.220
あるいは、関係がないと仮定して行動するかもしれません。

1:10:16.040,1:10:18.040
だから、４つの可能性をそれぞれ見て、

1:10:19.250,1:10:21.250
経済的、社会的な結果はどうなるのかと考える必要があります。

1:10:22.070,1:10:25.329
それぞれ大きな違いがあります。

1:10:26.000,1:10:30.220
失われた命の数や、経済の崩壊、その他何でもあります。

1:10:30.980,1:10:32.980
その四つの一つ一つに。

1:10:34.760,1:10:40.420
この論文の中には、もし彼らのモデルが正しければ、

1:10:40.550,1:10:48.219
3月の世界の全ての都市のR値はどうなるかを示しています。そして、世界の全ての都市の7月のR値はどうなるか。

1:10:48.950,1:10:53.800
例えば、ニューイングランドやニューヨークを見てみましょう。

1:10:54.530,1:11:00.009
この予測では、西海岸の海岸線も含めて、7月には

1:11:01.640,1:11:03.640
病気が広がらなくなると予測されています。

1:11:03.800,1:11:07.090
もしそうなったら、もし彼らの予測が正しければ、

1:11:07.880,1:11:13.089
それは大惨事になります。なぜならアメリカやイギリスでは、

1:11:13.790,1:11:16.790
「ああ、この病気は問題ではないことがわかった」と言われる可能性が高いと思います。

1:11:16.980,1:11:21.669
「実際には全く流行しなかった」とか「科学者は間違っていた」などと。

1:11:22.160,1:11:25.240
人々は以前の日常生活に戻ります。

1:11:25.820,1:11:32.679
1918年に起こったように,冬時期のインフルエンザウイルスの第2波は

1:11:33.740,1:11:35.740
最初よりもずっと悪い状態に

1:11:36.200,1:11:41.260
なりました。これが真か偽かによって、

1:11:42.320,1:11:48.489
政策に大きな影響を与える可能性があります。考えてみましょう。

1:11:49.280,1:11:55.179
はい？私が言いたかったのは、「夏になれば解決する」と考えるのは非常に無責任だということです。

1:11:55.730,1:11:57.999
「今すぐに行動する必要はない」と。

1:11:58.760,1:12:05.800
これは指数関数的に成長しているものであり、膨大な被害をもたらす可能性があるということだけです。被害はすでに起きているのですが。

1:12:06.650,1:12:07.450
どっちにしても問題です。

1:12:07.450,1:12:11.530
もし季節性があると仮定して、夏が解決すると仮定したら、

1:12:11.990,1:12:17.949
今は無関心になるかもしれません。逆にもし季節性がないと仮定したものの、

1:12:18.650,1:12:23.949
季節性があった場合、滅亡への予想が実際に起こるよりも大きくなり、

1:12:25.210,1:12:30.449
国民がさらに無関心になることになるかもしれない

1:12:30.449,1:12:34.559
どの方向に間違っても問題になります。

1:12:35.350,1:12:40.409
ですから、この種のモデリングを行う際の対処法の1つは、prior(事前)について考えてみることです。

1:12:41.230,1:12:45.750
prior(事前)とは、基本的には、帰無仮説を持つのではなく、

1:12:46.150,1:12:52.230
何がより可能性が高いのかを推測することです。 この場合、

1:12:54.070,1:13:00.420
記憶が正しければ、インフルエンザウイルスが27℃で不活性化することがわかっています。

1:13:00.730,1:13:03.209
そして風邪のコロナウイルスは

1:13:04.120,1:13:09.509
季節性があることがわかっています。1918年のインフルエンザの

1:13:10.449,1:13:12.250
大流行は季節性でした。

1:13:12.250,1:13:17.909
これまでに研究された全ての国や都市で

1:13:17.909,1:13:21.059
今のところほとんどは常に気候との関係を発見しています。

1:13:21.159,1:13:25.469
だから私たちの事前の推測は多分これは季節的なもので、
so maybe we'd say well prior belief is that this thing is probably

1:13:25.780,1:13:29.190
そしてこの論文は、それにいくつかの

1:13:30.010,1:13:32.010
証拠を加えているということになるでしょう。

1:13:32.230,1:13:34.230
このように、

1:13:34.300,1:13:38.250
モデルを実際に使用して、

1:13:39.340,1:13:46.560
この場合の政策議論だけでなく、組織的判断などに使用することがいかに複雑であるかわかると思います。

1:13:47.230,1:13:49.230
なぜなら、ご存じのように、

1:13:49.719,1:13:53.759
常に複雑さや不確実性があるからです。だから、実際には

1:13:54.429,1:13:59.729
ユーティリティと自分の最善の推測を考えて、できる限りすべてを組み合わせるようにしなければなりません。

1:14:00.400,1:14:05.250
そう言ったところで

1:14:07.659,1:14:08.890
それでもやっぱり

1:14:08.890,1:14:10.890
モデルを

1:14:11.590,1:14:16.350
稼働させることができたらいいなと思います。ただ予測モデルであっても、

1:14:17.170,1:14:22.589
それ自体が有用な場合もありますし、何かをプロトタイプ化することが役立つこともあります。

1:14:23.230,1:14:28.919
時には、何か大きなものの一部になることもあります。だから、ここでは巨大なエンドツーエンドのモデルを作ろうとするのではなく、

1:14:28.920,1:14:30.920
私たちは、どのようにして

1:14:31.780,1:14:33.780
Pytorchと

1:14:35.020,1:14:37.020
FastAIのモデルを

1:14:37.570,1:14:39.000
稼働させるかを説明することにしました。

1:14:39.000,1:14:45.180
可能な限り生の状態で。そこから、あなたの好きなように、その上に構築することができます。

1:14:45.610,1:14:47.610
そのためには、

1:14:47.710,1:14:49.510
自分のデータセットを

1:14:49.510,1:14:53.699
ダウンロードし、キュレーションする必要があります。そして、あなたも同じことをします。

1:14:54.340,1:14:58.139
そのデータセットを使って自分のモデルを学習し、

1:14:58.960,1:15:02.340
アプリケーションを作成して、それを公開するのです。

1:15:03.100,1:15:05.020
さて，

1:15:05.020,1:15:10.169
画像データセットを作成する方法はたくさんあります。自分のパソコンに写真があるかもしれませんし

1:15:11.110,1:15:13.110
職場であるものを使うかもしれません。

1:15:15.160,1:15:20.789
しかし、最も簡単な方法は、インターネットから画像をダウンロードすることです。 インターネットからダウンロードできるサービスはたくさんあります。

1:15:21.640,1:15:26.459
ここではBing Image Searchを使います。とても使いやすいからです。

1:15:27.010,1:15:33.119
他の多くのサービスはサイトの利用規約違反を犯す必要があります。

1:15:33.610,1:15:36.869
そのため、ここではその方法をお見せしません。

1:15:37.420,1:15:40.410
しかし、その方法を示す例はたくさんあります。

1:15:40.870,1:15:43.140
だから、どうしても知りたかったら、あなたはそれらを調べることができます。

1:15:43.690,1:15:47.850
Bingの画像検索は、今のところとても良いです。こういったものは頻繁に変わり、

1:15:47.850,1:15:50.430
おすすめが変わることもあるので、

1:15:51.460,1:15:53.460
ウェブサイトで確認してみてください。

1:15:53.710,1:16:00.000
Bing Image Searchの最大の問題点は、登録手続きが悪夢のようだということです。

1:16:00.730,1:16:06.390
今のところは。この本の最も難しい部分の1つは、彼らのAPIにサインアップすることのような気がします。

1:16:07.240,1:16:11.610
それにはAzureを経由する必要があります。それは Azure Cognitive Services と呼ばれていて

1:16:11.710,1:16:17.220
だから、私たちは、サインアップする方法がわかるように、すべての情報がウェブサイト上にあることを確認しておきます。

1:16:17.830,1:16:19.830
ということで、すでにサインアップされているという前提で

1:16:20.410,1:16:22.410
話を進めていきます。

1:16:25.060,1:16:27.060
Bing Image Search APIで検索

1:16:28.510,1:16:36.090
今のところ、7日間あまり制限なく

1:16:38.140,1:16:41.010
無料で利用できます。その後も

1:16:42.430,1:16:46.650
無料で利用できますが、

1:16:46.750,1:16:53.709
1秒間に処理3回などの制限が加されています。それでも十分な量です。

1:16:53.710,1:16:56.530
無料でも数千件の検索ができるので、今のところとてもいいオプションです。

1:16:58.460,1:16:59.480
さて、

1:16:59.480,1:17:01.250
Bing画像検索などのサービスに登録すると、

1:17:01.250,1:17:06.220
APIキーが発行されます。

1:17:06.290,1:17:11.649
ここにある「XXX」を発行されたAPIキーに置き換えてください。

1:17:11.750,1:17:14.740
これを「キー」と呼びます。

1:17:16.070,1:17:18.070
ここでやってみましょう。

1:17:20.060,1:17:24.399
キーを入力して、

1:17:25.400,1:17:29.530
search_images_bingという関数を作成しました。ご覧のように、

1:17:31.520,1:17:35.200
たった2行のコードですが、少しでも時間を節約しようと思って。

1:17:37.340,1:17:39.340
そして、

1:17:39.470,1:17:44.919
APIキーと検索語を入力して、その検索語にマッチするURLのリストを返します。

1:17:46.160,1:17:48.160
ご覧のように

1:17:48.830,1:17:54.609
この特定のサービスを利用するには特定のパッケージをインストールする必要があります。

1:17:55.730,1:17:59.530
このやり方もウェブサイトで紹介しておきます。

1:18:00.380,1:18:02.620
そうすれば、これを実行することができるようになり、

1:18:03.740,1:18:06.909
デフォルトで150のURLが返ってくると思います。

1:18:09.050,1:18:12.969
さて、fast.aiにはdownload_url関数がついていますので、

1:18:12.970,1:18:17.439
画像をダウンロードして確認してみましょう。

1:18:17.440,1:18:22.240
それで何をしたかというと、「グリズリーベア」で検索し、グリズリーベアの写真をダウンロードしました。

1:18:24.110,1:18:26.230
そこで私が言ったのは、

1:18:26.230,1:18:32.589
グリズリーベアと黒クマとテディベアを 認識できるモデルを作ってみようということです。

1:18:33.590,1:18:36.520
それを使ってキャンプ場の近くに

1:18:38.270,1:18:41.919
ビデオ認識システムを設置して

1:18:42.530,1:18:43.960
クマの警告をするようにしますが、

1:18:43.960,1:18:48.520
もしテディベアが来たら警告したり、私を起こしたりはしません。怖くないからです。

1:18:49.460,1:18:52.450
そこで、この３種類のクマをそれぞれ、

1:18:53.030,1:18:54.890
グリズリー、クロクマ、

1:18:54.890,1:19:00.669
テディベアという名前のフォルダを作り、Bingで

1:19:03.110,1:19:05.000
クマと一緒にそれらの検索語を検索して

1:19:05.000,1:19:09.370
ダウンロードします。download_imagesもfast.ai関数です。

1:19:10.430,1:19:13.360
この後にget_image_filesを呼び出すことができます。

1:19:13.460,1:19:18.610
これはfast.ai関数で、このパスの中にあるすべての画像ファイルを再帰的に返してくれます。

1:19:19.040,1:19:24.640
そして見ての通り、 bears/black/　そしてたくさんの数字。

1:19:27.260,1:19:28.790
さて、

1:19:28.790,1:19:33.490
注意しなければならないことの一つは、ダウンロードしたものの多くが画像ではなく、

1:19:33.490,1:19:37.990
エラーを起こしてしまうということです。そこで verify_images を呼び出して、

1:19:38.450,1:19:41.559
これらのファイル名がすべて実際の画像であるかどうかを確認します。

1:19:42.800,1:19:50.559
で、今回の場合は失敗したものがなかったので、空になっています。 しかし、もしあったのであれば、

1:19:51.920,1:19:58.149
Path.unlinkを呼び出してリンクを解除します。Path.unlinkはPython標準ライブラリの一部で、ファイルを削除してくれます。

1:19:59.240,1:20:02.169
そしてmapは、このコレクションの各要素に対して

1:20:02.990,1:20:06.189
この関数を呼び出すものです。

1:20:06.830,1:20:08.830
これは "L "と呼ばれる

1:20:08.870,1:20:10.730
特別な

1:20:10.730,1:20:13.450
fast.aiクラスの一部です。基本的には

1:20:14.180,1:20:16.570
Python標準ライブラリのリストクラスと

1:20:17.330,1:20:23.169
numpy配列クラスをミックスしたようなものです。
このコースでは後ほど詳しく説明しますが、

1:20:23.600,1:20:29.769
基本的にはPythonでより関数型のプログラミングが簡単にできるようにするものす。

1:20:30.830,1:20:34.809
この場合、失敗したリストにある

1:20:35.420,1:20:37.420
すべての画像のリンクを解除します。

1:20:37.880,1:20:42.550
検証に失敗した画像だからです。これで、

1:20:43.550,1:20:49.570
たくさんの画像が含まれたパスができました。ブラック、グリズリー、テディと、

1:20:50.510,1:20:54.070
どのフォルダに入っているかによって分類されています。

1:20:54.680,1:21:01.840
ということで、モデルを作成します。 モデルを作成するにはまず、

1:21:02.360,1:21:04.280
fast.aiに

1:21:04.280,1:21:07.419
どのようなデータがあり、どのように構造化されているかを伝える必要があります。

1:21:08.690,1:21:15.550
レッスン1では、ファクトリーメソッドと呼ばれるものを使用して、

1:21:15.620,1:21:22.359
ImageDataLoaders.from_nameと言っただけで、それがすべての処理をしてくれました。

1:21:23.869,1:21:26.289
これらのファクトリメソッドは初心者には良いのですが、

1:21:27.020,1:21:30.159
でも今はレッスン２に入っています 私たちはもう初心者ではありません

1:21:30.170,1:21:35.799
そこで、あなたの好きなフォーマットでデータを使用する超柔軟な方法をお見せしましょう。

1:21:35.960,1:21:40.119
これはDataBlock APIと呼ばれるものです。

1:21:45.050,1:21:47.800
これがDataBlock APIです。

1:21:49.340,1:21:55.600
fast.aiに独立変数と従属変数を指定します。

1:21:55.600,1:22:02.019
つまり、ラベルと入力データを指定します。 この場合の入力データは画像で、

1:22:03.170,1:22:08.619
ラベルはカテゴリです。カテゴリーはグリズリーかブラックか

1:22:09.260,1:22:11.179
テディになります。

1:22:11.179,1:22:13.239
これが最初に伝えることです。

1:22:13.239,1:22:19.178
これがブロックのパラメータです。そして、すべてのファイル名のリストを取得する方法を伝えます。

1:22:19.520,1:22:24.759
その方法は見たばかりです。なぜなら、さっきその関数を呼んだからです。関数は get_image_files と呼ばれています。

1:22:24.889,1:22:28.149
なのでこのリストを取得するためにどのような関数を使うかを指定します。

1:22:29.090,1:22:34.989
それからデータを検証セットとトレーニングセットにどうやって分けるかを指定します。

1:22:34.989,1:22:39.968
そこで、RandomSplitterと呼ばれるものを使って、データをランダムに分割します。

1:22:40.130,1:22:42.130
そして、そのうちの30%を検証セットに振り分けます。

1:22:42.469,1:22:48.669
また、ランダムシードを設定して、これを実行するたびに検証セットが同じになるようにします。

1:22:49.760,1:22:55.389
そして、データにラベルを付けるにはどうすればいいかを設定。これがその関数の名前、parent_labelです。

1:22:55.389,1:22:57.789
これは親フォルダの名前を見てラベルを判断します。

1:22:59.300,1:23:05.560
この画像のラベルは黒クマになります。

1:23:05.560,1:23:07.560
これは、画像データセットを表現する最も一般的な方法で、

1:23:09.469,1:23:16.178
異なる画像をラベルにしたがってフォルダに入れていくのです。

1:23:17.119,1:23:18.679
そして

1:23:18.679,1:23:21.579
最後にiアイテムトランスフォーム（item_tfms）と呼ばれるものがあります。

1:23:21.920,1:23:25.359
変換（トランスフォーム）についてはもう少し詳しく説明しますが、

1:23:25.580,1:23:33.070
これらは基本的に各画像に適用される関数です。この場合、それぞれの画像が128×128の正方形に

1:23:33.560,1:23:35.560
リサイズされます。

1:23:35.960,1:23:38.950
DataBlock APIについては近日中に詳しく説明する予定です。

1:23:39.200,1:23:44.619
しかし、基本的なプロセスはこのようになります。はじめに何らかのget_itemsを呼び出します（ここでは画像ファイルのリスト）。

1:23:45.650,1:23:50.320
そして get_x, get_y を呼び出します。この場合は get_x はありませんが、親ラベルの　get_y　があります。

1:23:50.320,1:23:55.659
そして、これらの2つのもののcreateメソッドを呼び出します。

1:23:55.660,1:23:57.789
画像を作成し、カテゴリを作成します。

1:23:58.520,1:24:01.990
そして、item_tfmsを呼び出してサイズを変更します。

1:24:02.930,1:24:06.249
次にそれをデータローダと呼ばれるものに入れます。

1:24:06.250,1:24:10.030
データローダとは、一度に数枚の画像を取得して、

1:24:10.400,1:24:14.890
（デフォルトでは64枚だと思います）それらを一つにまとめるものです。

1:24:14.890,1:24:19.090
これはバッチと呼ばれていて、64枚の画像を取得して、それらをすべて一つにまとめます。

1:24:19.760,1:24:23.499
なぜそうするかというと、すべての画像を一度にGPU上に配置して、

1:24:24.380,1:24:26.920
GPUを介してモデルに

1:24:27.230,1:24:33.640
一度にすべての画像を渡すことができるようにするためです。
これによりGPUの処理速度が格段に向上します。

1:24:34.730,1:24:36.879
そして最後に（ここでは何も使いませんが）、

1:24:37.190,1:24:43.960
これについては後ほど説明しますが、バッチ変換と呼ばれるものができます。そして、ここの真ん中辺りに

1:24:44.480,1:24:51.250
概念的にはスプリッタと呼ばれるものがありますが、これは学習セットと検証セットに分割するものです。

1:24:51.410,1:24:55.209
これはfast.aiにデータをどのように扱うかを指示するための

1:24:56.510,1:25:00.489
非常に柔軟な方法です。そして最後に

1:25:01.280,1:25:08.199
タイプがDataLoadersのオブジェクトを返します。
これをいつもDLと呼ぶのはそのためです。

1:25:08.390,1:25:12.579
DataLoadersには検証用とトレーニング用の

1:25:12.860,1:25:14.150
DataLoaderがあります。

1:25:14.150,1:25:20.470
先ほど言ったデータローダとは、いくつかのもののバッチを一度に取得して

1:25:20.470,1:25:22.250
GPU上に配置するものです。

1:25:22.250,1:25:26.530
これが基本的にデータローダのコード全体です。

1:25:27.470,1:25:31.269
細かいことは重要ではありませんが、指摘しておきたかったのは、

1:25:31.850,1:25:34.629
fast.aiの多くの概念は、実際に見てみると、

1:25:34.630,1:25:36.460
信じられないほどシンプルで小さなものです。

1:25:36.460,1:25:42.100
文字通り、いくつかのデータローダを渡すと、属性に保存されます。

1:25:42.410,1:25:47.359
すると、最初のものは.trainとして、2番目のものは.validとして返されます。

1:25:49.199,1:25:51.090
つまり、

1:25:51.090,1:25:53.210
まずDataBlockを作成して

1:25:55.230,1:26:02.359
DataLoadersを呼び出し、DLを作成するためのパスを渡すことでDataLoadersを作成することができます。

1:26:02.940,1:26:05.029
そして、show_batchを呼び出すことができます。

1:26:05.030,1:26:10.280
fast.aiではほとんどのものでshow_batchを呼び出して、データを見ることができます。見てください、グリズリーがいます。

1:26:10.280,1:26:12.280
テディがいて、グリズリーがいます。

1:26:14.280,1:26:16.280
わかりましたか？

1:26:17.880,1:26:22.699
データ拡張をは来週見ることにします。

1:26:22.699,1:26:27.469
なのでこれらは飛ばして、モデルのトレーニングをします。

1:26:31.710,1:26:35.089
さて、DLができたら、

1:26:35.760,1:26:39.199
レッスン１と同じように cnn_learner を呼び出して

1:26:39.719,1:26:43.038
ResNet を作成します。今回は小さめの ResNet18 を作成します。

1:26:43.590,1:26:49.519
ここでもエラー率を求めて、.fine_tune を呼びます。これまでに見てきたコードと

1:26:49.519,1:26:50.999
同じものを使っています。

1:26:50.999,1:26:55.819
誤差率が９から１に下がっているのがわかります。誤差は1%です。

1:26:56.519,1:27:02.719
約２５秒のトレーニングの後です。 見ての通り、たった450枚の画像で

1:27:03.690,1:27:10.789
1分にも満たないトレーニングで、混乱マトリックスを見てみましょう。

1:27:11.400,1:27:18.559
「分類解釈クラスを作りたい、混乱マトリックスを見たい」というと、ご覧のように、

1:27:18.659,1:27:21.768
「実際に黒クマであるものについて、

1:27:22.650,1:27:24.769
黒クマと予想じたのはいくつで

1:27:25.559,1:27:26.610
それに対して、

1:27:26.610,1:27:28.610
グリズリーベアやテディベアと予測したのはどれくらいでしょうか？」というような表です。

1:27:28.679,1:27:33.859
で、対角線上にあるのが全部正解で、2つの誤差があったようです。

1:27:33.860,1:27:38.150
黒クマだと予測されていたグリズリーが１匹とグリズリーだと予測されていた黒クマが１匹です。

1:27:40.889,1:27:42.889
超、超便利なメッソッドが

1:27:43.469,1:27:47.239
「トップの損失をプロットする」で、これは実際に私の誤差がどのように見えるかを教えてくれます。

1:27:48.809,1:27:56.119
これはグリズリーだと予測されていましたがラベルは「黒クマ」でした。

1:27:56.770,1:28:00.450
これは黒クマと予測されていましたがラベルは「グリズリーベア」でした。

1:28:02.500,1:28:04.800
こちらのものは実は間違っていません。

1:28:04.830,1:28:11.160
これは「黒」と予測されていて、実際には黒なのです。 しかし、この中に出てくるのは、これらがモデルが

1:28:12.730,1:28:15.540
最も自信を持っていなかったものだからです。

1:28:16.780,1:28:25.930
さて、画像分類器のクリーナーは来週見ることにします。

1:28:20.800,1:28:23.789
これをどうやって本番環境にに移すかに焦点を当ててみましょう。

1:28:25.930,1:28:27.930
本番環境に導入するためには、

1:28:28.150,1:28:30.150
モデルを

1:28:30.580,1:28:38.519
エクスポートする必要があります。モデルをエクスポートすると、新しいファイルが作成されます。デフォルトでは 「export.pkl」という名前で、

1:28:39.280,1:28:41.170
モデルのアーキテクチャと

1:28:41.170,1:28:43.920
すべてのパラメータが含まれています。

1:28:44.170,1:28:50.160
これで、どこかのサーバーにコピーして、

1:28:50.710,1:28:52.710
定義済みのプログラムとして

1:28:52.900,1:29:00.030
扱うことができます。そこで、学習したモデルを本番環境で

1:29:01.150,1:29:04.920
新しいデータに使用するプロセスを「推論」と呼びます。

1:29:05.410,1:29:10.019
ここでは、ラーナーを再びロードして推論ラーナーを作成しています。

1:29:10.390,1:29:17.640
明らかにノートに保存した後にすぐ隣で行うのは意味がありません。

1:29:17.640,1:29:23.459
しかし、これはどのように機能するかをお見せしているだけです。これはサーバー上で行う推論です。

1:29:24.730,1:29:31.470
一度モデルを学習したら、プログラムとして扱うことができることを覚えておいてください。

1:29:31.470,1:29:33.990
これが私たちのプログラムです。

1:29:33.990,1:29:40.590
これが私たちのクマの予測器です。これで 「predict」を呼び出して画像を渡すと、

1:29:41.200,1:29:43.200
ご覧の通り

1:29:43.210,1:29:45.210
99.999%の確率で

1:29:45.490,1:29:47.999
「グリズリー」であることを教えてくれます。

1:29:49.240,1:29:53.280
今日の授業はここまで。

1:29:54.160,1:29:57.180
来週は

1:29:58.750,1:30:00.750
クマ分類器の

1:30:01.180,1:30:02.680
実際のGUIを作成して

1:30:02.680,1:30:04.510
終わりにしましょう。

1:30:04.510,1:30:08.140
「Binder」というサービスを使って

1:30:08.140,1:30:10.140
無料で実行する方法を

1:30:10.920,1:30:12.570
紹介します。

1:30:12.570,1:30:14.570
それから、

1:30:16.530,1:30:23.150
そうすれば、裏で何が起こっているのかの詳細に飛び込む準備ができると思います。

1:30:23.849,1:30:27.379
レイチェル、質問や他に何かありますか？

1:30:28.860,1:30:34.339
ないです。オーケー。 All right. 皆さん、ありがとうございます。

1:30:37.409,1:30:39.679
ここまでで、

1:30:40.830,1:30:42.179
機械学習の観点からの

1:30:42.179,1:30:49.279
基礎となる重要な部分はほとんどカバーできたと思います。

1:30:51.000,1:30:53.060
ディープラーニングがどのように裏で機能しているのか、

1:30:54.840,1:30:58.310
低レベルの詳細に飛び込んでいく準備ができました。

1:31:00.540,1:31:03.889
それは来週から始まると思います。それでは、その時にお会いしましょう。
